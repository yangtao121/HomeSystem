"""
å…¬å¼çº é”™æ™ºèƒ½ä½“

åŸºäºLangGraphçš„è®ºæ–‡å…¬å¼çº é”™æ™ºèƒ½ä½“ï¼Œç”¨äºä¿®å¤åˆ†ææ–‡æ¡£ä¸­çš„å…¬å¼é”™è¯¯ã€‚
ä½¿ç”¨æ ‡å‡†å·¥å…·è°ƒç”¨æ¨¡å¼ï¼Œé›†æˆæ•°å­¦å…¬å¼æå–ã€OCRæ–‡æ¡£æŸ¥è¯¢å’Œæ–‡æœ¬ç¼–è¾‘åŠŸèƒ½ã€‚
"""

import json
import os
from typing import Annotated, Any, Dict, List, Optional
from typing_extensions import TypedDict
from pathlib import Path

from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from langchain_core.runnables import RunnableConfig
from langchain_core.messages import AIMessage, SystemMessage, ToolMessage, BaseMessage
from loguru import logger

from .base_graph import BaseGraph
from .llm_factory import get_llm
from .tool.math_formula_extractor import create_math_formula_extractor_tool
from .tool.ocr_document_loader import create_ocr_document_loader_tool
from .tool.text_editor import create_text_editor_tool


class FormulaCorrectionState(TypedDict):
    """å…¬å¼çº é”™çŠ¶æ€"""
    # è¾“å…¥æ•°æ®
    analysis_file_path: str                         # åˆ†ææ–‡æ¡£è·¯å¾„
    ocr_file_path: str                             # OCRåŸæ–‡æ¡£è·¯å¾„
    analysis_content: str                          # åˆ†ææ–‡æ¡£å†…å®¹
    ocr_content: str                              # OCRæ–‡æ¡£å†…å®¹
    
    # æå–çš„å…¬å¼ä¿¡æ¯
    extracted_formulas: Optional[List[Dict]]       # æå–çš„å…¬å¼åˆ—è¡¨
    
    # LangGraphæ¶ˆæ¯å†å²
    messages: Annotated[list, add_messages]        # å¯¹è¯å†å²
    
    # çº é”™ç»“æœ
    corrected_content: Optional[str]               # çº é”™åçš„å†…å®¹
    corrections_applied: Optional[List[Dict]]      # åº”ç”¨çš„çº é”™è®°å½•
    
    # æ‰§è¡ŒçŠ¶æ€
    is_complete: bool                              # æ˜¯å¦å®Œæˆçº é”™
    current_step: str                              # å½“å‰æ­¥éª¤


class FormulaCorrectionConfig:
    """å…¬å¼çº é”™é…ç½®ç±»"""
    
    def __init__(self,
                 correction_model: str = "deepseek.DeepSeek_V3",
                 memory_enabled: bool = True,
                 max_correction_rounds: int = 3,
                 custom_settings: Optional[Dict[str, Any]] = None):
        
        self.correction_model = correction_model      # çº é”™LLMæ¨¡å‹
        self.memory_enabled = memory_enabled          # æ˜¯å¦å¯ç”¨å†…å­˜
        self.max_correction_rounds = max_correction_rounds  # æœ€å¤§çº é”™è½®æ•°
        self.custom_settings = custom_settings or {}
    
    @classmethod
    def load_from_file(cls, config_path: str) -> "FormulaCorrectionConfig":
        """ä»é…ç½®æ–‡ä»¶åŠ è½½é…ç½®"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
            return cls(**config_data)
        except Exception as e:
            logger.warning(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            return cls()


class FormulaCorrectionAgent(BaseGraph):
    """å…¬å¼çº é”™æ™ºèƒ½ä½“
    
    åŠŸèƒ½ï¼š
    1. æå–åˆ†ææ–‡æ¡£ä¸­çš„æ‰€æœ‰ç‹¬è¡Œå…¬å¼
    2. ä½¿ç”¨OCRæ–‡æ¡£ä½œä¸ºå‚è€ƒï¼ŒæŸ¥æ‰¾åŸå§‹å…¬å¼
    3. é€šè¿‡LLMåˆ†æå’Œçº é”™å…¬å¼
    4. åº”ç”¨çº é”™åˆ°åˆ†ææ–‡æ¡£
    """
    
    def __init__(self,
                 config: Optional[FormulaCorrectionConfig] = None,
                 config_path: Optional[str] = None,
                 **kwargs):
        
        super().__init__(**kwargs)
        
        # åŠ è½½é…ç½®
        if config_path:
            self.config = FormulaCorrectionConfig.load_from_file(config_path)
        elif config:
            self.config = config
        else:
            self.config = FormulaCorrectionConfig()
        
        logger.info(f"åˆå§‹åŒ–å…¬å¼çº é”™æ™ºèƒ½ä½“")
        logger.info(f"çº é”™æ¨¡å‹: {self.config.correction_model}")
        
        # åˆ›å»ºçº é”™LLM
        self.correction_llm = get_llm(self.config.correction_model)
        
        # è®¾ç½®å†…å­˜ç®¡ç†
        self.memory = MemorySaver() if self.config.memory_enabled else None
        
        # å·¥å…·å°†åœ¨è¿è¡Œæ—¶åˆ›å»º
        self.formula_extractor = None
        self.ocr_loader = None
        self.text_editor = None
        self.llm_with_tools = None
        self.tool_node = None
        
        # æ„å»ºå›¾ï¼ˆå°†åœ¨çº é”™æ—¶åŠ¨æ€å®Œæˆï¼‰
        self.agent = None
        
        logger.info("å…¬å¼çº é”™æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
    
    def _build_graph_with_tools(self, tools: List[Any]) -> None:
        """ä½¿ç”¨å·¥å…·æ„å»ºLangGraphå·¥ä½œæµ"""
        graph = StateGraph(FormulaCorrectionState)
        
        # æ·»åŠ èŠ‚ç‚¹
        graph.add_node("initialize", self._initialize_node)
        graph.add_node("extract_formulas", self._extract_formulas_node)
        graph.add_node("load_ocr_reference", self._load_ocr_reference_node)
        graph.add_node("correction_analysis", self._correction_analysis_node)
        graph.add_node("finalize", self._finalize_node)
        
        # æ·»åŠ å·¥å…·èŠ‚ç‚¹
        self.tool_node = ToolNode(tools)
        graph.add_node("call_tools", self._call_tools_node)
        
        # æ„å»ºå·¥ä½œæµ
        graph.add_edge(START, "initialize")
        graph.add_edge("initialize", "extract_formulas")
        graph.add_edge("extract_formulas", "load_ocr_reference")
        graph.add_edge("load_ocr_reference", "correction_analysis")
        
        # çº é”™åˆ†æçš„æ¡ä»¶åˆ†æ”¯
        graph.add_conditional_edges(
            "correction_analysis",
            self._should_continue_correction,
            {
                "call_tools": "call_tools",      # è°ƒç”¨å·¥å…·
                "continue": "correction_analysis", # ç»§ç»­åˆ†æ
                "finalize": "finalize",          # å®Œæˆçº é”™
            }
        )
        
        # å·¥å…·è°ƒç”¨åå›åˆ°åˆ†æèŠ‚ç‚¹
        graph.add_edge("call_tools", "correction_analysis")
        graph.add_edge("finalize", END)
        
        # ç¼–è¯‘å›¾
        try:
            self.agent = graph.compile(checkpointer=self.memory)
            logger.info("âœ… å…¬å¼çº é”™LangGraphå›¾ç¼–è¯‘æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ LangGraphå›¾ç¼–è¯‘å¤±è´¥: {e}")
            raise
    
    def _initialize_node(self, state: FormulaCorrectionState) -> Dict[str, Any]:
        """åˆå§‹åŒ–èŠ‚ç‚¹"""
        logger.info("ğŸš€ å¼€å§‹å…¬å¼çº é”™æµç¨‹")
        logger.info(f"åˆ†ææ–‡æ¡£: {state['analysis_file_path']}")
        logger.info(f"OCRå‚è€ƒæ–‡æ¡£: {state['ocr_file_path']}")
        
        return {
            "current_step": "initialized",
            "is_complete": False,
            "messages": []
        }
    
    def _extract_formulas_node(self, state: FormulaCorrectionState) -> Dict[str, Any]:
        """æå–å…¬å¼èŠ‚ç‚¹"""
        logger.info("ğŸ“ å¼€å§‹æå–åˆ†ææ–‡æ¡£ä¸­çš„å…¬å¼")
        
        try:
            # ä½¿ç”¨å…¬å¼æå–å·¥å…·
            formula_result = self.formula_extractor._run(
                markdown_text=state["analysis_content"]
            )
            
            # è§£æç»“æœ
            try:
                formula_data = json.loads(formula_result)
                extracted_formulas = formula_data.get("formulas", [])
                logger.info(f"âœ… æå–åˆ° {len(extracted_formulas)} ä¸ªå…¬å¼")
                
            except json.JSONDecodeError:
                logger.error("å…¬å¼æå–ç»“æœè§£æå¤±è´¥")
                extracted_formulas = []
            
            return {
                "extracted_formulas": extracted_formulas,
                "current_step": "formulas_extracted",
                "messages": [SystemMessage(content=f"ä»åˆ†ææ–‡æ¡£ä¸­æå–åˆ° {len(extracted_formulas)} ä¸ªç‹¬è¡Œå…¬å¼")]
            }
            
        except Exception as e:
            logger.error(f"å…¬å¼æå–å¤±è´¥: {e}")
            return {
                "extracted_formulas": [],
                "current_step": "formula_extraction_failed",
                "messages": [SystemMessage(content=f"å…¬å¼æå–å¤±è´¥: {str(e)}")]
            }
    
    def _load_ocr_reference_node(self, state: FormulaCorrectionState) -> Dict[str, Any]:
        """åŠ è½½OCRå‚è€ƒæ–‡æ¡£èŠ‚ç‚¹"""
        logger.info("ğŸ“– åŠ è½½OCRå‚è€ƒæ–‡æ¡£")
        
        try:
            # åŠ è½½OCRæ–‡æ¡£å¹¶åˆ›å»ºç´¢å¼•
            ocr_result = self.ocr_loader._run(
                ocr_file_path=state["ocr_file_path"]
            )
            
            logger.info("âœ… OCRå‚è€ƒæ–‡æ¡£åŠ è½½å®Œæˆ")
            
            return {
                "current_step": "ocr_loaded",
                "messages": [SystemMessage(content="OCRå‚è€ƒæ–‡æ¡£å·²åŠ è½½å¹¶å»ºç«‹ç´¢å¼•ï¼Œå¯ä»¥è¿›è¡Œå…¬å¼å¯¹æ¯”å’Œçº é”™")]
            }
            
        except Exception as e:
            logger.error(f"OCRæ–‡æ¡£åŠ è½½å¤±è´¥: {e}")
            return {
                "current_step": "ocr_loading_failed",
                "messages": [SystemMessage(content=f"OCRæ–‡æ¡£åŠ è½½å¤±è´¥: {str(e)}")]
            }
    
    def _correction_analysis_node(self, state: FormulaCorrectionState) -> Dict[str, Any]:
        """çº é”™åˆ†æèŠ‚ç‚¹"""
        logger.info("ğŸ” å¼€å§‹å…¬å¼çº é”™åˆ†æ")
        
        messages = state["messages"]
        
        try:
            # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¿›å…¥çº é”™åˆ†æï¼Œåˆ›å»ºåˆå§‹æç¤º
            if state.get("current_step") == "ocr_loaded":
                correction_prompt = self._generate_correction_prompt(state)
                messages.append(SystemMessage(content=correction_prompt))
            
            # ç¡®ä¿llm_with_toolså·²åˆå§‹åŒ–
            if self.llm_with_tools is None:
                logger.error("âŒ LLM with tools not initialized")
                return {"messages": [AIMessage(content="LLMå·¥å…·æœªåˆå§‹åŒ–")]}
            
            # LLMåˆ†æå’Œçº é”™
            response = self.llm_with_tools.invoke(messages)
            
            logger.info(f"ğŸ’¬ LLMçº é”™å“åº”: {type(response).__name__}")
            
            # æ£€æŸ¥å·¥å…·è°ƒç”¨
            tool_calls = getattr(response, 'tool_calls', None)
            if tool_calls:
                logger.info(f"ğŸ”§ LLMå†³å®šè°ƒç”¨ {len(tool_calls)} ä¸ªå·¥å…·")
                for i, tool_call in enumerate(tool_calls):
                    try:
                        if hasattr(tool_call, 'get'):
                            tool_name = tool_call.get('name', 'unknown')
                            tool_args = tool_call.get('args', {})
                        else:
                            tool_name = getattr(tool_call, 'name', str(type(tool_call).__name__))
                            tool_args = getattr(tool_call, 'args', {})
                        
                        logger.info(f"  [{i+1}] å·¥å…·: {tool_name}")
                        logger.info(f"      å‚æ•°: {str(tool_args)[:200]}...")
                    except Exception as e:
                        logger.warning(f"      æ— æ³•è§£æå·¥å…·è°ƒç”¨ {i+1}: {e}")
                        logger.info(f"      åŸå§‹å·¥å…·è°ƒç”¨: {str(tool_call)[:200]}...")
            
            return {
                "messages": [response],
                "current_step": "correction_in_progress"
            }
            
        except Exception as e:
            logger.error(f"âŒ çº é”™åˆ†æå¤±è´¥: {e}")
            error_message = AIMessage(content=f"çº é”™åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            return {"messages": [error_message]}
    
    def _call_tools_node(self, state: FormulaCorrectionState) -> Dict[str, Any]:
        """å·¥å…·è°ƒç”¨èŠ‚ç‚¹ï¼ˆå¸¦æ—¥å¿—ï¼‰"""
        logger.info("ğŸ”§ æ‰§è¡Œå·¥å…·è°ƒç”¨...")
        
        messages = state["messages"]
        if messages:
            last_message = messages[-1]
            tool_calls = getattr(last_message, 'tool_calls', None)
            if tool_calls:
                logger.info(f"å‡†å¤‡æ‰§è¡Œ {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
        
        # æ‰§è¡Œå·¥å…·è°ƒç”¨
        try:
            result = self.tool_node.invoke(state)
            new_messages = result.get("messages", [])
            
            logger.info(f"å·¥å…·æ‰§è¡Œå®Œæˆï¼Œè¿”å› {len(new_messages)} æ¡æ¶ˆæ¯")
            
            # æ‰“å°å·¥å…·ç»“æœ
            for i, msg in enumerate(new_messages):
                if isinstance(msg, ToolMessage):
                    tool_name = getattr(msg, 'name', 'unknown')
                    content_preview = str(msg.content)[:300] if msg.content else "<empty>"
                    logger.info(f"  å·¥å…· [{i+1}] {tool_name} ç»“æœ: {content_preview}...")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return {"messages": []}
    
    def _finalize_node(self, state: FormulaCorrectionState) -> Dict[str, Any]:
        """å®Œæˆçº é”™èŠ‚ç‚¹"""
        logger.info("âœ… å®Œæˆå…¬å¼çº é”™æµç¨‹")
        
        # ä»æ¶ˆæ¯å†å²ä¸­æå–æœ€ç»ˆçš„çº é”™å†…å®¹
        messages = state["messages"]
        corrected_content = state["analysis_content"]  # é»˜è®¤ä½¿ç”¨åŸå†…å®¹
        corrections_applied = []
        
        # æŸ¥æ‰¾æ–‡æœ¬ç¼–è¾‘å·¥å…·çš„ä½¿ç”¨è®°å½•
        for message in messages:
            if isinstance(message, ToolMessage):
                if "text_editor" in getattr(message, 'name', ''):
                    try:
                        tool_result = json.loads(message.content)
                        if tool_result.get("success") and tool_result.get("edited_content"):
                            corrected_content = tool_result["edited_content"]
                            corrections_applied.append({
                                "operation": tool_result.get("operation", "unknown"),
                                "affected_lines": tool_result.get("affected_lines", "unknown"),
                                "message": tool_result.get("message", "")
                            })
                    except json.JSONDecodeError:
                        pass
        
        logger.info(f"åº”ç”¨äº† {len(corrections_applied)} ä¸ªçº é”™æ“ä½œ")
        
        return {
            "corrected_content": corrected_content,
            "corrections_applied": corrections_applied,
            "current_step": "completed",
            "is_complete": True
        }
    
    def _should_continue_correction(self, state: FormulaCorrectionState) -> str:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­çº é”™"""
        messages = state["messages"]
        
        logger.info(f"ğŸ”„ çº é”™æ§åˆ¶æµ: æ£€æŸ¥ {len(messages)} æ¡æ¶ˆæ¯")
        
        if messages:
            last_message = messages[-1]
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯AIæ¶ˆæ¯å¹¶ä¸”åŒ…å«å·¥å…·è°ƒç”¨
            if isinstance(last_message, AIMessage):
                tool_calls = getattr(last_message, 'tool_calls', None)
                if tool_calls:
                    logger.info(f"ğŸ”§ æ£€æµ‹åˆ° {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨ â†’ call_tools")
                    return "call_tools"
                
                # æ£€æŸ¥æ˜¯å¦è¡¨ç¤ºçº é”™å®Œæˆ
                content = last_message.content
                if isinstance(content, str):
                    content_lower = content.lower()
                    completion_keywords = [
                        "çº é”™å®Œæˆ", "correction complete", "å®Œæˆçº é”™",
                        "çº é”™ç»“æŸ", "correction finished", "ä¿®å¤å®Œæˆ",
                        "å…¬å¼å·²ä¿®å¤", "formulas corrected", "æ‰€æœ‰é”™è¯¯å·²ä¿®å¤"
                    ]
                    if any(keyword in content_lower for keyword in completion_keywords):
                        logger.info(f"âœ… LLMè¡¨ç¤ºçº é”™å®Œæˆ â†’ finalize")
                        return "finalize"
            
            # å¦‚æœæ˜¯å·¥å…·æ¶ˆæ¯ï¼Œç»§ç»­å¤„ç†
            elif isinstance(last_message, ToolMessage):
                logger.info(f"ğŸ”§ æ”¶åˆ°å·¥å…·ç»“æœ â†’ continue")
                return "continue"
        
        # é˜²æ­¢æ— é™å¾ªç¯
        if len(messages) > 20:
            logger.warning(f"âš ï¸ æ¶ˆæ¯æ•°é‡è¶…è¿‡é™åˆ¶ ({len(messages)}) â†’ finalize")
            return "finalize"
        
        # ç»Ÿè®¡å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯
        tool_call_count = 0
        for msg in messages:
            if isinstance(msg, AIMessage):
                tool_calls = getattr(msg, 'tool_calls', None)
                if tool_calls:
                    tool_call_count += len(tool_calls)
        
        if tool_call_count >= 8:  # é™åˆ¶æœ€å¤š8æ¬¡å·¥å…·è°ƒç”¨
            logger.warning(f"âš ï¸ å·¥å…·è°ƒç”¨æ¬¡æ•°è¶…è¿‡é™åˆ¶ ({tool_call_count}) â†’ finalize")
            return "finalize"
        
        # é»˜è®¤ç»§ç»­çº é”™
        logger.info(f"ğŸ”„ ç»§ç»­çº é”™ â†’ continue")
        return "continue"
    
    def _generate_correction_prompt(self, state: FormulaCorrectionState) -> str:
        """ç”Ÿæˆçº é”™æç¤ºè¯"""
        extracted_formulas = state.get("extracted_formulas", [])
        formula_count = len(extracted_formulas)
        
        # æ„å»ºå…¬å¼åˆ—è¡¨
        formula_list = ""
        if extracted_formulas:
            formula_list = "\n".join([
                f"ç¬¬{formula['start_line']}è¡Œ: {formula['formula']}"
                for formula in extracted_formulas[:10]  # åªæ˜¾ç¤ºå‰10ä¸ª
            ])
            if formula_count > 10:
                formula_list += f"\n... è¿˜æœ‰ {formula_count - 10} ä¸ªå…¬å¼"
        
        return f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡å…¬å¼çº é”™ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä¿®å¤åˆ†ææ–‡æ¡£ä¸­çš„å…¬å¼é”™è¯¯ã€‚

**é‡è¦è¯´æ˜:**
- OCRå‚è€ƒæ–‡æ¡£è·¯å¾„: {state['ocr_file_path']}
- åˆ†ææ–‡æ¡£è·¯å¾„: {state['analysis_file_path']}

**å¯ç”¨å·¥å…·:**
1. `ocr_document_loader`: æŸ¥è¯¢OCRåŸæ–‡æ¡£ä¸­çš„åŸå§‹å…¬å¼å†…å®¹
   - å‚æ•°: ocr_file_path="{state['ocr_file_path']}", query="ä½ çš„æŸ¥è¯¢å†…å®¹"
   - å½“éœ€è¦æŸ¥æ‰¾åŸå§‹å…¬å¼æ—¶ä½¿ç”¨ï¼Œæä¾›å…·ä½“çš„æŸ¥è¯¢å…³é”®è¯
   - ä¾‹å¦‚: æŸ¥è¯¢"mathcal"æˆ–"formula"æˆ–å…·ä½“çš„å…¬å¼ç¬¦å·

2. `text_editor`: ç¼–è¾‘åˆ†ææ–‡æ¡£å†…å®¹
   - å‚æ•°: content=å®Œæ•´çš„æ–‡æ¡£å†…å®¹, operation_type="replace", start_line=è¡Œå·, new_content="æ–°å†…å®¹"
   - ä½¿ç”¨replaceæ“ä½œä¿®å¤é”™è¯¯çš„å…¬å¼
   - ç¡®ä¿å…¬å¼æ ¼å¼æ­£ç¡®ï¼ˆä½¿ç”¨$$...$$åŒ…å›´ç‹¬è¡Œå…¬å¼ï¼‰
   - æ³¨æ„: contentå‚æ•°éœ€è¦ä¼ å…¥å®Œæ•´çš„æ–‡æ¡£å†…å®¹å­—ç¬¦ä¸²ï¼Œä¸æ˜¯æ–‡ä»¶è·¯å¾„

3. `math_formula_extractor_tool`: æå–æ–‡æ¡£ä¸­çš„æ•°å­¦å…¬å¼
   - å‚æ•°: file_path="æ–‡ä»¶è·¯å¾„" æˆ– markdown_text="æ–‡æ¡£å†…å®¹"

**å½“å‰ä»»åŠ¡:**
- åˆ†ææ–‡æ¡£: {state['analysis_file_path']}
- OCRå‚è€ƒæ–‡æ¡£: {state['ocr_file_path']}
- å·²æå–å…¬å¼æ•°é‡: {formula_count}

**æå–çš„å…¬å¼åˆ—è¡¨:**
{formula_list}

**å·¥ä½œæµç¨‹:**
1. é¦–å…ˆæ£€æŸ¥æå–çš„å…¬å¼æ˜¯å¦æœ‰æ˜æ˜¾é”™è¯¯ï¼ˆå¦‚æ ¼å¼é—®é¢˜ã€ç¬¦å·é”™è¯¯ç­‰ï¼‰
2. å¯¹äºå¯ç–‘çš„å…¬å¼ï¼Œä½¿ç”¨ocr_document_loaderæŸ¥è¯¢OCRåŸæ–‡æ¡£ä¸­çš„å¯¹åº”å†…å®¹
   - ä½¿ç”¨æ­£ç¡®çš„OCRæ–‡ä»¶è·¯å¾„: {state['ocr_file_path']}
3. å¯¹æ¯”åŸæ–‡æ¡£å’Œåˆ†ææ–‡æ¡£ä¸­çš„å…¬å¼ï¼Œè¯†åˆ«é”™è¯¯
4. å¦‚æœå‘ç°é”™è¯¯ï¼Œä½¿ç”¨text_editorä¿®å¤ï¼ˆä¼ å…¥å®Œæ•´æ–‡æ¡£å†…å®¹ï¼‰
5. å®Œæˆæ‰€æœ‰ä¿®å¤åï¼ŒæŠ¥å‘Š"çº é”™å®Œæˆ"

**æ³¨æ„äº‹é¡¹:**
- åªä¿®å¤æ˜ç¡®çš„å…¬å¼é”™è¯¯ï¼Œä¸è¦åšä¸å¿…è¦çš„ä¿®æ”¹
- ä¿æŒå…¬å¼çš„æ•°å­¦å«ä¹‰ä¸å˜
- ç¡®ä¿ä¿®å¤åçš„å…¬å¼æ ¼å¼æ­£ç¡®
- text_editorçš„contentå‚æ•°å¿…é¡»æ˜¯å®Œæ•´çš„æ–‡æ¡£å†…å®¹å­—ç¬¦ä¸²ï¼Œä¸æ˜¯æ–‡ä»¶è·¯å¾„
- ä½¿ç”¨æ­£ç¡®çš„OCRæ–‡ä»¶è·¯å¾„è¿›è¡ŒæŸ¥è¯¢

ç°åœ¨å¼€å§‹åˆ†æå’Œä¿®å¤å…¬å¼é”™è¯¯ã€‚å¦‚æœæ²¡æœ‰å‘ç°æ˜æ˜¾é”™è¯¯ï¼Œå¯ä»¥ç›´æ¥æŠ¥å‘Š"çº é”™å®Œæˆ"ã€‚
"""
    
    def correct_formulas(self, analysis_file_path: str, ocr_file_path: str, 
                        thread_id: str = "1") -> Dict[str, Any]:
        """
        æ‰§è¡Œå…¬å¼çº é”™çš„ä¸»å…¥å£
        
        Args:
            analysis_file_path: åˆ†ææ–‡æ¡£è·¯å¾„
            ocr_file_path: OCRåŸæ–‡æ¡£è·¯å¾„
            thread_id: çº¿ç¨‹ID
            
        Returns:
            Dict: å®Œæ•´çš„çº é”™ç»“æœ
        """
        logger.info(f"å¼€å§‹å…¬å¼çº é”™: {analysis_file_path}")
        
        try:
            # 1. è¯»å–æ–‡æ¡£å†…å®¹
            analysis_content = self._read_file(analysis_file_path)
            ocr_content = self._read_file(ocr_file_path)
            
            # 2. åˆ›å»ºå·¥å…·
            logger.info("åˆ›å»ºçº é”™å·¥å…·...")
            self.formula_extractor = create_math_formula_extractor_tool()
            self.ocr_loader = create_ocr_document_loader_tool()
            self.text_editor = create_text_editor_tool()
            
            tools = [self.formula_extractor, self.ocr_loader, self.text_editor]
            
            # 3. åˆ›å»ºå¸¦å·¥å…·çš„LLM
            self.llm_with_tools = self.correction_llm.bind_tools(tools)
            
            # 4. æ„å»ºå¹¶ç¼–è¯‘å›¾
            logger.info("æ„å»ºçº é”™å·¥ä½œæµ...")
            self._build_graph_with_tools(tools)
            
            # 5. åˆ›å»ºåˆå§‹çŠ¶æ€
            initial_state: FormulaCorrectionState = {
                "analysis_file_path": analysis_file_path,
                "ocr_file_path": ocr_file_path,
                "analysis_content": analysis_content,
                "ocr_content": ocr_content,
                
                "extracted_formulas": None,
                "messages": [],
                "corrected_content": None,
                "corrections_applied": None,
                
                "is_complete": False,
                "current_step": "starting"
            }
            
            # 6. é…ç½®LangGraph
            config = RunnableConfig(
                configurable={"thread_id": thread_id},
                recursion_limit=50
            )
            
            # 7. æ‰§è¡Œçº é”™
            logger.info("å¼€å§‹æ‰§è¡Œçº é”™å·¥ä½œæµ...")
            result = self.agent.invoke(initial_state, config)
            
            logger.info("å…¬å¼çº é”™å®Œæˆ")
            return result
            
        except Exception as e:
            logger.error(f"å…¬å¼çº é”™å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return {
                "error": f"çº é”™å¤±è´¥: {str(e)}",
                "analysis_file_path": analysis_file_path,
                "ocr_file_path": ocr_file_path
            }
    
    def _read_file(self, file_path: str) -> str:
        """è¯»å–æ–‡ä»¶å†…å®¹"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            logger.error(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            raise
    
    def save_corrected_document(self, result: Dict[str, Any], output_path: str) -> bool:
        """ä¿å­˜çº é”™åçš„æ–‡æ¡£"""
        try:
            corrected_content = result.get("corrected_content")
            if not corrected_content:
                logger.error("æ²¡æœ‰çº é”™å†…å®¹å¯ä¿å­˜")
                return False
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(corrected_content)
            
            logger.info(f"çº é”™æ–‡æ¡£å·²ä¿å­˜: {output_path}")
            return True
            
        except Exception as e:
            logger.error(f"ä¿å­˜çº é”™æ–‡æ¡£å¤±è´¥: {e}")
            return False
    
    def get_config(self) -> FormulaCorrectionConfig:
        """è·å–å½“å‰é…ç½®"""
        return self.config


# ä¾¿æ·å‡½æ•°
def create_formula_correction_agent(
    correction_model: str = "deepseek.DeepSeek_V3",
    **kwargs
) -> FormulaCorrectionAgent:
    """åˆ›å»ºå…¬å¼çº é”™agentçš„ä¾¿æ·å‡½æ•°"""
    config = FormulaCorrectionConfig(
        correction_model=correction_model,
        **kwargs
    )
    return FormulaCorrectionAgent(config=config)


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # åˆ›å»ºçº é”™agent
    agent = create_formula_correction_agent()
    print(f"å…¬å¼çº é”™Agentåˆ›å»ºæˆåŠŸ")
    print(f"é…ç½®: {agent.get_config().__dict__}")
    
    # æµ‹è¯•è·¯å¾„
    analysis_file = "/mnt/nfs_share/code/homesystem/data/paper_analyze/2412.03572/2412.03572_analysis.md"
    ocr_file = "/mnt/nfs_share/code/homesystem/data/paper_analyze/2412.03572/2412.03572_paddleocr.md"
    
    if os.path.exists(analysis_file) and os.path.exists(ocr_file):
        print(f"å¯ä»¥æ‰§è¡Œæµ‹è¯•: {analysis_file}")
    else:
        print("æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨")