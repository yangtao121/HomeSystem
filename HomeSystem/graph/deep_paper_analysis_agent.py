"""
æ·±åº¦è®ºæ–‡åˆ†æAgent

åŸºäºLangGraphçš„è®ºæ–‡æ·±åº¦åˆ†ææ™ºèƒ½ä½“ï¼Œä½¿ç”¨æ ‡å‡†å·¥å…·è°ƒç”¨æ¨¡å¼ï¼š
1. äº‘ç«¯LLMä¸»å¯¼åˆ†æï¼Œè‡ªåŠ¨å†³ç­–ä½•æ—¶è°ƒç”¨å›¾ç‰‡åˆ†æå·¥å…·
2. ç»“æ„åŒ–è¾“å‡ºç”Ÿæˆå®Œæ•´çš„åˆ†æç»“æœ
3. æ”¯æŒåŒè¯­åˆ†æç»“æœè¾“å‡º

é‡‡ç”¨æ ‡å‡†LangGraphå·¥å…·è°ƒç”¨æ¶æ„ï¼ŒLLMè‡ªä¸»å†³ç­–å·¥å…·ä½¿ç”¨ã€‚
"""

import json
from typing import Annotated, Any, Dict, List, Optional
from typing_extensions import TypedDict

from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from langchain_core.runnables import RunnableConfig
from langchain_core.messages import AIMessage, SystemMessage, ToolMessage, BaseMessage
from loguru import logger

from .base_graph import BaseGraph
from .llm_factory import get_llm
from .tool.image_analysis_tool import create_image_analysis_tool
from .parser.paper_folder_parser import create_paper_folder_parser
from .formatter.markdown_formatter import create_markdown_formatter


class DeepPaperAnalysisState(TypedDict):
    """æ·±åº¦è®ºæ–‡åˆ†æçŠ¶æ€"""
    # è¾“å…¥æ•°æ®
    base_folder_path: str                           # è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„
    paper_text: str                                 # è®ºæ–‡markdownæ–‡æœ¬
    available_images: List[str]                     # å¯ç”¨å›¾ç‰‡åˆ—è¡¨
    image_mappings: Dict[str, str]                  # å›¾ç‰‡è·¯å¾„æ˜ å°„
    
    # LangGraphæ¶ˆæ¯å†å²
    messages: Annotated[list, add_messages]         # å¯¹è¯å†å²
    
    # ç®€åŒ–çš„åˆ†æç»“æœ
    chinese_analysis: Optional[str]                 # ä¸­æ–‡åˆ†æç»“æœ
    
    # æ‰§è¡ŒçŠ¶æ€
    is_complete: bool                               # æ˜¯å¦å®Œæˆåˆ†æ


class DeepPaperAnalysisConfig:
    """æ·±åº¦è®ºæ–‡åˆ†æé…ç½®ç±»"""
    
    def __init__(self,
                 analysis_model: str = "deepseek.DeepSeek_V3",
                 vision_model: str = "ollama.llava", 
                 memory_enabled: bool = True,
                 custom_settings: Optional[Dict[str, Any]] = None):
        
        self.analysis_model = analysis_model          # ä¸»åˆ†æLLM
        self.vision_model = vision_model              # å›¾ç‰‡ç†è§£VLM
        self.memory_enabled = memory_enabled
        self.custom_settings = custom_settings or {}
    
    @classmethod
    def load_from_file(cls, config_path: str) -> "DeepPaperAnalysisConfig":
        """ä»é…ç½®æ–‡ä»¶åŠ è½½é…ç½®"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
            return cls(**config_data)
        except Exception as e:
            logger.warning(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            return cls()


class DeepPaperAnalysisAgent(BaseGraph):
    """æ·±åº¦è®ºæ–‡åˆ†ææ™ºèƒ½ä½“
    
    åŠŸèƒ½ï¼š
    1. ä½¿ç”¨æ ‡å‡†LangGraphå·¥å…·è°ƒç”¨æ¨¡å¼
    2. äº‘ç«¯LLMè‡ªä¸»å†³ç­–å·¥å…·ä½¿ç”¨
    3. ç»“æ„åŒ–è¾“å‡ºå’ŒåŒè¯­æ”¯æŒ
    """
    
    def __init__(self,
                 config: Optional[DeepPaperAnalysisConfig] = None,
                 config_path: Optional[str] = None,
                 **kwargs):
        
        super().__init__(**kwargs)
        
        # åŠ è½½é…ç½®
        if config_path:
            self.config = DeepPaperAnalysisConfig.load_from_file(config_path)
        elif config:
            self.config = config
        else:
            self.config = DeepPaperAnalysisConfig()
        
        logger.info(f"åˆå§‹åŒ–æ·±åº¦è®ºæ–‡åˆ†ææ™ºèƒ½ä½“")
        logger.info(f"åˆ†ææ¨¡å‹: {self.config.analysis_model}")
        logger.info(f"è§†è§‰æ¨¡å‹: {self.config.vision_model}")
        
        # åˆ›å»ºä¸»åˆ†æLLM
        self.analysis_llm = get_llm(self.config.analysis_model)
        
        # ç§»é™¤äº†ç»“æ„åŒ–è¾“å‡ºåŠŸèƒ½ï¼Œç®€åŒ–ä¸ºç›´æ¥æ–‡æœ¬è¾“å‡º
        
        # è®¾ç½®å†…å­˜ç®¡ç†
        self.memory = MemorySaver() if self.config.memory_enabled else None
        
        # å›¾ç‰‡åˆ†æå·¥å…·å°†åœ¨è¿è¡Œæ—¶åˆ›å»º
        self.image_tool = None
        self.llm_with_tools = None
        self.tool_node = None
        
        # æ„å»ºå›¾ï¼ˆå°†åœ¨åˆ†ææ—¶åŠ¨æ€å®Œæˆï¼‰
        self._graph_template = None
        self.agent = None
        
        logger.info("æ·±åº¦è®ºæ–‡åˆ†ææ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
    
    def _build_graph_with_tools(self, image_tool) -> None:
        """ä½¿ç”¨å·¥å…·æ„å»ºç®€åŒ–çš„LangGraphå·¥ä½œæµ"""
        graph = StateGraph(DeepPaperAnalysisState)
        
        # æ·»åŠ èŠ‚ç‚¹
        graph.add_node("initialize", self._initialize_node)
        graph.add_node("analysis_with_tools", self._analysis_with_tools_node)
        # æ·»åŠ  tool_node
        self.tool_node = ToolNode([image_tool])
        graph.add_node("call_tools", self.tool_node)
        graph.add_node("chinese_analysis", self._chinese_analysis_node)
        
        # æ„å»ºç®€åŒ–æµç¨‹
        graph.add_edge(START, "initialize")
        graph.add_edge("initialize", "analysis_with_tools")
        
        # åˆ†æå·¥å…·è°ƒç”¨çš„æ¡ä»¶åˆ†æ”¯
        graph.add_conditional_edges(
            "analysis_with_tools",
            self._should_continue_analysis,
            {
                "call_tools": "call_tools",  # è°ƒç”¨å·¥å…·
                "continue": "analysis_with_tools",  # ç»§ç»­åˆ†æ
                "chinese_analysis": "chinese_analysis",  # è¿›å…¥ä¸­æ–‡åˆ†æ
            }
        )
        
        # å·¥å…·è°ƒç”¨åå›åˆ°åˆ†æèŠ‚ç‚¹
        graph.add_edge("call_tools", "analysis_with_tools")
        
        # ä¸­æ–‡åˆ†æç»“æŸ
        graph.add_edge("chinese_analysis", END)
        
        # ç¼–è¯‘å›¾
        try:
            self.agent = graph.compile(checkpointer=self.memory)
            logger.info("âœ… LangGraph å›¾ç¼–è¯‘æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ LangGraph å›¾ç¼–è¯‘å¤±è´¥: {e}")
            raise
    
    def _initialize_node(self, state: DeepPaperAnalysisState) -> Dict[str, Any]:
        """åˆå§‹åŒ–èŠ‚ç‚¹"""
        logger.info("âœ… å·¥å…·å·²åœ¨åˆ†æå¼€å§‹å‰åˆå§‹åŒ–")
        
        # åˆ›å»ºåˆå§‹åˆ†ææç¤º
        initial_prompt = self._generate_initial_analysis_prompt(state)
        
        return {
            "messages": [SystemMessage(content=initial_prompt)],
            "is_complete": False
        }
    
    def _analysis_with_tools_node(self, state: DeepPaperAnalysisState) -> Dict[str, Any]:
        """å¸¦å·¥å…·è°ƒç”¨çš„åˆ†æèŠ‚ç‚¹ - ä½¿ç”¨æ ‡å‡† LangGraph æ¨¡å¼"""
        logger.info("å¼€å§‹LLMåˆ†æ...")
        
        messages = state["messages"]
        
        try:
            # ç¡®ä¿llm_with_toolså·²åˆå§‹åŒ–
            if self.llm_with_tools is None:
                logger.error("âŒ LLM with tools not initialized")
                return {"messages": [AIMessage(content="LLMå·¥å…·æœªåˆå§‹åŒ–")]}
            
            # æ˜¾ç¤ºè¾“å…¥æ¶ˆæ¯çš„è¯¦ç»†ä¿¡æ¯
            logger.info(f"ğŸ“¤ å‘é€æ¶ˆæ¯ç»™ LLM:")
            logger.info(f"  - æ¶ˆæ¯æ•°é‡: {len(messages)}")
            for i, msg in enumerate(messages[-3:]):  # åªæ˜¾ç¤ºæœ€å3æ¡æ¶ˆæ¯
                msg_type = type(msg).__name__
                msg_preview = str(msg.content)[:100] if hasattr(msg, 'content') else str(msg)[:100]
                logger.info(f"  - æ¶ˆæ¯ {i}: {msg_type} - {msg_preview}...")
            
            # LLMè‡ªä¸»å†³ç­–å¹¶å¯èƒ½è°ƒç”¨å·¥å…·
            response = self.llm_with_tools.invoke(messages)
            
            # è¯¦ç»†æ£€æŸ¥å“åº”
            logger.info(f"ğŸ’¬ LLM å“åº”:")
            logger.info(f"  - å“åº”ç±»å‹: {type(response).__name__}")
            if hasattr(response, 'content'):
                content_preview = str(response.content)[:200] if response.content else "<empty>"
                logger.info(f"  - å†…å®¹é¢„è§ˆ: {content_preview}...")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            tool_calls = getattr(response, 'tool_calls', None)
            if tool_calls:
                logger.info(f"ğŸ”§ LLMå†³å®šè°ƒç”¨ {len(tool_calls)} ä¸ªå·¥å…·:")
                for i, tool_call in enumerate(tool_calls):
                    try:
                        if hasattr(tool_call, 'get'):
                            tool_name = tool_call.get('name', 'unknown')
                            tool_args = tool_call.get('args', {})
                        else:
                            # å¤„ç†ä¸åŒçš„ tool_call å¯¹è±¡ç±»å‹
                            tool_name = getattr(tool_call, 'name', str(tool_call))
                            tool_args = getattr(tool_call, 'args', {})
                        
                        logger.info(f"  [{i+1}] å·¥å…·: {tool_name}")
                        if isinstance(tool_args, dict):
                            for key, value in tool_args.items():
                                value_preview = str(value)[:100] if len(str(value)) > 100 else str(value)
                                logger.info(f"      {key}: {value_preview}")
                        else:
                            logger.info(f"      å‚æ•°: {tool_args}")
                    except Exception as e:
                        logger.warning(f"      æ— æ³•è§£æå·¥å…·è°ƒç”¨ {i+1}: {e}")
            else:
                logger.info("ğŸš« LLMæœªè°ƒç”¨ä»»ä½•å·¥å…·")
            
            return {"messages": [response]}
            
        except Exception as e:
            logger.error(f"âŒ åˆ†æèŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            error_message = AIMessage(content=f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            return {"messages": [error_message]}
    
    def _should_continue_analysis(self, state: DeepPaperAnalysisState) -> str:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­åˆ†ææˆ–è°ƒç”¨å·¥å…·"""
        messages = state["messages"]
        
        logger.info(f"ğŸ”„ åˆ†ææ§åˆ¶æµ: æ£€æŸ¥ {len(messages)} æ¡æ¶ˆæ¯")
        
        # æ£€æŸ¥æœ€åçš„æ¶ˆæ¯
        if messages:
            last_message = messages[-1]
            last_msg_type = type(last_message).__name__
            logger.info(f"  - æœ€åæ¶ˆæ¯ç±»å‹: {last_msg_type}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ AI æ¶ˆæ¯å¹¶ä¸”åŒ…å«å·¥å…·è°ƒç”¨
            if isinstance(last_message, AIMessage):
                # ä½¿ç”¨ getattr å®‰å…¨æ£€æŸ¥ tool_calls å±æ€§
                tool_calls = getattr(last_message, 'tool_calls', None)
                if tool_calls:
                    logger.info(f"ğŸ”§ æ£€æµ‹åˆ° {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨ â†’ call_tools")
                    return "call_tools"
                
                # æ£€æŸ¥æ˜¯å¦LLMè¡¨ç¤ºåˆ†æå®Œæˆ
                content = last_message.content
                if isinstance(content, str):
                    content_lower = content.lower()
                    completion_keywords = [
                        "åˆ†æå®Œæˆ", "analysis complete", "å®Œæˆåˆ†æ",
                        "åˆ†æç»“æŸ", "analysis finished", "ç»“æŸåˆ†æ",
                        "analysis is complete", "finished analyzing"
                    ]
                    if any(keyword in content_lower for keyword in completion_keywords):
                        logger.info(f"âœ… LLMè¡¨ç¤ºåˆ†æå®Œæˆ â†’ chinese_analysis")
                        return "chinese_analysis"
                    
                    # æ£€æŸ¥å†…å®¹é•¿åº¦ï¼Œå¦‚æœè¾ƒé•¿å¯èƒ½æ˜¯å®Œæ•´åˆ†æ
                    if len(content) > 2000:  # å†…å®¹è¾ƒé•¿ï¼Œå¯èƒ½å·²ç»å®Œæˆäº†åˆ†æ
                        logger.info(f"ğŸ“ å†…å®¹è¾ƒé•¿ ({len(content)} å­—ç¬¦)ï¼Œå¯èƒ½å·²å®Œæˆåˆ†æ â†’ chinese_analysis")
                        return "chinese_analysis"
            
            # å¦‚æœæ˜¯å·¥å…·æ¶ˆæ¯ï¼Œè®©LLMç»§ç»­å¤„ç†å·¥å…·ç»“æœ
            elif isinstance(last_message, ToolMessage):
                logger.info(f"ğŸ”§ æ”¶åˆ°å·¥å…·ç»“æœ â†’ continue")
                return "continue"
        
        # é˜²æ­¢æ— é™å¾ªç¯ï¼šæ£€æŸ¥æ¶ˆæ¯æ•°é‡
        if len(messages) > 15:  # å¢åŠ ä¸Šé™ï¼Œç»™æ›´å¤šæœºä¼šè¿›è¡Œå·¥å…·è°ƒç”¨
            logger.warning(f"âš ï¸ æ¶ˆæ¯æ•°é‡è¶…è¿‡é™åˆ¶ ({len(messages)}) â†’ chinese_analysis")
            return "chinese_analysis"
        
        # ç»Ÿè®¡å·¥å…·è°ƒç”¨æ¬¡æ•°
        tool_call_count = 0
        tool_message_count = 0
        for msg in messages:
            if isinstance(msg, AIMessage):
                tool_calls = getattr(msg, 'tool_calls', None)
                if tool_calls:
                    tool_call_count += len(tool_calls)
            elif isinstance(msg, ToolMessage):
                tool_message_count += 1
        
        logger.info(f"  - å·¥å…·è°ƒç”¨æ¬¡æ•°: {tool_call_count}, å·¥å…·å“åº”: {tool_message_count}")
        
        # å¦‚æœå·²ç»è¿›è¡Œäº†è¶³å¤Ÿçš„å·¥å…·è°ƒç”¨ï¼Œè€ƒè™‘ç»“æŸ
        if tool_call_count >= 3:  # å·²ç»è¿›è¡Œäº†å¤šæ¬¡å·¥å…·è°ƒç”¨
            logger.info(f"ğŸ”„ å·²è¿›è¡Œ {tool_call_count} æ¬¡å·¥å…·è°ƒç”¨ï¼Œè€ƒè™‘ç»“æŸåˆ†æ â†’ chinese_analysis")
            return "chinese_analysis"
        
        # é»˜è®¤ç»§ç»­åˆ†æ
        logger.info(f"ğŸ”„ ç»§ç»­åˆ†æ â†’ continue")
        return "continue"
    
    def _chinese_analysis_node(self, state: DeepPaperAnalysisState) -> Dict[str, Any]:
        """ä¸­æ–‡åˆ†æèŠ‚ç‚¹ - ç›´æ¥è¾“å‡ºä¸­æ–‡åˆ†æç»“æœ"""
        logger.info("å¼€å§‹ç”Ÿæˆä¸­æ–‡åˆ†æç»“æœ...")
        
        try:
            # å‡†å¤‡ä¸­æ–‡åˆ†æçš„æç¤ºè¯
            chinese_prompt = self._generate_chinese_analysis_prompt(state)
            
            # ä½¿ç”¨ä¸»åˆ†æLLMç›´æ¥ç”Ÿæˆä¸­æ–‡ç»“æœ
            response = self.analysis_llm.invoke(chinese_prompt)
            chinese_content = response.content if hasattr(response, 'content') else str(response)
            
            logger.info("ä¸­æ–‡åˆ†æç»“æœç”Ÿæˆå®Œæˆ")
            
            return {
                "chinese_analysis": chinese_content,
                "is_complete": True
            }
            
        except Exception as e:
            logger.error(f"ä¸­æ–‡åˆ†æå¤±è´¥: {e}")
            return {"messages": [AIMessage(content=f"ä¸­æ–‡åˆ†æå¤±è´¥: {str(e)}")]}
    
    # ç§»é™¤äº†ç¿»è¯‘ç›¸å…³çš„æ–¹æ³•
    
    # ç§»é™¤äº†ç¿»è¯‘èŠ‚ç‚¹ï¼Œç›´æ¥è¾“å‡ºä¸­æ–‡
    
    def _generate_initial_analysis_prompt(self, state: DeepPaperAnalysisState) -> str:
        """ç”Ÿæˆåˆå§‹åˆ†ææç¤ºè¯"""
        available_images = state.get('available_images', [])
        image_list = "\n".join([f"  - {img}" for img in available_images[:10]])  # æ˜¾ç¤ºå‰10ä¸ªå›¾ç‰‡
        if len(available_images) > 10:
            image_list += f"\n  ... and {len(available_images) - 10} more images"
        
        return f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡åˆ†æä¸“å®¶ã€‚ä½ æœ‰ä¸€ä¸ªå›¾ç‰‡åˆ†æå·¥å…·ï¼Œå¯ä»¥å¸®åŠ©ä½ ç†è§£è®ºæ–‡ä¸­çš„å›¾è¡¨ã€æ¶æ„å›¾å’Œå®éªŒç»“æœã€‚

**å¯ç”¨å·¥å…·:**
- `analyze_image`: ç”¨äºåˆ†æè®ºæ–‡ä¸­çš„ä»»ä½•å›¾ç‰‡/å›¾è¡¨/å›¾è¡¨/ç¤ºæ„å›¾
  - å½“ä½ éœ€è¦ç†è§£æ–‡æœ¬ä¸­å¼•ç”¨çš„è§†è§‰å†…å®¹æ—¶è°ƒç”¨æ­¤å·¥å…·
  - å§‹ç»ˆåˆ†æå…³é”®å›¾è¡¨ã€æ¶æ„å›¾ã€å®éªŒå›¾è¡¨å’Œé‡è¦è¡¨æ ¼
  - æä¾›å…·ä½“çš„åˆ†ææŸ¥è¯¢ï¼Œå¦‚"åˆ†æè¿™ä¸ªæ¶æ„å›¾å¹¶è¯†åˆ«ä¸»è¦ç»„ä»¶"æˆ–"ä»è¿™ä¸ªå®éªŒå›¾è¡¨ä¸­æå–æ€§èƒ½æŒ‡æ ‡"

**æœ¬è®ºæ–‡ä¸­å¯ç”¨çš„å›¾ç‰‡:**
{image_list}

**è®ºæ–‡å†…å®¹:**
{state['paper_text'][:15000]}...

**ä½ çš„ä»»åŠ¡:**
å¯¹è¿™ç¯‡å­¦æœ¯è®ºæ–‡è¿›è¡Œå…¨é¢åˆ†æã€‚**é‡è¦**: å½“ä½ é‡åˆ°å¯¹å›¾è¡¨ã€å›¾è¡¨ã€æ¶æ„å›¾æˆ–å®éªŒç»“æœçš„å¼•ç”¨æ—¶ï¼Œä½¿ç”¨å›¾ç‰‡åˆ†æå·¥å…·æ¥è·å¾—æ›´æ·±å…¥çš„è§è§£ã€‚

**åˆ†ææŒ‡å¯¼åŸåˆ™:**
1. **ç ”ç©¶ç›®æ ‡å’Œè´¡çŒ®**: è¯†åˆ«ä¸»è¦ç ”ç©¶ç›®æ ‡å’Œå…³é”®è´¡çŒ®
2. **æŠ€æœ¯æ–¹æ³•ä¸åˆ›æ–°**: åˆ†ææŠ€æœ¯æ–¹æ³•å’Œæ–°é¢–æ–¹é¢
3. **å®éªŒè®¾è®¡ä¸ç»“æœ**: æ£€æŸ¥å®éªŒè®¾ç½®å’Œæ€§èƒ½ç»“æœ
4. **è§†è§‰å†…å®¹åˆ†æ**: å¯¹äºä»»ä½•æåˆ°çš„å›¾è¡¨/å›¾è¡¨/ç¤ºæ„å›¾ï¼Œä½¿ç”¨å›¾ç‰‡åˆ†æå·¥å…·

**ä½•æ—¶ä½¿ç”¨å›¾ç‰‡åˆ†æå·¥å…·:**
- å½“æ–‡æœ¬æåˆ°"å›¾X"ã€"è¡¨Y"ã€"æ¶æ„"ã€"ç¤ºæ„å›¾"ç­‰æ—¶
- å½“åˆ†æå¯èƒ½æœ‰è§†è§‰è¡¨ç¤ºçš„å®éªŒç»“æœæ—¶
- å½“ç†è§£ç³»ç»Ÿæ¶æ„æˆ–æ¨¡å‹è®¾è®¡æ—¶
- å½“ä»å›¾è¡¨æˆ–æ€§èƒ½æ¯”è¾ƒä¸­æå–ç‰¹å®šæ•°æ®æ—¶

**å¦‚ä½•ä½¿ç”¨å·¥å…·:**
è°ƒç”¨ `analyze_image` æ—¶éœ€è¦:
- `analysis_query`: å¯¹ä½ è¦åˆ†æå†…å®¹çš„æ¸…æ™°ä¸­æ–‡æè¿°ï¼ˆå¦‚"åˆ†æè¿™ä¸ªç³»ç»Ÿæ¶æ„å¹¶è¯†åˆ«ä¸»è¦ç»„ä»¶"ï¼‰
- `image_path`: æ¥è‡ªå¯ç”¨å›¾ç‰‡åˆ—è¡¨çš„ç›¸å¯¹è·¯å¾„ï¼ˆå¦‚"imgs/img_in_image_box_253_178_967_593.jpg"ï¼‰

ç°åœ¨å¼€å§‹ä½ çš„åˆ†æã€‚è®°ä½ï¼Œæ¯å½“è§†è§‰å†…å®¹å¯ä»¥æä¾›é¢å¤–è§è§£æ—¶ï¼Œå°±ä½¿ç”¨å›¾ç‰‡åˆ†æå·¥å…·ã€‚

**æ³¨æ„**: è¯·ç”¨ä¸­æ–‡è¿›è¡Œæ‰€æœ‰åˆ†æå’Œè¯´æ˜ã€‚
"""
    
    def _generate_chinese_analysis_prompt(self, state: DeepPaperAnalysisState) -> str:
        """ç”Ÿæˆä¸­æ–‡åˆ†ææç¤ºè¯"""
        
        # æ”¶é›†æ‰€æœ‰åˆ†æä¿¡æ¯
        paper_text = state["paper_text"]
        messages = state["messages"]
        
        # æå–å›¾ç‰‡åˆ†æç»“æœ
        image_analysis_results = []
        tool_call_count = 0
        for msg in messages:
            if isinstance(msg, ToolMessage):
                image_analysis_results.append(msg.content)
            elif isinstance(msg, AIMessage):
                tool_calls = getattr(msg, 'tool_calls', None)
                if tool_calls:
                    tool_call_count += len(tool_calls)
        
        image_insights = "\n\n".join(image_analysis_results) if image_analysis_results else "æœªè¿›è¡Œå›¾ç‰‡åˆ†æ"
        
        logger.info(f"ä¸­æ–‡åˆ†æ: å‘ç° {tool_call_count} æ¬¡å·¥å…·è°ƒç”¨, {len(image_analysis_results)} ä¸ªå›¾ç‰‡åˆ†æç»“æœ")
        
        return f"""
è¯·åŸºäºä¹‹å‰çš„åˆ†æå’Œå›¾ç‰‡ç†è§£ï¼Œç”¨ä¸­æ–‡ç”Ÿæˆè¿™ç¯‡è®ºæ–‡çš„å…¨é¢åˆ†ææŠ¥å‘Šã€‚

**è®ºæ–‡å†…å®¹:**
{paper_text[:15000]}

**å›¾ç‰‡åˆ†æç»“æœ:**
{image_insights}

**è¦æ±‚:**
è¯·ç”¨ä¸­æ–‡æä¾›è¯¦ç»†çš„åˆ†æï¼ŒåŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼š

# è®ºæ–‡æ·±åº¦åˆ†ææŠ¥å‘Š

## 1. ç ”ç©¶ç›®æ ‡ä¸åŠ¨æœº
- è®ºæ–‡è¦è§£å†³çš„ä¸»è¦é—®é¢˜
- ç ”ç©¶åŠ¨æœºå’Œé‡è¦æ€§
- ä¸ç°æœ‰ç ”ç©¶çš„å…³ç³»

## 2. ä¸»è¦è´¡çŒ®ä¸åˆ›æ–°ç‚¹
- åˆ—å‡º3-6ä¸ªå…³é”®è´¡çŒ®
- æ¯ä¸ªè´¡çŒ®çš„å…·ä½“æè¿°å’Œåˆ›æ–°æ€§
- ä¸ç°æœ‰æ–¹æ³•çš„åŒºåˆ«å’Œä¼˜åŠ¿

## 3. æŠ€æœ¯æ–¹æ³•åˆ†æ
- ä¸»è¦æŠ€æœ¯æ–¹æ³•å’Œç®—æ³•
- å…³é”®æŠ€æœ¯ç»†èŠ‚å’Œåˆ›æ–°ç‚¹
- æ–¹æ³•çš„ä¼˜åŠ¿å’Œé™åˆ¶

## 4. å®éªŒè®¾è®¡ä¸ç»“æœ
- å®éªŒè®¾ç½®å’Œæ•°æ®é›†
- ä¸»è¦æ€§èƒ½æŒ‡æ ‡å’Œç»“æœ
- ä¸åŸºå‡†æ–¹æ³•çš„æ¯”è¾ƒ

## 5. å›¾è¡¨åˆ†æä¸è§è§£
{'åŸºäºå›¾ç‰‡åˆ†æç»“æœçš„æ·±å…¥è§£è¯»' if image_analysis_results else 'æœªæä¾›å›¾è¡¨åˆ†æ'}

## 6. å…³é”®å‘ç°ä¸å¯ç¤º
- 3-5ä¸ªæœ€é‡è¦çš„å‘ç°
- å¯¹é¢†åŸŸçš„å½±å“å’Œæ„ä¹‰
- æœªæ¥ç ”ç©¶æ–¹å‘

## 7. æ•´ä½“è¯„ä»·ä¸æ€»ç»“
- è®ºæ–‡çš„æŠ€æœ¯è´¨é‡å’Œæ·±åº¦
- å®ç”¨ä»·å€¼å’Œåº”ç”¨å‰æ™¯
- ä¸è¶³ä¹‹å¤„å’Œæ”¹è¿›å»ºè®®

è¯·ç”¨ä¸“ä¸šã€å‡†ç¡®çš„ä¸­æ–‡è¿›è¡Œåˆ†æï¼Œç¡®ä¿å†…å®¹å…¨é¢ä¸”æ·±å…¥ã€‚
"""
    
    # ç§»é™¤äº†ç¿»è¯‘æç¤ºè¯ç”Ÿæˆæ–¹æ³•
    
    def analyze_paper_folder(self, folder_path: str, thread_id: str = "1") -> Dict[str, Any]:
        """
        åˆ†æè®ºæ–‡æ–‡ä»¶å¤¹çš„ä¸»å…¥å£
        
        Args:
            folder_path: è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„
            thread_id: çº¿ç¨‹ID
            
        Returns:
            Dict: å®Œæ•´çš„åˆ†æç»“æœçŠ¶æ€
        """
        logger.info(f"å¼€å§‹åˆ†æè®ºæ–‡æ–‡ä»¶å¤¹: {folder_path}")
        
        try:
            # 1. è§£ææ–‡ä»¶å¤¹å†…å®¹
            folder_data = self._parse_paper_folder(folder_path)
            
            # 2. åˆ›å»ºå›¾ç‰‡åˆ†æå·¥å…·
            logger.info("åˆ›å»ºå›¾ç‰‡åˆ†æå·¥å…·...")
            self.image_tool = create_image_analysis_tool(folder_path, self.config.vision_model)
            
            # 3. åˆ›å»ºå¸¦å·¥å…·çš„LLM
            self.llm_with_tools = self.analysis_llm.bind_tools([self.image_tool])
            
            # 4. æ„å»ºå¹¶ç¼–è¯‘å®Œæ•´çš„å›¾
            logger.info("æ„å»º LangGraph å·¥ä½œæµ...")
            self._build_graph_with_tools(self.image_tool)
            
            logger.info(f"âœ… åˆå§‹åŒ–å®Œæˆ:")
            logger.info(f"  - å›¾ç‰‡åˆ†æå·¥å…·: {self.image_tool.name}")
            logger.info(f"  - å¯åˆ†æå›¾ç‰‡æ•°é‡: {len(folder_data['available_images'])}")
            logger.info(f"  - è§†è§‰æ¨¡å‹: {self.config.vision_model}")
            
            # 5. åˆ›å»ºåˆå§‹çŠ¶æ€
            initial_state: DeepPaperAnalysisState = {
                "base_folder_path": folder_path,
                "paper_text": folder_data["paper_text"],
                "available_images": folder_data["available_images"],
                "image_mappings": folder_data["image_mappings"],
                
                "messages": [],
                "chinese_analysis": None,
                "is_complete": False
            }
            
            # 6. é…ç½®LangGraph
            config = RunnableConfig(
                configurable={"thread_id": thread_id},
                recursion_limit=100
            )
            
            # 7. æ‰§è¡Œåˆ†æ
            logger.info("å¼€å§‹æ‰§è¡ŒLangGraphå·¥ä½œæµ...")
            result = self.agent.invoke(initial_state, config)
            
            logger.info("è®ºæ–‡åˆ†æå®Œæˆ")
            return result
            
        except Exception as e:
            logger.error(f"è®ºæ–‡åˆ†æå¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return {
                "error": f"åˆ†æå¤±è´¥: {str(e)}",
                "folder_path": folder_path
            }
    
    def _parse_paper_folder(self, folder_path: str) -> Dict[str, Any]:
        """è§£æè®ºæ–‡æ–‡ä»¶å¤¹ç»“æ„"""
        # ä½¿ç”¨ä¸“é—¨çš„è§£æå™¨
        parser = create_paper_folder_parser(folder_path)
        
        # éªŒè¯æ–‡ä»¶å¤¹å®Œæ•´æ€§
        validation = parser.validate_folder_integrity()
        if not validation["is_valid"]:
            logger.warning(f"æ–‡ä»¶å¤¹éªŒè¯å¤±è´¥: {validation['issues']}")
        
        # è§£ææ–‡ä»¶å¤¹
        parse_result = parser.parse_folder()
        
        # æå–éœ€è¦çš„ä¿¡æ¯
        return {
            "paper_text": parse_result["paper_text"],
            "available_images": parse_result["available_images"],
            "image_mappings": parse_result["image_mappings"],
            "latex_formulas": parse_result["latex_formulas"],
            "image_references": parse_result["image_references"],
            "content_sections": parse_result["content_sections"]
        }
    
    def get_config(self) -> DeepPaperAnalysisConfig:
        """è·å–å½“å‰é…ç½®"""
        return self.config
    
    def generate_markdown_report(self, analysis_result: Dict[str, Any], output_path: Optional[str] = None) -> str:
        """
        ç”Ÿæˆmarkdownåˆ†ææŠ¥å‘Š
        
        Args:
            analysis_result: åˆ†æç»“æœçŠ¶æ€
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            str: markdownæŠ¥å‘Šå†…å®¹
        """
        logger.info("ç”Ÿæˆmarkdownåˆ†ææŠ¥å‘Š...")
        
        # åˆ›å»ºæ ¼å¼åŒ–å™¨ï¼ˆä½¿ç”¨ä¸­æ–‡ï¼‰
        formatter = create_markdown_formatter("zh")
        
        # ç”ŸæˆæŠ¥å‘Š
        report_content = formatter.format_analysis_report(analysis_result)
        
        # ä¿å­˜æ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šäº†è·¯å¾„ï¼‰
        if output_path:
            success = formatter.save_report(report_content, output_path)
            if success:
                logger.info(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
            else:
                logger.error("æŠ¥å‘Šä¿å­˜å¤±è´¥")
        
        return report_content
    
    def analyze_and_generate_report(self, folder_path: str, output_path: Optional[str] = None, thread_id: str = "1") -> tuple[Dict[str, Any], str]:
        """
        å®Œæ•´çš„åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆæµç¨‹
        
        Args:
            folder_path: è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„
            output_path: æŠ¥å‘Šè¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰
            thread_id: çº¿ç¨‹ID
            
        Returns:
            tuple: (åˆ†æç»“æœ, markdownæŠ¥å‘Šå†…å®¹)
        """
        logger.info(f"å¼€å§‹å®Œæ•´çš„è®ºæ–‡åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆæµç¨‹: {folder_path}")
        
        # æ‰§è¡Œåˆ†æ
        analysis_result = self.analyze_paper_folder(folder_path, thread_id)
        
        # ç”ŸæˆæŠ¥å‘Š
        report_content = self.generate_markdown_report(analysis_result, output_path)
        
        logger.info("å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæˆ")
        return analysis_result, report_content


# ä¾¿æ·å‡½æ•°
def create_deep_paper_analysis_agent(
    analysis_model: str = "deepseek.DeepSeek_V3",
    vision_model: str = "ollama.llava",
    **kwargs
) -> DeepPaperAnalysisAgent:
    """åˆ›å»ºæ·±åº¦è®ºæ–‡åˆ†æagentçš„ä¾¿æ·å‡½æ•°"""
    config = DeepPaperAnalysisConfig(
        analysis_model=analysis_model,
        vision_model=vision_model,
        **kwargs
    )
    return DeepPaperAnalysisAgent(config=config)


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # æµ‹è¯•agentåˆ›å»º
    agent = create_deep_paper_analysis_agent()
    print(f"æ·±åº¦è®ºæ–‡åˆ†æAgentåˆ›å»ºæˆåŠŸ")
    print(f"é…ç½®: {agent.get_config().__dict__}")