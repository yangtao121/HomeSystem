"""
ç»Ÿä¸€çš„è®ºæ–‡æ·±åº¦åˆ†ææœåŠ¡

æä¾›ç»Ÿä¸€çš„è®ºæ–‡æ·±åº¦åˆ†ææ¥å£ï¼Œæ›¿ä»£å„ä¸ªæ¨¡å—ä¸­çš„é‡å¤å®ç°
åŒ…å«å®Œæ•´çš„åˆ†ææµç¨‹ï¼šæ–‡ä»¶å‡†å¤‡ã€PDFä¸‹è½½ã€OCRå¤„ç†ã€æ·±åº¦åˆ†æ
"""

import os
import re
import time
import logging
from pathlib import Path
from typing import Dict, Any, Optional, Tuple

from loguru import logger

from HomeSystem.utility.arxiv.arxiv import ArxivData


class PaperAnalysisService:
    """ç»Ÿä¸€çš„è®ºæ–‡æ·±åº¦åˆ†ææœåŠ¡
    
    åŠŸèƒ½ï¼š
    1. è®ºæ–‡æ–‡ä»¶å¤¹å‡†å¤‡
    2. PDFä¸‹è½½å’ŒéªŒè¯
    3. OCRæ–‡æœ¬æå–
    4. æ·±åº¦åˆ†ææ‰§è¡Œ
    5. ç»“æœå¤„ç†å’Œä¿å­˜
    """
    
    def __init__(self, default_config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–åˆ†ææœåŠ¡
        
        Args:
            default_config: é»˜è®¤é…ç½®å‚æ•°
        """
        self.default_config = default_config or {
            'analysis_model': 'deepseek.DeepSeek_V3',
            'vision_model': 'ollama.Qwen2_5_VL_7B',
            'enable_video_analysis': False,
            'video_analysis_model': 'ollama.Qwen3_30B',
            'enable_user_prompt': False,  # ç”¨æˆ·æç¤ºè¯åŠŸèƒ½å¼€å…³ï¼ˆé»˜è®¤å…³é—­ï¼‰
            'user_prompt': None,  # ç”¨æˆ·è‡ªå®šä¹‰æç¤ºè¯
            'timeout': 600,
            # è¿œç¨‹OCRé…ç½®
            'enable_remote_ocr': False,
            'remote_ocr_endpoint': 'http://localhost:5001',
            'remote_ocr_timeout': 300
        }
        
        # åˆå§‹åŒ–æ—¶éªŒè¯é…ç½®
        self._validate_configuration()
    
    def _validate_configuration(self) -> None:
        """éªŒè¯æœåŠ¡é…ç½®"""
        try:
            if self.default_config.get('enable_video_analysis', False):
                logger.info("ğŸ”§ æ£€æµ‹åˆ°è§†é¢‘åˆ†æåŠŸèƒ½é…ç½®ï¼Œè¿›è¡Œåˆå§‹éªŒè¯...")
                video_model = self.default_config.get('video_analysis_model')
                if not video_model:
                    logger.warning("âš ï¸ è§†é¢‘åˆ†æå·²å¯ç”¨ä½†æœªæŒ‡å®šè§†é¢‘åˆ†ææ¨¡å‹ï¼Œå°†ä½¿ç”¨é»˜è®¤æ¨¡å‹ ollama.Qwen3_30B")
                    self.default_config['video_analysis_model'] = 'ollama.Qwen3_30B'
                else:
                    logger.info(f"âœ… è§†é¢‘åˆ†ææ¨¡å‹é…ç½®: {video_model}")
            else:
                logger.info("â„¹ï¸ è§†é¢‘åˆ†æåŠŸèƒ½æœªå¯ç”¨ï¼Œä½¿ç”¨æ ‡å‡†åˆ†ææ¨¡å¼")
        except Exception as e:
            logger.warning(f"âš ï¸ é…ç½®éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
    
    def perform_deep_analysis(
        self,
        arxiv_id: str,
        paper_folder_path: str,
        config: Optional[Dict[str, Any]] = None,
        paper_data: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„æ·±åº¦è®ºæ–‡åˆ†ææµç¨‹
        
        Args:
            arxiv_id: ArXivè®ºæ–‡ID
            paper_folder_path: è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„
            config: åˆ†æé…ç½®ï¼ˆå¯é€‰ï¼‰
            paper_data: è®ºæ–‡åŸºç¡€æ•°æ®ï¼ˆå¯é€‰ï¼Œç”¨äºPDFä¸‹è½½ï¼‰
            
        Returns:
            Dict: åˆ†æç»“æœ
                - success: bool, æ˜¯å¦æˆåŠŸ
                - analysis_result: str, åˆ†æå†…å®¹ï¼ˆæˆåŠŸæ—¶ï¼‰
                - analysis_file_path: str, åˆ†ææ–‡ä»¶è·¯å¾„ï¼ˆæˆåŠŸæ—¶ï¼‰
                - error: str, é”™è¯¯ä¿¡æ¯ï¼ˆå¤±è´¥æ—¶ï¼‰
        """
        try:
            logger.info(f"ğŸš€ å¼€å§‹è®ºæ–‡æ·±åº¦åˆ†ææµç¨‹: {arxiv_id}")
            
            # åˆå¹¶é…ç½®
            analysis_config = {**self.default_config, **(config or {})}
            
            # é…ç½®éªŒè¯å’ŒçŠ¶æ€æ—¥å¿—
            video_analysis_enabled = analysis_config.get('enable_video_analysis', False)
            if video_analysis_enabled:
                logger.info(f"ğŸ¥ è§†é¢‘åˆ†æåŠŸèƒ½å·²å¯ç”¨")
                logger.info(f"   - è§†é¢‘åˆ†ææ¨¡å‹: {analysis_config.get('video_analysis_model', 'ollama.Qwen3_30B')}")
                logger.info(f"   - åˆ†ææ¨¡å‹: {analysis_config.get('analysis_model')}")
                logger.info(f"   - è§†è§‰æ¨¡å‹: {analysis_config.get('vision_model')}")
            else:
                logger.info(f"ğŸ“ ä½¿ç”¨æ ‡å‡†åˆ†ææ¨¡å¼ (è§†é¢‘åˆ†ææœªå¯ç”¨)")
                logger.info(f"   - åˆ†ææ¨¡å‹: {analysis_config.get('analysis_model')}")
                logger.info(f"   - è§†è§‰æ¨¡å‹: {analysis_config.get('vision_model')}")
            
            # ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡è®ºæ–‡æ–‡ä»¶å¤¹
            folder_result = self._prepare_paper_folder(paper_folder_path, analysis_config)
            if not folder_result['success']:
                return folder_result
            
            if folder_result.get('video_analysis_enabled'):
                logger.info(f"âœ… è®ºæ–‡æ–‡ä»¶å¤¹å‡†å¤‡å®Œæˆ: {paper_folder_path} (åŒ…å«è§†é¢‘ç›®å½•)")
            else:
                logger.info(f"âœ… è®ºæ–‡æ–‡ä»¶å¤¹å‡†å¤‡å®Œæˆ: {paper_folder_path}")
            
            # ç¬¬äºŒæ­¥ï¼šä¸‹è½½è®ºæ–‡PDFï¼ˆå¦‚æœå°šæœªå­˜åœ¨ï¼‰
            pdf_result = self._ensure_paper_pdf(
                arxiv_id, 
                paper_folder_path, 
                paper_data
            )
            if not pdf_result['success']:
                return pdf_result
            
            logger.info(f"âœ… è®ºæ–‡PDFå‡†å¤‡å®Œæˆ: {arxiv_id}")
            
            # ç¬¬ä¸‰æ­¥ï¼šæ‰§è¡ŒOCRå¤„ç†ï¼ˆå¦‚æœå°šæœªå­˜åœ¨ï¼‰
            ocr_result = self._ensure_paper_ocr(arxiv_id, paper_folder_path, analysis_config)
            if not ocr_result['success']:
                return ocr_result
            
            logger.info(f"âœ… è®ºæ–‡OCRå¤„ç†å®Œæˆ: {arxiv_id}")
            
            # ç¬¬å››æ­¥ï¼šæ‰§è¡Œæ·±åº¦åˆ†æ
            analysis_result = self._execute_deep_analysis(
                arxiv_id, 
                paper_folder_path, 
                analysis_config
            )
            
            if analysis_result['success']:
                logger.info(f"âœ… æ·±åº¦åˆ†æå®Œæˆ: {arxiv_id}")
            else:
                logger.error(f"âŒ æ·±åº¦åˆ†æå¤±è´¥: {arxiv_id}")
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"ğŸ’¥ æ·±åº¦åˆ†ææµç¨‹å¼‚å¸¸ {arxiv_id}: {e}")
            return {
                'success': False,
                'error': f'æ·±åº¦åˆ†ææµç¨‹å¼‚å¸¸: {str(e)}'
            }
    
    def _prepare_paper_folder(self, paper_folder_path: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        å‡†å¤‡è®ºæ–‡åˆ†ææ–‡ä»¶å¤¹
        
        Args:
            paper_folder_path: è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„
            config: åˆ†æé…ç½®
            
        Returns:
            Dict: æ“ä½œç»“æœ
        """
        try:
            folder_path = Path(paper_folder_path)
            folder_path.mkdir(parents=True, exist_ok=True)
            
            logger.info(f"ğŸ“ è®ºæ–‡æ–‡ä»¶å¤¹å·²å‡†å¤‡: {folder_path}")
            
            # å¦‚æœå¯ç”¨è§†é¢‘åˆ†æï¼Œåˆ›å»ºvideoså­ç›®å½•
            if config.get('enable_video_analysis', False):
                videos_folder = folder_path / 'videos'
                videos_folder.mkdir(exist_ok=True)
                logger.info(f"ğŸ¥ è§†é¢‘æ–‡ä»¶å¤¹å·²å‡†å¤‡: {videos_folder}")
                
                return {
                    'success': True,
                    'folder_path': str(folder_path),
                    'videos_folder': str(videos_folder),
                    'video_analysis_enabled': True
                }
            else:
                return {
                    'success': True,
                    'folder_path': str(folder_path),
                    'video_analysis_enabled': False
                }
            
        except Exception as e:
            logger.error(f"âŒ å‡†å¤‡è®ºæ–‡æ–‡ä»¶å¤¹å¤±è´¥: {e}")
            return {
                'success': False,
                'error': f'å‡†å¤‡è®ºæ–‡æ–‡ä»¶å¤¹å¤±è´¥: {str(e)}'
            }
    
    def _ensure_paper_pdf(
        self,
        arxiv_id: str,
        paper_folder_path: str,
        paper_data: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ç¡®ä¿è®ºæ–‡PDFæ–‡ä»¶å­˜åœ¨
        
        Args:
            arxiv_id: ArXivè®ºæ–‡ID
            paper_folder_path: è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„
            paper_data: è®ºæ–‡åŸºç¡€æ•°æ®
            
        Returns:
            Dict: æ“ä½œç»“æœ
        """
        try:
            # æ£€æŸ¥PDFæ˜¯å¦å·²å­˜åœ¨
            pdf_path = os.path.join(paper_folder_path, f"{arxiv_id}.pdf")
            if os.path.exists(pdf_path) and os.path.getsize(pdf_path) > 0:
                logger.info(f"ğŸ“„ PDFæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {pdf_path}")
                return {
                    'success': True,
                    'pdf_path': pdf_path,
                    'skipped': True
                }
            
            # ä¸‹è½½PDF
            logger.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½PDF: {arxiv_id}")
            
            # æ„é€ ArxivDataå¯¹è±¡
            if paper_data:
                arxiv_data = ArxivData(paper_data)
            else:
                # ä½¿ç”¨æœ€å°å¿…è¦ä¿¡æ¯
                arxiv_data = ArxivData({
                    'title': '',
                    'link': f"https://arxiv.org/abs/{arxiv_id}",
                    'snippet': '',
                    'categories': '',
                    'arxiv_id': arxiv_id
                })
            
            # ä¸‹è½½PDFåˆ°æŒ‡å®šè·¯å¾„
            arxiv_data.downloadPdf(save_path=paper_folder_path)
            
            # æ£€æŸ¥ä¸‹è½½ç»“æœå¹¶é‡å‘½åä¸ºæ ‡å‡†æ ¼å¼
            pdf_files = [f for f in os.listdir(paper_folder_path) if f.endswith('.pdf')]
            if pdf_files:
                # é‡å‘½åä¸ºæ ‡å‡†æ ¼å¼
                actual_pdf_path = os.path.join(paper_folder_path, pdf_files[0])
                if actual_pdf_path != pdf_path and os.path.exists(actual_pdf_path):
                    os.rename(actual_pdf_path, pdf_path)
                    logger.info(f"ğŸ“ PDFé‡å‘½åä¸ºæ ‡å‡†æ ¼å¼: {pdf_path}")
            
            # éªŒè¯ä¸‹è½½ç»“æœ
            if os.path.exists(pdf_path) and os.path.getsize(pdf_path) > 0:
                logger.info(f"âœ… PDFä¸‹è½½æˆåŠŸ: {pdf_path}")
                return {
                    'success': True,
                    'pdf_path': pdf_path,
                    'downloaded': True
                }
            else:
                logger.error(f"âŒ PDFä¸‹è½½å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º: {pdf_path}")
                return {
                    'success': False,
                    'error': 'PDFä¸‹è½½å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º'
                }
                
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½PDFå¤±è´¥ {arxiv_id}: {e}")
            return {
                'success': False,
                'error': f'ä¸‹è½½PDFå¤±è´¥: {str(e)}'
            }
    
    def _ensure_paper_ocr(self, arxiv_id: str, paper_folder_path: str, config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        ç¡®ä¿è®ºæ–‡OCRå¤„ç†å®Œæˆ
        
        Args:
            arxiv_id: ArXivè®ºæ–‡ID
            paper_folder_path: è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„
            config: é…ç½®å‚æ•°ï¼ˆåŒ…å«OCRé…ç½®ï¼‰
            
        Returns:
            Dict: æ“ä½œç»“æœ
        """
        try:
            # æ£€æŸ¥OCRç»“æœæ˜¯å¦å·²å­˜åœ¨
            ocr_file = os.path.join(paper_folder_path, f"{arxiv_id}_paddleocr.md")
            if os.path.exists(ocr_file) and os.path.getsize(ocr_file) > 0:
                logger.info(f"ğŸ“ OCRæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†: {ocr_file}")
                return {
                    'success': True,
                    'ocr_file_path': ocr_file,
                    'skipped': True
                }
            
            # æ£€æŸ¥PDFæ–‡ä»¶
            pdf_path = os.path.join(paper_folder_path, f"{arxiv_id}.pdf")
            if not os.path.exists(pdf_path):
                logger.error(f"âŒ PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
                return {
                    'success': False,
                    'error': 'PDFæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡ŒOCR'
                }
            
            logger.info(f"ğŸ” å¼€å§‹OCRå¤„ç†: {pdf_path}")
            
            # åˆ›å»ºArxivDataå®ä¾‹å¹¶æ‰§è¡ŒOCR
            arxiv_data = ArxivData({
                'title': '',
                'link': f"https://arxiv.org/abs/{arxiv_id}",
                'snippet': '',
                'categories': '',
                'arxiv_id': arxiv_id
            })
            
            # ä»æ–‡ä»¶åŠ è½½PDF
            with open(pdf_path, 'rb') as f:
                arxiv_data.pdf = f.read()
            
            # è·å–OCRé…ç½®
            effective_config = {**self.default_config, **(config or {})}
            use_remote_ocr = effective_config.get('enable_remote_ocr', False)
            
            # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœä½¿ç”¨è¿œç¨‹OCRï¼‰
            if use_remote_ocr:
                remote_endpoint = effective_config.get('remote_ocr_endpoint', 'http://localhost:5001')
                remote_timeout = effective_config.get('remote_ocr_timeout', 300)
                remote_max_pages = effective_config.get('remote_ocr_max_pages', 25)
                os.environ['REMOTE_OCR_ENDPOINT'] = remote_endpoint
                os.environ['REMOTE_OCR_TIMEOUT'] = str(remote_timeout)
                os.environ['REMOTE_OCR_MAX_PAGES'] = str(remote_max_pages)
                logger.info(f"ğŸŒ ä½¿ç”¨è¿œç¨‹OCRæœåŠ¡: {remote_endpoint} (è¶…æ—¶: {remote_timeout}ç§’, æœ€å¤§é¡µæ•°: {remote_max_pages})")
            else:
                logger.info("ğŸ” ä½¿ç”¨æœ¬åœ°PaddleOCRå¤„ç†")
            
            # æ‰§è¡ŒOCRå¤„ç†
            ocr_result, status_info = arxiv_data.performOCR(
                use_paddleocr=True,
                use_remote_ocr=use_remote_ocr,
                auto_save=True,
                save_path=paper_folder_path
            )
            
            if ocr_result and len(ocr_result.strip()) > 0:
                logger.info(f"âœ… OCRå¤„ç†æˆåŠŸï¼Œç”Ÿæˆ {len(ocr_result)} å­—ç¬¦: {arxiv_id}")
                return {
                    'success': True,
                    'ocr_file_path': ocr_file,
                    'ocr_content': ocr_result,
                    'processed': True
                }
            else:
                logger.error(f"âŒ OCRå¤„ç†å¤±è´¥ï¼Œæœªç”Ÿæˆæœ‰æ•ˆå†…å®¹: {arxiv_id}")
                return {
                    'success': False,
                    'error': 'OCRå¤„ç†å¤±è´¥ï¼Œæœªç”Ÿæˆæœ‰æ•ˆå†…å®¹'
                }
                
        except Exception as e:
            logger.error(f"âŒ OCRå¤„ç†å¤±è´¥ {arxiv_id}: {e}")
            return {
                'success': False,
                'error': f'OCRå¤„ç†å¤±è´¥: {str(e)}'
            }
    
    def _execute_deep_analysis(
        self,
        arxiv_id: str,
        paper_folder_path: str,
        config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ·±åº¦åˆ†æ
        
        Args:
            arxiv_id: ArXivè®ºæ–‡ID
            paper_folder_path: è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„
            config: åˆ†æé…ç½®
            
        Returns:
            Dict: åˆ†æç»“æœ
        """
        try:
            logger.info(f"ğŸ¤– å¼€å§‹æ·±åº¦åˆ†æ: {arxiv_id}")
            
            # åŠ¨æ€å¯¼å…¥æ·±åº¦åˆ†ææ™ºèƒ½ä½“
            video_analysis_enabled = config.get('enable_video_analysis', False)
            try:
                if video_analysis_enabled:
                    from HomeSystem.graph.deep_paper_analysis_agent import create_video_enhanced_analysis_agent
                    logger.info("âœ… æˆåŠŸå¯¼å…¥è§†é¢‘å¢å¼ºè®ºæ–‡åˆ†ææ™ºèƒ½ä½“")
                    agent_creator = create_video_enhanced_analysis_agent
                    agent_type = "è§†é¢‘å¢å¼ºåˆ†ææ™ºèƒ½ä½“"
                else:
                    from HomeSystem.graph.deep_paper_analysis_agent import create_deep_paper_analysis_agent
                    logger.info("âœ… æˆåŠŸå¯¼å…¥æ·±åº¦è®ºæ–‡åˆ†ææ™ºèƒ½ä½“")
                    agent_creator = create_deep_paper_analysis_agent
                    agent_type = "æ·±åº¦åˆ†ææ™ºèƒ½ä½“"
            except Exception as import_error:
                logger.error(f"âŒ å¯¼å…¥è®ºæ–‡åˆ†ææ™ºèƒ½ä½“å¤±è´¥: {import_error}")
                return {
                    'success': False,
                    'error': f'å¯¼å…¥è®ºæ–‡åˆ†ææ™ºèƒ½ä½“å¤±è´¥: {str(import_error)}'
                }
            
            # åˆ›å»ºæ·±åº¦åˆ†ææ™ºèƒ½ä½“
            logger.info(f"ğŸ¤– åˆ›å»º{agent_type}...")
            
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨ç”¨æˆ·æç¤ºè¯
            enable_user_prompt = config.get('enable_user_prompt', False)
            user_prompt = config.get('user_prompt', None)
            
            if enable_user_prompt and user_prompt:
                logger.info(f"ğŸ“ å¯ç”¨ç”¨æˆ·æç¤ºè¯åŠŸèƒ½")
                logger.info(f"   - ç”¨æˆ·æç¤ºè¯é¢„è§ˆ: {user_prompt[:100]}..." if len(user_prompt) > 100 else f"   - ç”¨æˆ·æç¤ºè¯: {user_prompt}")
            
            if video_analysis_enabled:
                agent = agent_creator(
                    analysis_model=config['analysis_model'],
                    vision_model=config['vision_model'],
                    video_analysis_model=config.get('video_analysis_model', 'ollama.Qwen3_30B'),
                    enable_user_prompt=enable_user_prompt,
                    user_prompt=user_prompt
                )
                logger.info(f"âœ… {agent_type}åˆ›å»ºæˆåŠŸ (è§†é¢‘åˆ†ææ¨¡å‹: {config.get('video_analysis_model', 'ollama.Qwen3_30B')})")
            else:
                agent = agent_creator(
                    analysis_model=config['analysis_model'],
                    vision_model=config['vision_model'],
                    enable_user_prompt=enable_user_prompt,
                    user_prompt=user_prompt
                )
                logger.info(f"âœ… {agent_type}åˆ›å»ºæˆåŠŸ")
            
            # æ‰§è¡Œåˆ†æ
            # ä¼ é€’ç”¨æˆ·æç¤ºè¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if enable_user_prompt and user_prompt:
                analysis_result, report_content = agent.analyze_and_generate_report(
                    folder_path=paper_folder_path,
                    thread_id=f"unified_analysis_{arxiv_id}_{int(time.time())}",
                    user_prompt=user_prompt
                )
            else:
                analysis_result, report_content = agent.analyze_and_generate_report(
                    folder_path=paper_folder_path,
                    thread_id=f"unified_analysis_{arxiv_id}_{int(time.time())}"
                )
            
            # æ£€æŸ¥åˆ†ææ˜¯å¦æˆåŠŸ
            if 'error' in analysis_result:
                logger.error(f"åˆ†ææ‰§è¡Œå¤±è´¥ {arxiv_id}: {analysis_result['error']}")
                return {
                    'success': False,
                    'error': f"åˆ†ææ‰§è¡Œå¤±è´¥: {analysis_result['error']}"
                }
            
            # å¤„ç†åˆ†æç»“æœ
            if analysis_result.get('analysis_result') or report_content:
                # ä½¿ç”¨åˆ†æç»“æœæˆ–æŠ¥å‘Šå†…å®¹
                final_content = analysis_result.get('analysis_result') or report_content
                
                # å¤„ç†å›¾ç‰‡è·¯å¾„ï¼ˆå¦‚æœéœ€è¦ï¼‰
                processed_content = self._process_image_paths(final_content, arxiv_id)
                
                # ä¿å­˜åˆ†æç»“æœ
                analysis_file_path = os.path.join(paper_folder_path, f"{arxiv_id}_analysis.md")
                with open(analysis_file_path, 'w', encoding='utf-8') as f:
                    f.write(processed_content)
                
                logger.info(f"æ·±åº¦åˆ†æå®Œæˆ: {arxiv_id}, ä¿å­˜äº† {len(processed_content)} å­—ç¬¦")
                logger.info(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: {analysis_file_path}")
                
                return {
                    'success': True,
                    'analysis_result': processed_content,
                    'analysis_file_path': analysis_file_path,
                    'content_length': len(processed_content)
                }
            else:
                logger.warning(f"æ·±åº¦åˆ†ææœªç”Ÿæˆæœ‰æ•ˆç»“æœ: {arxiv_id}")
                return {
                    'success': False,
                    'error': 'æ·±åº¦åˆ†ææœªç”Ÿæˆæœ‰æ•ˆç»“æœ'
                }
                
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œæ·±åº¦åˆ†æå¤±è´¥ {arxiv_id}: {e}")
            return {
                'success': False,
                'error': f'æ‰§è¡Œæ·±åº¦åˆ†æå¤±è´¥: {str(e)}'
            }
    
    def _process_image_paths(self, content: str, arxiv_id: str) -> str:
        """
        å¤„ç†Markdownå†…å®¹ä¸­çš„å›¾ç‰‡è·¯å¾„
        
        Args:
            content: åŸå§‹Markdownå†…å®¹
            arxiv_id: ArXivè®ºæ–‡ID
            
        Returns:
            str: å¤„ç†åçš„Markdownå†…å®¹
        """
        try:
            logger.info(f"ğŸ–¼ï¸ å¼€å§‹å¤„ç†å›¾ç‰‡è·¯å¾„: {arxiv_id}")
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å›¾ç‰‡è·¯å¾„
            img_pattern = r'!\[([^\]]*)\]\((imgs/[^)]+)\)'
            
            def replace_image_path(match):
                alt_text = match.group(1)
                relative_path = match.group(2)
                filename = relative_path.replace('imgs/', '')
                # ç”ŸæˆWebå¯è®¿é—®è·¯å¾„ï¼ˆæ ¹æ®å…·ä½“Webåº”ç”¨éœ€æ±‚è°ƒæ•´ï¼‰
                new_path = f"/paper/{arxiv_id}/imgs/{filename}"
                logger.debug(f"  ğŸ“¸ è½¬æ¢å›¾ç‰‡è·¯å¾„: {relative_path} â†’ {new_path}")
                return f"![{alt_text}]({new_path})"
            
            # ç»Ÿè®¡åŸå§‹å›¾ç‰‡å¼•ç”¨æ•°é‡
            original_matches = re.findall(img_pattern, content)
            logger.info(f"  ğŸ“Š å‘ç° {len(original_matches)} ä¸ªå›¾ç‰‡å¼•ç”¨: {arxiv_id}")
            
            # æ›¿æ¢æ‰€æœ‰å›¾ç‰‡è·¯å¾„
            processed_content = re.sub(img_pattern, replace_image_path, content)
            
            # éªŒè¯å¤„ç†ç»“æœ
            processed_matches = re.findall(r'!\[([^\]]*)\]\((/paper/[^)]+)\)', processed_content)
            logger.info(f"  âœ… æˆåŠŸå¤„ç† {len(processed_matches)} ä¸ªå›¾ç‰‡è·¯å¾„: {arxiv_id}")
            
            return processed_content
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†å›¾ç‰‡è·¯å¾„å¤±è´¥ {arxiv_id}: {e}")
            return content
    
    def add_analysis_footer(
        self, 
        content: str, 
        publication_date: Optional[str] = None,
        additional_info: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        æ·»åŠ åˆ†æç»“æœçš„é¡µè„šä¿¡æ¯
        
        Args:
            content: åˆ†æå†…å®¹
            publication_date: è®ºæ–‡å‘è¡¨æ—¶é—´
            additional_info: é¢å¤–ä¿¡æ¯
            
        Returns:
            str: æ·»åŠ é¡µè„šåçš„å†…å®¹
        """
        try:
            footer_parts = ["---"]
            
            if publication_date:
                footer_parts.append(f"**è®ºæ–‡å‘è¡¨æ—¶é—´**: {publication_date}")
                footer_parts.append("")
            
            if additional_info:
                for key, value in additional_info.items():
                    footer_parts.append(f"**{key}**: {value}")
                footer_parts.append("")
            
            footer_parts.extend([
                "---",
                "*æ­¤åˆ†æç”± HomeSystem ç”Ÿæˆ*"
            ])
            
            footer_content = "\n\n" + "\n".join(footer_parts)
            return content + footer_content
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ é¡µè„šå¤±è´¥: {e}")
            return content


# ä¾¿æ·å‡½æ•°
def create_paper_analysis_service(config: Optional[Dict[str, Any]] = None) -> PaperAnalysisService:
    """
    åˆ›å»ºè®ºæ–‡åˆ†ææœåŠ¡çš„ä¾¿æ·å‡½æ•°
    
    Args:
        config: é…ç½®å‚æ•°ï¼ˆå¯åŒ…å« enable_user_prompt å’Œ user_promptï¼‰
        
    Returns:
        PaperAnalysisService: åˆ†ææœåŠ¡å®ä¾‹
    """
    return PaperAnalysisService(default_config=config)


def create_video_enhanced_paper_analysis_service(
    analysis_model: str = "deepseek.DeepSeek_V3",
    vision_model: str = "ollama.Qwen2_5_VL_7B", 
    video_analysis_model: str = "ollama.Qwen3_30B",
    enable_user_prompt: bool = False,
    user_prompt: Optional[str] = None,
    **kwargs
) -> PaperAnalysisService:
    """
    åˆ›å»ºå¸¦è§†é¢‘åˆ†æåŠŸèƒ½çš„è®ºæ–‡åˆ†ææœåŠ¡
    
    Args:
        analysis_model: ä¸»åˆ†ææ¨¡å‹
        vision_model: è§†è§‰åˆ†ææ¨¡å‹
        video_analysis_model: è§†é¢‘åˆ†ææ¨¡å‹
        enable_user_prompt: æ˜¯å¦å¯ç”¨ç”¨æˆ·æç¤ºè¯åŠŸèƒ½
        user_prompt: ç”¨æˆ·è‡ªå®šä¹‰æç¤ºè¯
        **kwargs: å…¶ä»–é…ç½®å‚æ•°
        
    Returns:
        PaperAnalysisService: æ”¯æŒè§†é¢‘åˆ†æçš„æœåŠ¡å®ä¾‹
    """
    config = {
        'analysis_model': analysis_model,
        'vision_model': vision_model,
        'enable_video_analysis': True,
        'video_analysis_model': video_analysis_model,
        'enable_user_prompt': enable_user_prompt,
        'user_prompt': user_prompt,
        'timeout': 600,
        **kwargs
    }
    return PaperAnalysisService(default_config=config)