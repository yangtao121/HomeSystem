"""
ç»Ÿä¸€çš„è®ºæ–‡æ·±åº¦åˆ†ææœåŠ¡

æä¾›ç»Ÿä¸€çš„è®ºæ–‡æ·±åº¦åˆ†ææ¥å£ï¼Œæ›¿ä»£å„ä¸ªæ¨¡å—ä¸­çš„é‡å¤å®ç°
åŒ…å«å®Œæ•´çš„åˆ†ææµç¨‹ï¼šæ–‡ä»¶å‡†å¤‡ã€PDFä¸‹è½½ã€OCRå¤„ç†ã€æ·±åº¦åˆ†æ
"""

import os
import re
import time
import logging
from pathlib import Path
from typing import Dict, Any, Optional, Tuple

from loguru import logger

from HomeSystem.utility.arxiv.arxiv import ArxivData


class PaperAnalysisService:
    """ç»Ÿä¸€çš„è®ºæ–‡æ·±åº¦åˆ†ææœåŠ¡
    
    åŠŸèƒ½ï¼š
    1. è®ºæ–‡æ–‡ä»¶å¤¹å‡†å¤‡
    2. PDFä¸‹è½½å’ŒéªŒè¯
    3. OCRæ–‡æœ¬æå–
    4. æ·±åº¦åˆ†ææ‰§è¡Œ
    5. ç»“æœå¤„ç†å’Œä¿å­˜
    """
    
    def __init__(self, default_config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–åˆ†ææœåŠ¡
        
        Args:
            default_config: é»˜è®¤é…ç½®å‚æ•°
        """
        self.default_config = default_config or {
            'analysis_model': 'deepseek.DeepSeek_V3',
            'vision_model': 'ollama.Qwen2_5_VL_7B',
            'timeout': 600
        }
    
    def perform_deep_analysis(
        self,
        arxiv_id: str,
        paper_folder_path: str,
        config: Optional[Dict[str, Any]] = None,
        paper_data: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„æ·±åº¦è®ºæ–‡åˆ†ææµç¨‹
        
        Args:
            arxiv_id: ArXivè®ºæ–‡ID
            paper_folder_path: è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„
            config: åˆ†æé…ç½®ï¼ˆå¯é€‰ï¼‰
            paper_data: è®ºæ–‡åŸºç¡€æ•°æ®ï¼ˆå¯é€‰ï¼Œç”¨äºPDFä¸‹è½½ï¼‰
            
        Returns:
            Dict: åˆ†æç»“æœ
                - success: bool, æ˜¯å¦æˆåŠŸ
                - analysis_result: str, åˆ†æå†…å®¹ï¼ˆæˆåŠŸæ—¶ï¼‰
                - analysis_file_path: str, åˆ†ææ–‡ä»¶è·¯å¾„ï¼ˆæˆåŠŸæ—¶ï¼‰
                - error: str, é”™è¯¯ä¿¡æ¯ï¼ˆå¤±è´¥æ—¶ï¼‰
        """
        try:
            logger.info(f"ğŸš€ å¼€å§‹è®ºæ–‡æ·±åº¦åˆ†ææµç¨‹: {arxiv_id}")
            
            # åˆå¹¶é…ç½®
            analysis_config = {**self.default_config, **(config or {})}
            
            # ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡è®ºæ–‡æ–‡ä»¶å¤¹
            folder_result = self._prepare_paper_folder(paper_folder_path)
            if not folder_result['success']:
                return folder_result
            
            logger.info(f"âœ… è®ºæ–‡æ–‡ä»¶å¤¹å‡†å¤‡å®Œæˆ: {paper_folder_path}")
            
            # ç¬¬äºŒæ­¥ï¼šä¸‹è½½è®ºæ–‡PDFï¼ˆå¦‚æœå°šæœªå­˜åœ¨ï¼‰
            pdf_result = self._ensure_paper_pdf(
                arxiv_id, 
                paper_folder_path, 
                paper_data
            )
            if not pdf_result['success']:
                return pdf_result
            
            logger.info(f"âœ… è®ºæ–‡PDFå‡†å¤‡å®Œæˆ: {arxiv_id}")
            
            # ç¬¬ä¸‰æ­¥ï¼šæ‰§è¡ŒOCRå¤„ç†ï¼ˆå¦‚æœå°šæœªå­˜åœ¨ï¼‰
            ocr_result = self._ensure_paper_ocr(arxiv_id, paper_folder_path)
            if not ocr_result['success']:
                return ocr_result
            
            logger.info(f"âœ… è®ºæ–‡OCRå¤„ç†å®Œæˆ: {arxiv_id}")
            
            # ç¬¬å››æ­¥ï¼šæ‰§è¡Œæ·±åº¦åˆ†æ
            analysis_result = self._execute_deep_analysis(
                arxiv_id, 
                paper_folder_path, 
                analysis_config
            )
            
            if analysis_result['success']:
                logger.info(f"âœ… æ·±åº¦åˆ†æå®Œæˆ: {arxiv_id}")
            else:
                logger.error(f"âŒ æ·±åº¦åˆ†æå¤±è´¥: {arxiv_id}")
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"ğŸ’¥ æ·±åº¦åˆ†ææµç¨‹å¼‚å¸¸ {arxiv_id}: {e}")
            return {
                'success': False,
                'error': f'æ·±åº¦åˆ†ææµç¨‹å¼‚å¸¸: {str(e)}'
            }
    
    def _prepare_paper_folder(self, paper_folder_path: str) -> Dict[str, Any]:
        """
        å‡†å¤‡è®ºæ–‡åˆ†ææ–‡ä»¶å¤¹
        
        Args:
            paper_folder_path: è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„
            
        Returns:
            Dict: æ“ä½œç»“æœ
        """
        try:
            folder_path = Path(paper_folder_path)
            folder_path.mkdir(parents=True, exist_ok=True)
            
            logger.info(f"ğŸ“ è®ºæ–‡æ–‡ä»¶å¤¹å·²å‡†å¤‡: {folder_path}")
            return {
                'success': True,
                'folder_path': str(folder_path)
            }
            
        except Exception as e:
            logger.error(f"âŒ å‡†å¤‡è®ºæ–‡æ–‡ä»¶å¤¹å¤±è´¥: {e}")
            return {
                'success': False,
                'error': f'å‡†å¤‡è®ºæ–‡æ–‡ä»¶å¤¹å¤±è´¥: {str(e)}'
            }
    
    def _ensure_paper_pdf(
        self,
        arxiv_id: str,
        paper_folder_path: str,
        paper_data: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ç¡®ä¿è®ºæ–‡PDFæ–‡ä»¶å­˜åœ¨
        
        Args:
            arxiv_id: ArXivè®ºæ–‡ID
            paper_folder_path: è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„
            paper_data: è®ºæ–‡åŸºç¡€æ•°æ®
            
        Returns:
            Dict: æ“ä½œç»“æœ
        """
        try:
            # æ£€æŸ¥PDFæ˜¯å¦å·²å­˜åœ¨
            pdf_path = os.path.join(paper_folder_path, f"{arxiv_id}.pdf")
            if os.path.exists(pdf_path) and os.path.getsize(pdf_path) > 0:
                logger.info(f"ğŸ“„ PDFæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {pdf_path}")
                return {
                    'success': True,
                    'pdf_path': pdf_path,
                    'skipped': True
                }
            
            # ä¸‹è½½PDF
            logger.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½PDF: {arxiv_id}")
            
            # æ„é€ ArxivDataå¯¹è±¡
            if paper_data:
                arxiv_data = ArxivData(paper_data)
            else:
                # ä½¿ç”¨æœ€å°å¿…è¦ä¿¡æ¯
                arxiv_data = ArxivData({
                    'title': '',
                    'link': f"https://arxiv.org/abs/{arxiv_id}",
                    'snippet': '',
                    'categories': '',
                    'arxiv_id': arxiv_id
                })
            
            # ä¸‹è½½PDFåˆ°æŒ‡å®šè·¯å¾„
            arxiv_data.downloadPdf(save_path=paper_folder_path)
            
            # æ£€æŸ¥ä¸‹è½½ç»“æœå¹¶é‡å‘½åä¸ºæ ‡å‡†æ ¼å¼
            pdf_files = [f for f in os.listdir(paper_folder_path) if f.endswith('.pdf')]
            if pdf_files:
                # é‡å‘½åä¸ºæ ‡å‡†æ ¼å¼
                actual_pdf_path = os.path.join(paper_folder_path, pdf_files[0])
                if actual_pdf_path != pdf_path and os.path.exists(actual_pdf_path):
                    os.rename(actual_pdf_path, pdf_path)
                    logger.info(f"ğŸ“ PDFé‡å‘½åä¸ºæ ‡å‡†æ ¼å¼: {pdf_path}")
            
            # éªŒè¯ä¸‹è½½ç»“æœ
            if os.path.exists(pdf_path) and os.path.getsize(pdf_path) > 0:
                logger.info(f"âœ… PDFä¸‹è½½æˆåŠŸ: {pdf_path}")
                return {
                    'success': True,
                    'pdf_path': pdf_path,
                    'downloaded': True
                }
            else:
                logger.error(f"âŒ PDFä¸‹è½½å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º: {pdf_path}")
                return {
                    'success': False,
                    'error': 'PDFä¸‹è½½å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º'
                }
                
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½PDFå¤±è´¥ {arxiv_id}: {e}")
            return {
                'success': False,
                'error': f'ä¸‹è½½PDFå¤±è´¥: {str(e)}'
            }
    
    def _ensure_paper_ocr(self, arxiv_id: str, paper_folder_path: str) -> Dict[str, Any]:
        """
        ç¡®ä¿è®ºæ–‡OCRå¤„ç†å®Œæˆ
        
        Args:
            arxiv_id: ArXivè®ºæ–‡ID
            paper_folder_path: è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„
            
        Returns:
            Dict: æ“ä½œç»“æœ
        """
        try:
            # æ£€æŸ¥OCRç»“æœæ˜¯å¦å·²å­˜åœ¨
            ocr_file = os.path.join(paper_folder_path, f"{arxiv_id}_paddleocr.md")
            if os.path.exists(ocr_file) and os.path.getsize(ocr_file) > 0:
                logger.info(f"ğŸ“ OCRæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†: {ocr_file}")
                return {
                    'success': True,
                    'ocr_file_path': ocr_file,
                    'skipped': True
                }
            
            # æ£€æŸ¥PDFæ–‡ä»¶
            pdf_path = os.path.join(paper_folder_path, f"{arxiv_id}.pdf")
            if not os.path.exists(pdf_path):
                logger.error(f"âŒ PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
                return {
                    'success': False,
                    'error': 'PDFæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡ŒOCR'
                }
            
            logger.info(f"ğŸ” å¼€å§‹OCRå¤„ç†: {pdf_path}")
            
            # åˆ›å»ºArxivDataå®ä¾‹å¹¶æ‰§è¡ŒOCR
            arxiv_data = ArxivData({
                'title': '',
                'link': f"https://arxiv.org/abs/{arxiv_id}",
                'snippet': '',
                'categories': '',
                'arxiv_id': arxiv_id
            })
            
            # ä»æ–‡ä»¶åŠ è½½PDF
            with open(pdf_path, 'rb') as f:
                arxiv_data.pdf = f.read()
            
            # æ‰§è¡ŒPaddleOCRå¤„ç†
            ocr_result, status_info = arxiv_data.performOCR(
                use_paddleocr=True,
                auto_save=True,
                save_path=paper_folder_path
            )
            
            if ocr_result and len(ocr_result.strip()) > 0:
                logger.info(f"âœ… OCRå¤„ç†æˆåŠŸï¼Œç”Ÿæˆ {len(ocr_result)} å­—ç¬¦: {arxiv_id}")
                return {
                    'success': True,
                    'ocr_file_path': ocr_file,
                    'ocr_content': ocr_result,
                    'processed': True
                }
            else:
                logger.error(f"âŒ OCRå¤„ç†å¤±è´¥ï¼Œæœªç”Ÿæˆæœ‰æ•ˆå†…å®¹: {arxiv_id}")
                return {
                    'success': False,
                    'error': 'OCRå¤„ç†å¤±è´¥ï¼Œæœªç”Ÿæˆæœ‰æ•ˆå†…å®¹'
                }
                
        except Exception as e:
            logger.error(f"âŒ OCRå¤„ç†å¤±è´¥ {arxiv_id}: {e}")
            return {
                'success': False,
                'error': f'OCRå¤„ç†å¤±è´¥: {str(e)}'
            }
    
    def _execute_deep_analysis(
        self,
        arxiv_id: str,
        paper_folder_path: str,
        config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ·±åº¦åˆ†æ
        
        Args:
            arxiv_id: ArXivè®ºæ–‡ID
            paper_folder_path: è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„
            config: åˆ†æé…ç½®
            
        Returns:
            Dict: åˆ†æç»“æœ
        """
        try:
            logger.info(f"ğŸ¤– å¼€å§‹æ·±åº¦åˆ†æ: {arxiv_id}")
            
            # åŠ¨æ€å¯¼å…¥æ·±åº¦åˆ†ææ™ºèƒ½ä½“
            try:
                from HomeSystem.graph.deep_paper_analysis_agent import create_deep_paper_analysis_agent
                logger.info("âœ… æˆåŠŸå¯¼å…¥æ·±åº¦è®ºæ–‡åˆ†ææ™ºèƒ½ä½“")
            except Exception as import_error:
                logger.error(f"âŒ å¯¼å…¥æ·±åº¦è®ºæ–‡åˆ†ææ™ºèƒ½ä½“å¤±è´¥: {import_error}")
                return {
                    'success': False,
                    'error': f'å¯¼å…¥æ·±åº¦è®ºæ–‡åˆ†ææ™ºèƒ½ä½“å¤±è´¥: {str(import_error)}'
                }
            
            # åˆ›å»ºæ·±åº¦åˆ†ææ™ºèƒ½ä½“
            logger.info("ğŸ¤– åˆ›å»ºæ·±åº¦åˆ†ææ™ºèƒ½ä½“...")
            agent = create_deep_paper_analysis_agent(
                analysis_model=config['analysis_model'],
                vision_model=config['vision_model']
            )
            logger.info("âœ… æ·±åº¦åˆ†ææ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸ")
            
            # æ‰§è¡Œåˆ†æ
            analysis_result, report_content = agent.analyze_and_generate_report(
                folder_path=paper_folder_path,
                thread_id=f"unified_analysis_{arxiv_id}_{int(time.time())}"
            )
            
            # æ£€æŸ¥åˆ†ææ˜¯å¦æˆåŠŸ
            if 'error' in analysis_result:
                logger.error(f"åˆ†ææ‰§è¡Œå¤±è´¥ {arxiv_id}: {analysis_result['error']}")
                return {
                    'success': False,
                    'error': f"åˆ†ææ‰§è¡Œå¤±è´¥: {analysis_result['error']}"
                }
            
            # å¤„ç†åˆ†æç»“æœ
            if analysis_result.get('analysis_result') or report_content:
                # ä½¿ç”¨åˆ†æç»“æœæˆ–æŠ¥å‘Šå†…å®¹
                final_content = analysis_result.get('analysis_result') or report_content
                
                # å¤„ç†å›¾ç‰‡è·¯å¾„ï¼ˆå¦‚æœéœ€è¦ï¼‰
                processed_content = self._process_image_paths(final_content, arxiv_id)
                
                # ä¿å­˜åˆ†æç»“æœ
                analysis_file_path = os.path.join(paper_folder_path, f"{arxiv_id}_analysis.md")
                with open(analysis_file_path, 'w', encoding='utf-8') as f:
                    f.write(processed_content)
                
                logger.info(f"æ·±åº¦åˆ†æå®Œæˆ: {arxiv_id}, ä¿å­˜äº† {len(processed_content)} å­—ç¬¦")
                logger.info(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: {analysis_file_path}")
                
                return {
                    'success': True,
                    'analysis_result': processed_content,
                    'analysis_file_path': analysis_file_path,
                    'content_length': len(processed_content)
                }
            else:
                logger.warning(f"æ·±åº¦åˆ†ææœªç”Ÿæˆæœ‰æ•ˆç»“æœ: {arxiv_id}")
                return {
                    'success': False,
                    'error': 'æ·±åº¦åˆ†ææœªç”Ÿæˆæœ‰æ•ˆç»“æœ'
                }
                
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œæ·±åº¦åˆ†æå¤±è´¥ {arxiv_id}: {e}")
            return {
                'success': False,
                'error': f'æ‰§è¡Œæ·±åº¦åˆ†æå¤±è´¥: {str(e)}'
            }
    
    def _process_image_paths(self, content: str, arxiv_id: str) -> str:
        """
        å¤„ç†Markdownå†…å®¹ä¸­çš„å›¾ç‰‡è·¯å¾„
        
        Args:
            content: åŸå§‹Markdownå†…å®¹
            arxiv_id: ArXivè®ºæ–‡ID
            
        Returns:
            str: å¤„ç†åçš„Markdownå†…å®¹
        """
        try:
            logger.info(f"ğŸ–¼ï¸ å¼€å§‹å¤„ç†å›¾ç‰‡è·¯å¾„: {arxiv_id}")
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å›¾ç‰‡è·¯å¾„
            img_pattern = r'!\[([^\]]*)\]\((imgs/[^)]+)\)'
            
            def replace_image_path(match):
                alt_text = match.group(1)
                relative_path = match.group(2)
                filename = relative_path.replace('imgs/', '')
                # ç”ŸæˆWebå¯è®¿é—®è·¯å¾„ï¼ˆæ ¹æ®å…·ä½“Webåº”ç”¨éœ€æ±‚è°ƒæ•´ï¼‰
                new_path = f"/paper/{arxiv_id}/analysis_images/{filename}"
                logger.debug(f"  ğŸ“¸ è½¬æ¢å›¾ç‰‡è·¯å¾„: {relative_path} â†’ {new_path}")
                return f"![{alt_text}]({new_path})"
            
            # ç»Ÿè®¡åŸå§‹å›¾ç‰‡å¼•ç”¨æ•°é‡
            original_matches = re.findall(img_pattern, content)
            logger.info(f"  ğŸ“Š å‘ç° {len(original_matches)} ä¸ªå›¾ç‰‡å¼•ç”¨: {arxiv_id}")
            
            # æ›¿æ¢æ‰€æœ‰å›¾ç‰‡è·¯å¾„
            processed_content = re.sub(img_pattern, replace_image_path, content)
            
            # éªŒè¯å¤„ç†ç»“æœ
            processed_matches = re.findall(r'!\[([^\]]*)\]\((/paper/[^)]+)\)', processed_content)
            logger.info(f"  âœ… æˆåŠŸå¤„ç† {len(processed_matches)} ä¸ªå›¾ç‰‡è·¯å¾„: {arxiv_id}")
            
            return processed_content
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†å›¾ç‰‡è·¯å¾„å¤±è´¥ {arxiv_id}: {e}")
            return content
    
    def add_analysis_footer(
        self, 
        content: str, 
        publication_date: Optional[str] = None,
        additional_info: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        æ·»åŠ åˆ†æç»“æœçš„é¡µè„šä¿¡æ¯
        
        Args:
            content: åˆ†æå†…å®¹
            publication_date: è®ºæ–‡å‘è¡¨æ—¶é—´
            additional_info: é¢å¤–ä¿¡æ¯
            
        Returns:
            str: æ·»åŠ é¡µè„šåçš„å†…å®¹
        """
        try:
            footer_parts = ["---"]
            
            if publication_date:
                footer_parts.append(f"**è®ºæ–‡å‘è¡¨æ—¶é—´**: {publication_date}")
                footer_parts.append("")
            
            if additional_info:
                for key, value in additional_info.items():
                    footer_parts.append(f"**{key}**: {value}")
                footer_parts.append("")
            
            footer_parts.extend([
                "---",
                "*æ­¤åˆ†æç”± HomeSystem ç”Ÿæˆ*"
            ])
            
            footer_content = "\n\n" + "\n".join(footer_parts)
            return content + footer_content
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ é¡µè„šå¤±è´¥: {e}")
            return content


# ä¾¿æ·å‡½æ•°
def create_paper_analysis_service(config: Optional[Dict[str, Any]] = None) -> PaperAnalysisService:
    """
    åˆ›å»ºè®ºæ–‡åˆ†ææœåŠ¡çš„ä¾¿æ·å‡½æ•°
    
    Args:
        config: é…ç½®å‚æ•°
        
    Returns:
        PaperAnalysisService: åˆ†ææœåŠ¡å®ä¾‹
    """
    return PaperAnalysisService(default_config=config)