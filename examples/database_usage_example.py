#!/usr/bin/env python3
"""
Home System æ•°æ®åº“é›†æˆä½¿ç”¨ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ•°æ®åº“é›†æˆåŠŸèƒ½è¿›è¡ŒArXivè®ºæ–‡ç®¡ç†
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def example_basic_database_operations():
    """åŸºç¡€æ•°æ®åº“æ“ä½œç¤ºä¾‹"""
    print("ğŸ“Š åŸºç¡€æ•°æ®åº“æ“ä½œç¤ºä¾‹")
    print("-" * 50)
    
    from HomeSystem.integrations.database import DatabaseOperations, ArxivPaperModel
    
    # åˆ›å»ºæ•°æ®åº“æ“ä½œå®ä¾‹
    db_ops = DatabaseOperations()
    
    # åˆå§‹åŒ–è¡¨ç»“æ„
    arxiv_model = ArxivPaperModel()
    success = db_ops.init_tables([arxiv_model])
    print(f"è¡¨ç»“æ„åˆå§‹åŒ–: {'âœ…' if success else 'âŒ'}")
    
    # åˆ›å»ºç¤ºä¾‹è®ºæ–‡
    paper = ArxivPaperModel(
        arxiv_id="2024.01001",
        title="ç¤ºä¾‹è®ºæ–‡ï¼šæ·±åº¦å­¦ä¹ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åº”ç”¨",
        abstract="è¿™æ˜¯ä¸€ç¯‡å…³äºæ·±åº¦å­¦ä¹ åœ¨NLPé¢†åŸŸåº”ç”¨çš„ç¤ºä¾‹è®ºæ–‡...",
        categories="cs.CL, cs.LG",
        published_date="2024å¹´01æœˆ",
        tags=["æ·±åº¦å­¦ä¹ ", "NLP"],
        metadata={"conference": "ç¤ºä¾‹ä¼šè®®"}
    )
    
    # ä¿å­˜è®ºæ–‡
    if db_ops.create(paper):
        print(f"âœ… è®ºæ–‡å·²ä¿å­˜: {paper.title}")
    else:
        print("âš ï¸  è®ºæ–‡å·²å­˜åœ¨æˆ–ä¿å­˜å¤±è´¥")
    
    # æŸ¥è¯¢è®ºæ–‡
    retrieved = db_ops.get_by_field(ArxivPaperModel, 'arxiv_id', '2024.01001')
    if retrieved:
        print(f"âœ… æŸ¥è¯¢æˆåŠŸ: {retrieved.title}")
        print(f"   çŠ¶æ€: {retrieved.processing_status}")
        print(f"   æ ‡ç­¾: {', '.join(retrieved.tags)}")
    
    # æ›´æ–°è®ºæ–‡çŠ¶æ€
    if retrieved:
        db_ops.update(retrieved, {'processing_status': 'completed'})
        print("âœ… è®ºæ–‡çŠ¶æ€å·²æ›´æ–°ä¸ºå·²å®Œæˆ")
    
    return True

def example_cache_operations():
    """ç¼“å­˜æ“ä½œç¤ºä¾‹"""
    print("\nğŸ’¾ ç¼“å­˜æ“ä½œç¤ºä¾‹")
    print("-" * 50)
    
    from HomeSystem.integrations.database import CacheOperations, ArxivPaperModel
    
    cache_ops = CacheOperations()
    
    # åŸºç¡€é”®å€¼ç¼“å­˜
    cache_ops.set("example_key", "ç¤ºä¾‹å€¼", expire=300)
    value = cache_ops.get("example_key")
    print(f"ç¼“å­˜æ“ä½œ: {'âœ…' if value == 'ç¤ºä¾‹å€¼' else 'âŒ'}")
    
    # é›†åˆæ“ä½œ - å·²å¤„ç†è®ºæ–‡é›†åˆ
    cache_ops.sadd("processed_papers", "2024.01001", "2024.01002")
    is_processed = cache_ops.sismember("processed_papers", "2024.01001")
    print(f"é›†åˆæ“ä½œ: {'âœ…' if is_processed else 'âŒ'}")
    
    # æ¨¡å‹ç¼“å­˜
    paper = ArxivPaperModel(
        arxiv_id="cache.test",
        title="ç¼“å­˜æµ‹è¯•è®ºæ–‡",
        abstract="ç”¨äºæµ‹è¯•ç¼“å­˜åŠŸèƒ½çš„è®ºæ–‡"
    )
    
    success = cache_ops.cache_model(paper, expire=600)
    print(f"æ¨¡å‹ç¼“å­˜: {'âœ…' if success else 'âŒ'}")
    
    cached_paper = cache_ops.get_cached_model(ArxivPaperModel, paper.id)
    print(f"æ¨¡å‹è¯»å–: {'âœ…' if cached_paper and cached_paper.title == paper.title else 'âŒ'}")
    
    return True

def example_arxiv_integration():
    """ArXivé›†æˆç¤ºä¾‹"""
    print("\nğŸ”¬ ArXivé›†æˆä½¿ç”¨ç¤ºä¾‹")
    print("-" * 50)
    
    try:
        from HomeSystem.utility.arxiv import EnhancedArxivTool
        
        # åˆ›å»ºå¢å¼ºç‰ˆArXivå·¥å…·ï¼ˆå¯ç”¨æ•°æ®åº“ï¼‰
        arxiv_tool = EnhancedArxivTool(enable_database=True)
        print("âœ… å¢å¼ºç‰ˆArXivå·¥å…·å·²åˆ›å»º")
        
        # æœç´¢è®ºæ–‡ï¼ˆè‡ªåŠ¨ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
        print("ğŸ” æœç´¢è®ºæ–‡: 'machine learning'...")
        results = arxiv_tool.arxivSearch("machine learning", num_results=5)
        
        if results.num_results > 0:
            print(f"âœ… æ‰¾åˆ° {results.num_results} ç¯‡è®ºæ–‡")
            
            # æ˜¾ç¤ºç¬¬ä¸€ç¯‡è®ºæ–‡
            first_paper = results.results[0]
            print(f"   ç¤ºä¾‹è®ºæ–‡: {first_paper.title[:60]}...")
            print(f"   ArXiv ID: {first_paper.arxiv_id}")
            print(f"   å‘å¸ƒæ—¶é—´: {first_paper.published_date}")
            
            # æ¼”ç¤ºå»é‡æœç´¢
            print("\nğŸ” æœç´¢ç›¸åŒå…³é”®è¯ï¼ˆè·³è¿‡å·²å¤„ç†ï¼‰...")
            filtered_results = arxiv_tool.arxivSearch(
                "machine learning", 
                num_results=5, 
                skip_processed=True
            )
            print(f"âœ… è¿‡æ»¤åå‰©ä½™ {filtered_results.num_results} ç¯‡æ–°è®ºæ–‡")
            
            # æ¼”ç¤ºè®ºæ–‡å¤„ç†
            def sample_processor(paper):
                """ç¤ºä¾‹å¤„ç†å‡½æ•°"""
                print(f"   æ­£åœ¨å¤„ç†: {paper.title[:40]}...")
                # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„å¤„ç†é€»è¾‘ï¼Œå¦‚ä¸‹è½½PDFã€æå–ä¿¡æ¯ç­‰
                return f"å·²å¤„ç†è®ºæ–‡: {paper.arxiv_id}"
            
            if results.results:
                paper_to_process = results.results[0]
                result = arxiv_tool.process_paper(paper_to_process, sample_processor)
                print(f"âœ… {result}")
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = arxiv_tool.get_processing_statistics()
            print(f"\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡:")
            print(f"   æ€»è®ºæ–‡æ•°: {stats.get('total', 0)}")
            print(f"   å¾…å¤„ç†: {stats.get('pending', 0)}")
            print(f"   å·²å®Œæˆ: {stats.get('completed', 0)}")
            print(f"   å¤±è´¥: {stats.get('failed', 0)}")
            
        return True
        
    except ImportError as e:
        print(f"âš ï¸  ArXivé›†æˆä¸å¯ç”¨: {e}")
        return False
    except Exception as e:
        print(f"âŒ ArXivé›†æˆç¤ºä¾‹å¤±è´¥: {e}")
        return False

def example_advanced_usage():
    """é«˜çº§ç”¨æ³•ç¤ºä¾‹"""
    print("\nğŸš€ é«˜çº§ç”¨æ³•ç¤ºä¾‹")
    print("-" * 50)
    
    try:
        from HomeSystem.utility.arxiv.database_integration import ArxivDatabaseManager
        
        # ç›´æ¥ä½¿ç”¨æ•°æ®åº“ç®¡ç†å™¨
        db_manager = ArxivDatabaseManager()
        
        # è·å–æœªå¤„ç†çš„è®ºæ–‡
        unprocessed = db_manager.get_unprocessed_papers(limit=3)
        print(f"âœ… æ‰¾åˆ° {len(unprocessed)} ç¯‡å¾…å¤„ç†è®ºæ–‡")
        
        for paper in unprocessed[:2]:  # åªæ˜¾ç¤ºå‰2ç¯‡
            print(f"   - {paper.title[:50]}... ({paper.arxiv_id})")
        
        # æ‰¹é‡æ ‡è®°ä¸ºå·²å¤„ç†
        for paper in unprocessed[:1]:  # åªå¤„ç†ç¬¬ä¸€ç¯‡
            success = db_manager.mark_processed(paper.arxiv_id, 'completed')
            if success:
                print(f"âœ… å·²æ ‡è®°è®ºæ–‡ä¸ºå·²å¤„ç†: {paper.arxiv_id}")
        
        # è·å–æŒ‰çŠ¶æ€åˆ†ç»„çš„è®ºæ–‡
        completed_papers = db_manager.get_papers_by_status('completed', limit=3)
        print(f"âœ… å·²å®Œæˆçš„è®ºæ–‡: {len(completed_papers)} ç¯‡")
        
        return True
        
    except Exception as e:
        print(f"âŒ é«˜çº§ç”¨æ³•ç¤ºä¾‹å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Home System æ•°æ®åº“é›†æˆä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    try:
        from dotenv import load_dotenv
        load_dotenv()
        print("âœ… ç¯å¢ƒå˜é‡å·²åŠ è½½")
    except ImportError:
        print("âš ï¸  python-dotenv æœªå®‰è£…")
    
    # è¿è¡Œç¤ºä¾‹
    examples = [
        ("åŸºç¡€æ•°æ®åº“æ“ä½œ", example_basic_database_operations),
        ("ç¼“å­˜æ“ä½œ", example_cache_operations),
        ("ArXivé›†æˆ", example_arxiv_integration),
        ("é«˜çº§ç”¨æ³•", example_advanced_usage),
    ]
    
    for name, func in examples:
        try:
            print(f"\n{'='*20} {name} {'='*20}")
            success = func()
            if not success:
                print(f"âš ï¸  {name} ç¤ºä¾‹æœªå®Œå…¨æˆåŠŸ")
        except Exception as e:
            print(f"âŒ {name} ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {e}")
        
        print()  # æ·»åŠ ç©ºè¡Œåˆ†éš”
    
    print("ğŸ‰ æ‰€æœ‰ç¤ºä¾‹æ‰§è¡Œå®Œæˆï¼")
    print("\nğŸ’¡ æç¤º:")
    print("- ä½¿ç”¨ docker-compose up -d å¯åŠ¨æ•°æ®åº“æœåŠ¡")
    print("- æŸ¥çœ‹ docs/database-integration-guide.md äº†è§£è¯¦ç»†ç”¨æ³•")
    print("- è¿è¡Œ python quick_test.py å¿«é€Ÿæµ‹è¯•è¿æ¥")

if __name__ == "__main__":
    main()