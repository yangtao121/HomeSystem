#!/usr/bin/env python3
"""
ç¿»è¯‘è´¨é‡å¯¹æ¯”æµ‹è¯•è„šæœ¬
å¯¹æ¯”æœ¬åœ°æ¨¡å‹ï¼ˆOllamaï¼‰å’Œäº‘ç«¯æ¨¡å‹ï¼ˆDeepSeekï¼‰çš„ç¿»è¯‘æ•ˆæœ
"""

import sys
import os
import time
import asyncio
from pathlib import Path

# æ·»åŠ è·¯å¾„ä»¥å¯¼å…¥HomeSystemæ¨¡å—
sys.path.append(str(Path(__file__).parent.parent))

from HomeSystem.workflow.paper_gather_task.llm_config import TranslationLLM
from HomeSystem.graph.llm_factory import llm_factory
from loguru import logger

# é…ç½®æ—¥å¿—
logger.remove()
logger.add(sys.stdout, level="INFO", format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | {message}")


class TranslationComparison:
    """ç¿»è¯‘å¯¹æ¯”æµ‹è¯•ç±»"""
    
    def __init__(self):
        # åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹å’Œäº‘ç«¯æ¨¡å‹
        self.local_model = "ollama.Qwen3_30B"  # æœ¬åœ°æ¨¡å‹
        self.cloud_model = "deepseek.DeepSeek_V3"  # äº‘ç«¯æ¨¡å‹
        
        logger.info("åˆå§‹åŒ–ç¿»è¯‘å¯¹æ¯”æµ‹è¯•...")
        
    def create_translators(self):
        """åˆ›å»ºç¿»è¯‘å™¨å®ä¾‹"""
        try:
            # åˆ›å»ºæœ¬åœ°ç¿»è¯‘å™¨
            logger.info(f"åˆ›å»ºæœ¬åœ°ç¿»è¯‘å™¨: {self.local_model}")
            self.local_translator = TranslationLLM(model_name=self.local_model)
            
            # åˆ›å»ºäº‘ç«¯ç¿»è¯‘å™¨
            logger.info(f"åˆ›å»ºäº‘ç«¯ç¿»è¯‘å™¨: {self.cloud_model}")
            self.cloud_translator = TranslationLLM(model_name=self.cloud_model)
            
            logger.info("ç¿»è¯‘å™¨åˆ›å»ºæˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"ç¿»è¯‘å™¨åˆ›å»ºå¤±è´¥: {e}")
            return False
    
    def get_test_texts(self):
        """è·å–æµ‹è¯•æ–‡æœ¬ï¼ˆæ¨¡æ‹Ÿè®ºæ–‡å­—æ®µå†…å®¹ï¼‰"""
        return [
            {
                "field": "research_background",
                "text": "Machine learning has revolutionized various domains, including computer vision, natural language processing, and robotics. However, the interpretability of deep neural networks remains a significant challenge. Recent advances in explainable AI have focused on developing methods to understand and visualize the decision-making process of complex models."
            },
            {
                "field": "research_objectives", 
                "text": "This study aims to develop a novel framework for enhancing the interpretability of convolutional neural networks in image classification tasks. We propose a gradient-based attribution method that can identify the most influential regions in input images that contribute to the model's predictions."
            },
            {
                "field": "methods",
                "text": "We implement a multi-scale gradient analysis approach combined with attention mechanisms. The method involves computing gradients at multiple layers of the CNN, applying Gaussian filters for noise reduction, and using attention weights to highlight salient features. We evaluate our approach on three benchmark datasets: CIFAR-10, ImageNet, and a custom medical imaging dataset."
            },
            {
                "field": "key_findings",
                "text": "Our experimental results demonstrate that the proposed method achieves 15% improvement in interpretability metrics compared to existing techniques such as GradCAM and LIME. The method successfully identifies relevant image regions with 92% accuracy on the medical imaging dataset, significantly outperforming baseline approaches."
            },
            {
                "field": "conclusions",
                "text": "The proposed gradient-based attribution framework provides more accurate and reliable explanations for CNN decisions in image classification. This advancement has important implications for safety-critical applications such as medical diagnosis and autonomous driving, where model interpretability is crucial for trust and adoption."
            }
        ]
    
    async def compare_single_translation(self, test_item):
        """å¯¹æ¯”å•ä¸ªæ–‡æœ¬çš„ç¿»è¯‘æ•ˆæœ"""
        field = test_item["field"]
        text = test_item["text"]
        
        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ” æ­£åœ¨ç¿»è¯‘å­—æ®µ: {field}")
        logger.info(f"ğŸ“ åŸæ–‡:")
        logger.info(f"{text}")
        logger.info(f"{'='*80}")
        
        results = {}
        
        # æœ¬åœ°æ¨¡å‹ç¿»è¯‘
        try:
            logger.info(f"ğŸ–¥ï¸  ä½¿ç”¨æœ¬åœ°æ¨¡å‹ç¿»è¯‘ ({self.local_model})")
            local_start = time.time()
            local_result = self.local_translator.translate_text(text)
            local_time = time.time() - local_start
            
            results["local"] = {
                "model": self.local_model,
                "result": local_result,
                "time": local_time
            }
            
            logger.info(f"âœ… æœ¬åœ°ç¿»è¯‘å®Œæˆï¼Œè€—æ—¶: {local_time:.2f}ç§’")
            
        except Exception as e:
            logger.error(f"âŒ æœ¬åœ°æ¨¡å‹ç¿»è¯‘å¤±è´¥: {e}")
            results["local"] = {"error": str(e)}
        
        # äº‘ç«¯æ¨¡å‹ç¿»è¯‘
        try:
            logger.info(f"â˜ï¸  ä½¿ç”¨äº‘ç«¯æ¨¡å‹ç¿»è¯‘ ({self.cloud_model})")
            cloud_start = time.time()
            cloud_result = self.cloud_translator.translate_text(text)
            cloud_time = time.time() - cloud_start
            
            results["cloud"] = {
                "model": self.cloud_model,
                "result": cloud_result,
                "time": cloud_time
            }
            
            logger.info(f"âœ… äº‘ç«¯ç¿»è¯‘å®Œæˆï¼Œè€—æ—¶: {cloud_time:.2f}ç§’")
            
        except Exception as e:
            logger.error(f"âŒ äº‘ç«¯æ¨¡å‹ç¿»è¯‘å¤±è´¥: {e}")
            results["cloud"] = {"error": str(e)}
        
        # æ˜¾ç¤ºç¿»è¯‘ç»“æœå¯¹æ¯”
        self.display_comparison(field, text, results)
        
        return results
    
    def display_comparison(self, field, original_text, results):
        """æ˜¾ç¤ºç¿»è¯‘ç»“æœå¯¹æ¯”"""
        print(f"\n{'ğŸ” ç¿»è¯‘ç»“æœå¯¹æ¯”':<30}")
        print("=" * 100)
        print(f"ğŸ“‹ å­—æ®µ: {field}")
        print(f"ğŸ“ åŸæ–‡: {original_text[:100]}{'...' if len(original_text) > 100 else ''}")
        print("-" * 100)
        
        # æœ¬åœ°æ¨¡å‹ç»“æœ
        if "local" in results and "result" in results["local"]:
            local_result = results["local"]["result"]
            local_time = results["local"]["time"]
            print(f"ğŸ–¥ï¸  æœ¬åœ°æ¨¡å‹ ({self.local_model}):")
            print(f"   â±ï¸  ç¿»è¯‘æ—¶é—´: {local_time:.2f}ç§’")
            print(f"   ğŸ¯ ç¿»è¯‘è´¨é‡: {local_result.translation_quality}")
            print(f"   ğŸ“– ä¸­æ–‡ç¿»è¯‘:")
            print(f"   {local_result.translated_text}")
            if local_result.notes:
                print(f"   ğŸ“ ç¿»è¯‘æ³¨é‡Š: {local_result.notes}")
        elif "local" in results:
            print(f"ğŸ–¥ï¸  æœ¬åœ°æ¨¡å‹ ({self.local_model}): âŒ ç¿»è¯‘å¤±è´¥ - {results['local'].get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        print("-" * 50)
        
        # äº‘ç«¯æ¨¡å‹ç»“æœ
        if "cloud" in results and "result" in results["cloud"]:
            cloud_result = results["cloud"]["result"]
            cloud_time = results["cloud"]["time"]
            print(f"â˜ï¸  äº‘ç«¯æ¨¡å‹ ({self.cloud_model}):")
            print(f"   â±ï¸  ç¿»è¯‘æ—¶é—´: {cloud_time:.2f}ç§’")
            print(f"   ğŸ¯ ç¿»è¯‘è´¨é‡: {cloud_result.translation_quality}")
            print(f"   ğŸ“– ä¸­æ–‡ç¿»è¯‘:")
            print(f"   {cloud_result.translated_text}")
            if cloud_result.notes:
                print(f"   ğŸ“ ç¿»è¯‘æ³¨é‡Š: {cloud_result.notes}")
        elif "cloud" in results:
            print(f"â˜ï¸  äº‘ç«¯æ¨¡å‹ ({self.cloud_model}): âŒ ç¿»è¯‘å¤±è´¥ - {results['cloud'].get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # æ€§èƒ½å¯¹æ¯”
        if ("local" in results and "cloud" in results and 
            "result" in results["local"] and "result" in results["cloud"]):
            
            local_time = results["local"]["time"]
            cloud_time = results["cloud"]["time"]
            
            print("-" * 50)
            print("ğŸ“Š æ€§èƒ½å¯¹æ¯”:")
            if local_time < cloud_time:
                speedup = cloud_time / local_time
                print(f"   ğŸš€ æœ¬åœ°æ¨¡å‹æ›´å¿« {speedup:.2f}x")
            else:
                speedup = local_time / cloud_time
                print(f"   â˜ï¸  äº‘ç«¯æ¨¡å‹æ›´å¿« {speedup:.2f}x")
            
            print(f"   ğŸ“ˆ æ—¶é—´å·®: {abs(local_time - cloud_time):.2f}ç§’")
        
        print("=" * 100)
    
    async def run_comparison(self):
        """è¿è¡Œå®Œæ•´çš„ç¿»è¯‘å¯¹æ¯”æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹ç¿»è¯‘è´¨é‡å¯¹æ¯”æµ‹è¯•")
        
        # åˆ›å»ºç¿»è¯‘å™¨
        if not self.create_translators():
            logger.error("ç¿»è¯‘å™¨åˆ›å»ºå¤±è´¥ï¼Œé€€å‡ºæµ‹è¯•")
            return
        
        # è·å–æµ‹è¯•æ–‡æœ¬
        test_texts = self.get_test_texts()
        logger.info(f"ğŸ“š å‡†å¤‡æµ‹è¯• {len(test_texts)} ä¸ªå­—æ®µçš„ç¿»è¯‘")
        
        all_results = []
        total_start_time = time.time()
        
        # é€ä¸ªè¿›è¡Œç¿»è¯‘å¯¹æ¯”
        for i, test_item in enumerate(test_texts, 1):
            logger.info(f"\nğŸ”„ è¿›è¡Œç¬¬ {i}/{len(test_texts)} ä¸ªç¿»è¯‘å¯¹æ¯”...")
            result = await self.compare_single_translation(test_item)
            all_results.append({
                "field": test_item["field"],
                "original": test_item["text"],
                "results": result
            })
            
            # æ·»åŠ é—´éš”ï¼Œé¿å…APIè°ƒç”¨è¿‡å¿«
            if i < len(test_texts):
                await asyncio.sleep(1)
        
        total_time = time.time() - total_start_time
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self.generate_summary_report(all_results, total_time)
    
    def generate_summary_report(self, all_results, total_time):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        print(f"\n{'ğŸ“Š ç¿»è¯‘å¯¹æ¯”æ€»ç»“æŠ¥å‘Š':<50}")
        print("=" * 120)
        
        local_successes = 0
        cloud_successes = 0
        local_total_time = 0
        cloud_total_time = 0
        quality_comparison = {"local": [], "cloud": []}
        
        for item in all_results:
            results = item["results"]
            
            # ç»Ÿè®¡æˆåŠŸç‡
            if "local" in results and "result" in results["local"]:
                local_successes += 1
                local_total_time += results["local"]["time"]
                quality_comparison["local"].append(results["local"]["result"].translation_quality)
            
            if "cloud" in results and "result" in results["cloud"]:
                cloud_successes += 1
                cloud_total_time += results["cloud"]["time"]
                quality_comparison["cloud"].append(results["cloud"]["result"].translation_quality)
        
        total_tests = len(all_results)
        
        print(f"ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡:")
        print(f"   ğŸ–¥ï¸  æœ¬åœ°æ¨¡å‹ ({self.local_model}):")
        print(f"      âœ… æˆåŠŸç‡: {local_successes}/{total_tests} ({local_successes/total_tests*100:.1f}%)")
        if local_successes > 0:
            print(f"      â±ï¸  å¹³å‡æ—¶é—´: {local_total_time/local_successes:.2f}ç§’")
            local_quality_dist = {q: quality_comparison['local'].count(q) for q in set(quality_comparison['local'])}
            print(f"      ğŸ¯ è´¨é‡åˆ†å¸ƒ: {local_quality_dist}")
        
        print(f"   â˜ï¸  äº‘ç«¯æ¨¡å‹ ({self.cloud_model}):")
        print(f"      âœ… æˆåŠŸç‡: {cloud_successes}/{total_tests} ({cloud_successes/total_tests*100:.1f}%)")
        if cloud_successes > 0:
            print(f"      â±ï¸  å¹³å‡æ—¶é—´: {cloud_total_time/cloud_successes:.2f}ç§’")
            cloud_quality_dist = {q: quality_comparison['cloud'].count(q) for q in set(quality_comparison['cloud'])}
            print(f"      ğŸ¯ è´¨é‡åˆ†å¸ƒ: {cloud_quality_dist}")
        
        # æ•´ä½“å¯¹æ¯”
        if local_successes > 0 and cloud_successes > 0:
            avg_local_time = local_total_time / local_successes
            avg_cloud_time = cloud_total_time / cloud_successes
            
            print(f"\nğŸ† æ•´ä½“å¯¹æ¯”:")
            if avg_local_time < avg_cloud_time:
                speedup = avg_cloud_time / avg_local_time
                print(f"   ğŸš€ æœ¬åœ°æ¨¡å‹å¹³å‡é€Ÿåº¦æ›´å¿« {speedup:.2f}x")
            else:
                speedup = avg_local_time / avg_cloud_time
                print(f"   â˜ï¸  äº‘ç«¯æ¨¡å‹å¹³å‡é€Ÿåº¦æ›´å¿« {speedup:.2f}x")
        
        print(f"\nâ±ï¸  æ€»æµ‹è¯•æ—¶é—´: {total_time:.2f}ç§’")
        print(f"ğŸ“Š æµ‹è¯•å®Œæˆ: {total_tests} ä¸ªå­—æ®µç¿»è¯‘å¯¹æ¯”")
        print("=" * 120)


async def main():
    """ä¸»å‡½æ•°"""
    try:
        logger.info("ğŸ¯ å¯åŠ¨ç¿»è¯‘è´¨é‡å¯¹æ¯”æµ‹è¯•")
        
        # æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§
        logger.info("ğŸ” æ£€æŸ¥å¯ç”¨æ¨¡å‹...")
        available_models = llm_factory.get_available_llm_models()
        logger.info(f"ğŸ“‹ å¯ç”¨æ¨¡å‹: {available_models}")
        
        # åˆ›å»ºå¯¹æ¯”æµ‹è¯•å®ä¾‹
        comparison = TranslationComparison()
        
        # è¿è¡Œå¯¹æ¯”æµ‹è¯•
        await comparison.run_comparison()
        
        logger.info("âœ… ç¿»è¯‘å¯¹æ¯”æµ‹è¯•å®Œæˆ")
        
    except KeyboardInterrupt:
        logger.info("âŒ ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main())