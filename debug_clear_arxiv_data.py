#!/usr/bin/env python3
"""
Arxiv æ•°æ®åº“è°ƒè¯•è„šæœ¬ - æ¸…é™¤æ‰€æœ‰æ•°æ®
ç”¨äºåˆ é™¤æ•°æ®åº“ä¸­çš„æ‰€æœ‰ Arxiv è®ºæ–‡æ•°æ®ï¼Œæ–¹ä¾¿æµ‹è¯•å’Œé‡æ–°å¼€å§‹
"""

import psycopg2
import redis
import json
from datetime import datetime
from typing import List, Dict, Any

# æ•°æ®åº“é…ç½®
DB_CONFIG = {
    'host': '192.168.5.54',
    'port': 15432,
    'database': 'homesystem',
    'user': 'homesystem',
    'password': 'homesystem123'
}

REDIS_CONFIG = {
    'host': '192.168.5.54',
    'port': 16379,
    'db': 0
}

def connect_db():
    """è¿æ¥PostgreSQLæ•°æ®åº“"""
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        return conn
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return None

def connect_redis():
    """è¿æ¥Redisç¼“å­˜"""
    try:
        r = redis.Redis(**REDIS_CONFIG)
        r.ping()
        return r
    except Exception as e:
        print(f"âš ï¸ Redisè¿æ¥å¤±è´¥: {e}")
        return None

def get_data_stats(conn):
    """è·å–å½“å‰æ•°æ®ç»Ÿè®¡"""
    try:
        with conn.cursor() as cur:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            cur.execute("""
                SELECT tablename FROM pg_tables 
                WHERE schemaname = 'public' AND tablename = 'arxiv_papers'
            """)
            if not cur.fetchone():
                return None, "è¡¨ä¸å­˜åœ¨"
            
            # è·å–æ€»æ•°
            cur.execute("SELECT COUNT(*) FROM arxiv_papers")
            total_count = cur.fetchone()[0]
            
            # æŒ‰çŠ¶æ€ç»Ÿè®¡
            cur.execute("""
                SELECT processing_status, COUNT(*) 
                FROM arxiv_papers 
                GROUP BY processing_status
            """)
            status_stats = dict(cur.fetchall())
            
            return total_count, status_stats
    
    except Exception as e:
        return None, f"è·å–ç»Ÿè®¡å¤±è´¥: {e}"

def clear_postgres_data(conn, confirm=False):
    """æ¸…é™¤PostgreSQLä¸­çš„Arxivæ•°æ®"""
    print("\n" + "=" * 60)
    print("ğŸ—‘ï¸ PostgreSQL æ•°æ®æ¸…ç†")
    print("=" * 60)
    
    # è·å–å½“å‰æ•°æ®ç»Ÿè®¡
    total_count, status_info = get_data_stats(conn)
    
    if total_count is None:
        print(f"âŒ {status_info}")
        return False
    
    if total_count == 0:
        print("ğŸ“­ æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®éœ€è¦æ¸…ç†")
        return True
    
    print(f"ğŸ“Š å½“å‰æ•°æ®ç»Ÿè®¡:")
    print(f"   æ€»è®ºæ–‡æ•°é‡: {total_count}")
    if isinstance(status_info, dict):
        print(f"   æŒ‰çŠ¶æ€åˆ†å¸ƒ:")
        for status, count in status_info.items():
            print(f"     {status}: {count}")
    
    if not confirm:
        print(f"\nâš ï¸ å³å°†åˆ é™¤ {total_count} ç¯‡è®ºæ–‡æ•°æ®")
        response = input("â“ ç¡®è®¤åˆ é™¤æ‰€æœ‰æ•°æ®ï¼Ÿ(è¾“å…¥ 'YES' ç¡®è®¤): ").strip()
        if response != 'YES':
            print("âŒ æ“ä½œå·²å–æ¶ˆ")
            return False
    
    try:
        with conn.cursor() as cur:
            print("\nğŸ”„ å¼€å§‹æ¸…ç†æ•°æ®...")
            
            # åˆ é™¤æ‰€æœ‰æ•°æ®
            cur.execute("DELETE FROM arxiv_papers")
            deleted_count = cur.rowcount
            
            # é‡ç½®è‡ªåŠ¨é€’å¢åºåˆ—ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            cur.execute("""
                SELECT sequence_name FROM information_schema.sequences 
                WHERE sequence_schema = 'public'
            """)
            sequences = cur.fetchall()
            for (seq_name,) in sequences:
                if 'arxiv' in seq_name.lower():
                    cur.execute(f"ALTER SEQUENCE {seq_name} RESTART WITH 1")
                    print(f"   é‡ç½®åºåˆ—: {seq_name}")
            
            # æäº¤äº‹åŠ¡
            conn.commit()
            
            print(f"âœ… æˆåŠŸåˆ é™¤ {deleted_count} æ¡è®°å½•")
            
            # éªŒè¯åˆ é™¤ç»“æœ
            cur.execute("SELECT COUNT(*) FROM arxiv_papers")
            remaining_count = cur.fetchone()[0]
            
            if remaining_count == 0:
                print("âœ… æ•°æ®åº“æ¸…ç†å®Œæˆï¼Œæ‰€æœ‰æ•°æ®å·²åˆ é™¤")
                return True
            else:
                print(f"âš ï¸ è­¦å‘Šï¼šä»æœ‰ {remaining_count} æ¡è®°å½•æœªåˆ é™¤")
                return False
    
    except Exception as e:
        print(f"âŒ åˆ é™¤æ•°æ®å¤±è´¥: {e}")
        conn.rollback()
        return False

def clear_redis_cache(redis_conn, confirm=False):
    """æ¸…é™¤Redisä¸­çš„Arxivç›¸å…³ç¼“å­˜"""
    print("\n" + "=" * 60)
    print("ğŸ—‘ï¸ Redis ç¼“å­˜æ¸…ç†")
    print("=" * 60)
    
    if not redis_conn:
        print("âš ï¸ Redis æœªè¿æ¥ï¼Œè·³è¿‡ç¼“å­˜æ¸…ç†")
        return True
    
    try:
        # æŸ¥æ‰¾ Arxiv ç›¸å…³çš„é”®
        arxiv_patterns = ['arxiv:*', 'paper:*', 'cache:arxiv:*', 'arxiv_*']
        all_arxiv_keys = []
        
        for pattern in arxiv_patterns:
            keys = redis_conn.keys(pattern)
            all_arxiv_keys.extend(keys)
        
        # å»é‡
        unique_keys = list(set(all_arxiv_keys))
        
        if not unique_keys:
            print("ğŸ“­ æ²¡æœ‰æ‰¾åˆ° Arxiv ç›¸å…³çš„ç¼“å­˜æ•°æ®")
            return True
        
        print(f"ğŸ” æ‰¾åˆ° {len(unique_keys)} ä¸ª Arxiv ç›¸å…³ç¼“å­˜é”®:")
        for key in sorted(unique_keys)[:10]:  # æ˜¾ç¤ºå‰10ä¸ªé”®
            key_str = key.decode('utf-8') if isinstance(key, bytes) else str(key)
            print(f"   {key_str}")
        
        if len(unique_keys) > 10:
            print(f"   ... è¿˜æœ‰ {len(unique_keys) - 10} ä¸ªé”®")
        
        if not confirm:
            response = input(f"\nâ“ ç¡®è®¤åˆ é™¤è¿™ {len(unique_keys)} ä¸ªç¼“å­˜é”®ï¼Ÿ(è¾“å…¥ 'YES' ç¡®è®¤): ").strip()
            if response != 'YES':
                print("âŒ ç¼“å­˜æ¸…ç†å·²å–æ¶ˆ")
                return False
        
        print("\nğŸ”„ å¼€å§‹æ¸…ç†ç¼“å­˜...")
        
        # åˆ é™¤æ‰€æœ‰ç›¸å…³é”®
        deleted_count = 0
        for key in unique_keys:
            try:
                redis_conn.delete(key)
                deleted_count += 1
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤é”®å¤±è´¥ {key}: {e}")
        
        print(f"âœ… æˆåŠŸåˆ é™¤ {deleted_count} ä¸ªç¼“å­˜é”®")
        return True
    
    except Exception as e:
        print(f"âŒ æ¸…ç† Redis ç¼“å­˜å¤±è´¥: {e}")
        return False

def clear_all_redis_cache(redis_conn, confirm=False):
    """æ¸…é™¤Redisä¸­çš„æ‰€æœ‰ç¼“å­˜ï¼ˆæ…ç”¨ï¼‰"""
    print("\n" + "=" * 60)
    print("ğŸ—‘ï¸ Redis å®Œå…¨æ¸…ç† (æ‰€æœ‰æ•°æ®)")
    print("=" * 60)
    
    if not redis_conn:
        print("âš ï¸ Redis æœªè¿æ¥ï¼Œè·³è¿‡æ¸…ç†")
        return True
    
    try:
        # è·å–å½“å‰æ•°æ®åº“é”®æ•°é‡
        info = redis_conn.info()
        total_keys = info.get('db0', {}).get('keys', 0)
        
        if total_keys == 0:
            print("ğŸ“­ Redis æ•°æ®åº“ä¸ºç©º")
            return True
        
        print(f"âš ï¸ è­¦å‘Šï¼šè¿™å°†åˆ é™¤ Redis æ•°æ®åº“ä¸­çš„æ‰€æœ‰ {total_keys} ä¸ªé”®")
        print("   è¿™åŒ…æ‹¬æ‰€æœ‰ç¼“å­˜æ•°æ®ï¼Œä¸ä»…ä»…æ˜¯ Arxiv ç›¸å…³çš„")
        
        if not confirm:
            response = input("â“ ç¡®è®¤æ¸…ç©ºæ•´ä¸ª Redis æ•°æ®åº“ï¼Ÿ(è¾“å…¥ 'FLUSH ALL' ç¡®è®¤): ").strip()
            if response != 'FLUSH ALL':
                print("âŒ å®Œå…¨æ¸…ç†å·²å–æ¶ˆ")
                return False
        
        print("\nğŸ”„ å¼€å§‹æ¸…ç©º Redis æ•°æ®åº“...")
        redis_conn.flushdb()
        
        # éªŒè¯ç»“æœ
        new_info = redis_conn.info()
        remaining_keys = new_info.get('db0', {}).get('keys', 0)
        
        if remaining_keys == 0:
            print("âœ… Redis æ•°æ®åº“å·²å®Œå…¨æ¸…ç©º")
            return True
        else:
            print(f"âš ï¸ è­¦å‘Šï¼šä»æœ‰ {remaining_keys} ä¸ªé”®æœªåˆ é™¤")
            return False
    
    except Exception as e:
        print(f"âŒ æ¸…ç©º Redis å¤±è´¥: {e}")
        return False

def backup_data_before_clear(conn):
    """åœ¨æ¸…ç†å‰å¤‡ä»½é‡è¦æ•°æ®"""
    print("\n" + "=" * 60)
    print("ğŸ’¾ æ•°æ®å¤‡ä»½ï¼ˆå¯é€‰ï¼‰")
    print("=" * 60)
    
    try:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_file = f"/tmp/arxiv_backup_{timestamp}.sql"
        
        # å¯¼å‡ºæ•°æ®åˆ°SQLæ–‡ä»¶
        import subprocess
        cmd = [
            'docker', 'exec', 'homesystem-postgres',
            'pg_dump', '-U', 'homesystem', '-d', 'homesystem',
            '-t', 'arxiv_papers', '--data-only', '--inserts'
        ]
        
        with open(backup_file, 'w') as f:
            result = subprocess.run(cmd, stdout=f, stderr=subprocess.PIPE, text=True)
        
        if result.returncode == 0:
            print(f"âœ… æ•°æ®å·²å¤‡ä»½åˆ°: {backup_file}")
            return backup_file
        else:
            print(f"âš ï¸ å¤‡ä»½å¤±è´¥: {result.stderr}")
            return None
    
    except Exception as e:
        print(f"âš ï¸ å¤‡ä»½è¿‡ç¨‹å‡ºé”™: {e}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ—‘ï¸ Arxiv æ•°æ®åº“è°ƒè¯•å·¥å…· - æ•°æ®æ¸…ç†")
    print(f"â° è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("\nâš ï¸ è­¦å‘Šï¼šæ­¤å·¥å…·å°†åˆ é™¤æ‰€æœ‰ Arxiv è®ºæ–‡æ•°æ®ï¼Œè¯·è°¨æ…ä½¿ç”¨ï¼")
    
    # è¿æ¥æ•°æ®åº“
    conn = connect_db()
    if not conn:
        return
    
    redis_conn = connect_redis()
    
    try:
        # æ˜¾ç¤ºå½“å‰æ•°æ®çŠ¶æ€
        total_count, status_info = get_data_stats(conn)
        if total_count is None:
            print(f"âŒ {status_info}")
            return
        
        if total_count == 0:
            print("ğŸ“­ æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®ï¼Œæ— éœ€æ¸…ç†")
            if redis_conn:
                arxiv_keys = []
                for pattern in ['arxiv:*', 'paper:*', 'cache:arxiv:*']:
                    arxiv_keys.extend(redis_conn.keys(pattern))
                if not arxiv_keys:
                    print("ğŸ“­ Redis ä¸­ä¹Ÿæ²¡æœ‰ Arxiv ç›¸å…³ç¼“å­˜")
                    return
            else:
                return
        
        print("\n" + "=" * 60)
        print("ğŸ”§ é€‰æ‹©æ¸…ç†é€‰é¡¹")
        print("=" * 60)
        print("1. ä»…æ¸…ç† PostgreSQL æ•°æ®")
        print("2. ä»…æ¸…ç† Redis Arxiv ç›¸å…³ç¼“å­˜")
        print("3. æ¸…ç† PostgreSQL æ•°æ® + Redis Arxiv ç¼“å­˜")
        print("4. å®Œå…¨æ¸…ç† (PostgreSQL + æ‰€æœ‰ Redis æ•°æ®)")
        print("5. å…ˆå¤‡ä»½å†æ¸…ç† (é€‰é¡¹3 + å¤‡ä»½)")
        print("0. å–æ¶ˆæ“ä½œ")
        
        try:
            choice = input("\nâ“ è¯·é€‰æ‹©æ“ä½œ (0-5): ").strip()
        except KeyboardInterrupt:
            print("\nâŒ æ“ä½œå·²å–æ¶ˆ")
            return
        
        success = True
        
        if choice == '1':
            success = clear_postgres_data(conn)
        elif choice == '2':
            success = clear_redis_cache(redis_conn)
        elif choice == '3':
            success = clear_postgres_data(conn) and clear_redis_cache(redis_conn)
        elif choice == '4':
            success = clear_postgres_data(conn) and clear_all_redis_cache(redis_conn)
        elif choice == '5':
            backup_file = backup_data_before_clear(conn)
            if backup_file:
                print(f"ğŸ’¾ å¤‡ä»½å®Œæˆ: {backup_file}")
            success = clear_postgres_data(conn) and clear_redis_cache(redis_conn)
        elif choice == '0':
            print("âŒ æ“ä½œå·²å–æ¶ˆ")
            return
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            return
        
        print("\n" + "=" * 60)
        if success:
            print("âœ… æ•°æ®æ¸…ç†å®Œæˆ")
        else:
            print("âŒ æ•°æ®æ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
        print("=" * 60)
        
    finally:
        if conn:
            conn.close()
        if redis_conn:
            redis_conn.close()

if __name__ == "__main__":
    main()