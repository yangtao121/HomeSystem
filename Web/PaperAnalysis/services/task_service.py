"""
è®ºæ–‡æ”¶é›†ä»»åŠ¡æœåŠ¡
æ”¯æŒä¸¤ç§æ‰§è¡Œæ¨¡å¼ï¼šå³æ—¶æ‰§è¡Œå’Œåå°å®šæ—¶æ‰§è¡Œ
ä½¿ç”¨çº¿ç¨‹åˆ†ç¦»é˜²æ­¢Webç•Œé¢é˜»å¡
"""
import asyncio
import threading
import uuid
from datetime import datetime
from typing import Dict, Any, Optional, List
from enum import Enum
import sys
import os
from concurrent.futures import ThreadPoolExecutor

# æ·»åŠ HomeSystemåˆ°è·¯å¾„ - ä½¿ç”¨æ›´ç¨³å®šçš„ç›¸å¯¹è·¯å¾„è®¡ç®—
current_dir = os.path.dirname(__file__)
homesystem_root = os.path.normpath(os.path.join(current_dir, "..", ".."))
if homesystem_root not in sys.path:
    sys.path.insert(0, homesystem_root)

from HomeSystem.workflow.paper_gather_task.paper_gather_task import PaperGatherTask, PaperGatherTaskConfig
from HomeSystem.workflow.paper_gather_task.data_manager import PaperGatherDataManager, ConfigVersionManager
from HomeSystem.utility.arxiv.arxiv import ArxivSearchMode
from HomeSystem.workflow.engine import WorkflowEngine
from HomeSystem.workflow.scheduler import TaskScheduler
from HomeSystem.graph.llm_factory import LLMFactory
from loguru import logger
import signal
import time


class TaskMode(Enum):
    """ä»»åŠ¡æ‰§è¡Œæ¨¡å¼"""
    IMMEDIATE = "immediate"  # å³æ—¶æ‰§è¡Œ
    SCHEDULED = "scheduled"  # åå°å®šæ—¶æ‰§è¡Œ


class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    STOPPED = "stopped"


class TaskResult:
    """ä»»åŠ¡æ‰§è¡Œç»“æœ"""
    def __init__(self, task_id: str, status: TaskStatus, 
                 start_time: datetime, end_time: Optional[datetime] = None,
                 result_data: Optional[Dict[str, Any]] = None,
                 error_message: Optional[str] = None,
                 progress: float = 0.0,
                 task_name: Optional[str] = None,
                 search_query: Optional[str] = None,
                 papers_found: Optional[int] = None):
        self.task_id = task_id
        self.status = status
        self.start_time = start_time
        self.end_time = end_time
        self.result_data = result_data or {}
        self.error_message = error_message
        self.progress = progress  # 0.0 - 1.0
        self.task_name = task_name
        self.search_query = search_query
        self.papers_found = papers_found
        
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'task_id': self.task_id,
            'status': self.status.value,
            'start_time': self.start_time.isoformat(),
            'end_time': self.end_time.isoformat() if self.end_time else None,
            'result_data': self.result_data,
            'error_message': self.error_message,
            'progress': self.progress,
            'duration': (self.end_time - self.start_time).total_seconds() if self.end_time else None,
            'task_name': self.task_name,
            'search_query': self.search_query,
            'papers_found': self.papers_found
        }


class PaperGatherService:
    """è®ºæ–‡æ”¶é›†æœåŠ¡ - çº¿ç¨‹å®‰å…¨çš„ä»»åŠ¡ç®¡ç†"""
    
    def __init__(self):
        # åˆå§‹åŒ–è¶…æ—¶è®¾ç½® (30ç§’)
        self.initialization_timeout = 30
        
        # æ•°æ®ç®¡ç†å™¨
        self.data_manager = PaperGatherDataManager()
        
        # çº¿ç¨‹æ± ç”¨äºæ‰§è¡Œä»»åŠ¡ - ä½¿ç”¨æ›´å¥å£®çš„é…ç½®
        self.executor = ThreadPoolExecutor(
            max_workers=3, 
            thread_name_prefix="paper_gather_task"
        )
        self._executor_shutdown = False
        
        # çº¿ç¨‹é”ä¿è¯æ•°æ®å®‰å…¨
        self.lock = threading.Lock()
        
        # åå°è°ƒåº¦å™¨çº¿ç¨‹
        self.scheduler_thread: Optional[threading.Thread] = None
        self.scheduler_running = False
        self.scheduler_shutdown_event = None
        
        # æŒä¹…åŒ–çš„å®šæ—¶ä»»åŠ¡æ•°æ® (task_id -> persistent_task_data)
        self.persistent_scheduled_tasks: Dict[str, Dict[str, Any]] = {}
        
        # ä»»åŠ¡çŠ¶æ€å­˜å‚¨
        self.task_scheduler: Optional[TaskScheduler] = None
        self.scheduled_tasks: Dict[str, PaperGatherTask] = {}
        self.task_results: Dict[str, TaskResult] = {}
        
        # å»¶è¿Ÿåˆå§‹åŒ–LLMå·¥å‚ä»¥é¿å…å¯åŠ¨é˜»å¡
        self.llm_factory = None
        
        # å¯åŠ¨æ—¶å¿«é€ŸåŠ è½½æ•°æ®ï¼Œå»¶è¿Ÿåˆå§‹åŒ–æœåŠ¡
        
        # æ³¨å†Œæ¸…ç†å‡½æ•°ç¡®ä¿èµ„æºé‡Šæ”¾
        import atexit
        atexit.register(self._cleanup_resources)
        self._load_historical_data()
        self._load_persistent_scheduled_tasks_non_blocking()
    
    def _initialize_llm_factory_with_timeout(self) -> bool:
        """å¸¦è¶…æ—¶ä¿æŠ¤çš„LLMå·¥å‚åˆå§‹åŒ–"""
        if self.llm_factory is not None:
            return True
            
        try:
            import threading
            result = [None]  # ä½¿ç”¨åˆ—è¡¨å­˜å‚¨ç»“æœï¼Œå› ä¸ºéå±€éƒ¨å˜é‡
            exception = [None]
            
            def init_llm():
                """åœ¨å•ç‹¬çº¿ç¨‹ä¸­åˆå§‹åŒ–LLMå·¥å‚"""
                try:
                    logger.info("æ­£åœ¨åˆå§‹åŒ–LLMå·¥å‚...")
                    factory = LLMFactory()
                    result[0] = factory
                    logger.info("âœ… LLMå·¥å‚åˆå§‹åŒ–æˆåŠŸ")
                except Exception as e:
                    exception[0] = e
                    logger.error(f"âŒ LLMå·¥å‚åˆå§‹åŒ–å¤±è´¥: {e}")
            
            # åœ¨å•ç‹¬çº¿ç¨‹ä¸­è¿è¡Œåˆå§‹åŒ–
            init_thread = threading.Thread(target=init_llm)
            init_thread.daemon = True
            init_thread.start()
            
            # ç­‰å¾…åˆå§‹åŒ–å®Œæˆæˆ–è¶…æ—¶
            init_thread.join(timeout=self.initialization_timeout)
            
            if init_thread.is_alive():
                logger.error(f"âŒ LLMå·¥å‚åˆå§‹åŒ–è¶…æ—¶ ({self.initialization_timeout}ç§’)")
                return False
            
            if exception[0]:
                logger.error(f"âŒ LLMå·¥å‚åˆå§‹åŒ–å¤±è´¥: {exception[0]}")
                return False
                
            if result[0]:
                self.llm_factory = result[0]
                return True
            else:
                logger.error("âŒ LLMå·¥å‚åˆå§‹åŒ–å¤±è´¥: æœªçŸ¥é”™è¯¯")
                return False
                
        except Exception as e:
            logger.error(f"âŒ LLMå·¥å‚åˆå§‹åŒ–å¼‚å¸¸: {e}")
            return False
    
    def _load_persistent_scheduled_tasks_non_blocking(self):
        """éé˜»å¡åŠ è½½æŒä¹…åŒ–å®šæ—¶ä»»åŠ¡"""
        try:
            persistent_tasks = self.data_manager.load_scheduled_tasks()
            logger.info(f"ä»æŒä¹…åŒ–å­˜å‚¨è·å–åˆ° {len(persistent_tasks)} ä¸ªå®šæ—¶ä»»åŠ¡")
            
            with self.lock:
                loaded_count = 0
                for task_data in persistent_tasks:
                    try:
                        task_id = task_data.get("task_id")
                        status = task_data.get("status", "running")
                        
                        if not task_id:
                            logger.warning(f"è·³è¿‡æ— æ•ˆä»»åŠ¡æ•°æ®: ç¼ºå°‘task_id - {task_data}")
                            continue
                        
                        # åŠ è½½æ‰€æœ‰çŠ¶æ€çš„ä»»åŠ¡åˆ°å†…å­˜ç¼“å­˜ï¼ŒåŒ…æ‹¬å·²åœæ­¢çš„ä»»åŠ¡ç”¨äºæ˜¾ç¤º
                        self.persistent_scheduled_tasks[task_id] = task_data
                        loaded_count += 1
                        
                        # åªæœ‰è¿è¡Œä¸­å’Œæš‚åœçš„ä»»åŠ¡éœ€è¦é‡å¯
                        if status in ["running", "paused"]:
                            logger.info(f"è®°å½•å®šæ—¶ä»»åŠ¡ {task_id}ï¼ŒçŠ¶æ€: {status} (ç¨åé‡å¯)")
                        else:
                            logger.info(f"è®°å½•å®šæ—¶ä»»åŠ¡ {task_id}ï¼ŒçŠ¶æ€: {status} (ä»…æ˜¾ç¤º)")
                    
                    except Exception as e:
                        logger.warning(f"åŠ è½½å•ä¸ªå®šæ—¶ä»»åŠ¡å¤±è´¥: {e}")
                        continue
                
                if loaded_count > 0:
                    logger.info(f"âœ… è®°å½•äº† {loaded_count} ä¸ªå®šæ—¶ä»»åŠ¡åˆ°å†…å­˜ç¼“å­˜")
                else:
                    logger.info("â„¹ï¸  æ²¡æœ‰æ‰¾åˆ°å®šæ—¶ä»»åŠ¡æ•°æ®")
                    
        except Exception as e:
            logger.error(f"âŒ åŠ è½½å®šæ—¶ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
    
    def _refresh_persistent_tasks(self):
        """åˆ·æ–°æŒä¹…åŒ–ä»»åŠ¡æ•°æ®"""
        try:
            # é‡æ–°ä»æŒä¹…åŒ–å­˜å‚¨åŠ è½½æœ€æ–°æ•°æ®
            persistent_tasks = self.data_manager.load_scheduled_tasks()
            
            with self.lock:
                # æ›´æ–°å†…å­˜ç¼“å­˜ï¼Œä½†ä¿ç•™è¿è¡Œæ—¶çŠ¶æ€
                for task_data in persistent_tasks:
                    task_id = task_data.get("task_id")
                    if task_id:
                        # å¦‚æœä»»åŠ¡å·²åœ¨ç¼“å­˜ä¸­ï¼Œæ›´æ–°æ•°æ®ä½†ä¿ç•™é‡è¦è¿è¡Œæ—¶çŠ¶æ€
                        if task_id in self.persistent_scheduled_tasks:
                            # æ›´æ–°æŒä¹…åŒ–æ•°æ®ï¼Œä½†ä¸è¦†ç›–æŸäº›è¿è¡Œæ—¶è®¡ç®—çš„å­—æ®µ
                            existing_data = self.persistent_scheduled_tasks[task_id]
                            task_data['last_refresh'] = datetime.now().isoformat()
                            
                            # ä¿ç•™æŸäº›è¿è¡Œæ—¶çŠ¶æ€
                            if 'next_execution_at' in existing_data and 'next_execution_at' not in task_data:
                                task_data['next_execution_at'] = existing_data['next_execution_at']
                        
                        self.persistent_scheduled_tasks[task_id] = task_data
                        
            logger.debug(f"åˆ·æ–°äº† {len(persistent_tasks)} ä¸ªæŒä¹…åŒ–ä»»åŠ¡æ•°æ®")
            
        except Exception as e:
            logger.warning(f"åˆ·æ–°æŒä¹…åŒ–ä»»åŠ¡æ•°æ®å¤±è´¥: {e}")
    
    def initialize_background_services(self):
        """åœ¨åº”ç”¨å¯åŠ¨ååˆå§‹åŒ–åå°æœåŠ¡"""
        def init_in_background():
            try:
                # åˆå§‹åŒ–LLMå·¥å‚
                if not self._initialize_llm_factory_with_timeout():
                    logger.warning("LLMå·¥å‚åˆå§‹åŒ–å¤±è´¥ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
                
                # é‡å¯æŒä¹…åŒ–çš„å®šæ—¶ä»»åŠ¡
                self._restart_persistent_scheduled_tasks()
                
                logger.info("âœ… åå°æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
                
            except Exception as e:
                logger.error(f"âŒ åå°æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œ
        background_thread = threading.Thread(target=init_in_background)
        background_thread.daemon = True
        background_thread.start()
    
    def _restart_persistent_scheduled_tasks(self):
        """é‡å¯æŒä¹…åŒ–çš„å®šæ—¶ä»»åŠ¡"""
        with self.lock:
            tasks_to_restart = list(self.persistent_scheduled_tasks.items())
        
        logger.info(f"ğŸ”„ å¼€å§‹é‡å¯ {len(tasks_to_restart)} ä¸ªæŒä¹…åŒ–å®šæ—¶ä»»åŠ¡...")
        
        restart_success = 0
        restart_failed = 0
        restart_skipped = 0
        
        for task_id, task_data in tasks_to_restart:
            try:
                status = task_data.get("status")
                task_name = task_data.get('config', {}).get('task_name', 'unknown')
                
                if status == "running":
                    logger.info(f"ğŸ”„ é‡å¯è¿è¡Œä¸­ä»»åŠ¡: {task_id} ({task_name})")
                    success = self._restart_scheduled_task_from_persistence_timeout(task_id, task_data)
                    if success:
                        restart_success += 1
                        logger.info(f"âœ… æˆåŠŸé‡å¯å®šæ—¶ä»»åŠ¡: {task_id} ({task_name})")
                    else:
                        restart_failed += 1
                        logger.warning(f"âš ï¸  å®šæ—¶ä»»åŠ¡é‡å¯å¤±è´¥: {task_id} ({task_name})")
                else:
                    restart_skipped += 1
                    logger.info(f"â­ï¸  è·³è¿‡éè¿è¡ŒçŠ¶æ€ä»»åŠ¡: {task_id} ({task_name}), çŠ¶æ€: {status}")
                    
            except Exception as e:
                restart_failed += 1
                logger.error(f"âŒ é‡å¯å®šæ—¶ä»»åŠ¡ {task_id} æ—¶å‡ºé”™: {e}")
                
        logger.info(f"ğŸ¯ å®šæ—¶ä»»åŠ¡é‡å¯å®Œæˆ: æˆåŠŸ {restart_success} ä¸ª, å¤±è´¥ {restart_failed} ä¸ª, è·³è¿‡ {restart_skipped} ä¸ª")
    
    def _load_historical_data(self):
        """åŠ è½½å†å²æ•°æ®åˆ°å†…å­˜ - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒé”™è¯¯æ¢å¤å’Œæ•°æ®å…¼å®¹æ€§"""
        loaded_count = 0
        error_count = 0
        
        try:
            # åŠ è½½æœ€è¿‘çš„ä»»åŠ¡ç»“æœåˆ°å†…å­˜ï¼ˆç”¨äºçŠ¶æ€æŸ¥è¯¢ï¼‰
            recent_tasks = self.data_manager.load_task_history(limit=50)
            logger.info(f"ä»æ•°æ®åº“è·å–åˆ° {len(recent_tasks)} ä¸ªå†å²ä»»åŠ¡è®°å½•")
            
            with self.lock:
                for task_data in recent_tasks:
                    try:
                        task_id = task_data.get("task_id")
                        if not task_id:
                            logger.warning(f"è·³è¿‡æ— æ•ˆä»»åŠ¡è®°å½•: ç¼ºå°‘task_id - {task_data}")
                            error_count += 1
                            continue
                        
                        # æ•°æ®å…¼å®¹æ€§å¤„ç† - å®‰å…¨è§£ææ—¶é—´å­—æ®µ
                        start_time = self._safe_parse_datetime(
                            task_data.get("start_time"), 
                            f"ä»»åŠ¡ {task_id} çš„start_time"
                        )
                        if not start_time:
                            error_count += 1
                            continue
                        
                        end_time_str = task_data.get("end_time")
                        end_time = None
                        if end_time_str:
                            end_time = self._safe_parse_datetime(
                                end_time_str, 
                                f"ä»»åŠ¡ {task_id} çš„end_time"
                            )
                        
                        # å®‰å…¨è§£æçŠ¶æ€å­—æ®µ
                        status_str = task_data.get("status", "completed")
                        try:
                            status = TaskStatus(status_str)
                        except ValueError:
                            logger.warning(f"ä»»åŠ¡ {task_id} çŠ¶æ€æ— æ•ˆ: {status_str}, ä½¿ç”¨é»˜è®¤çŠ¶æ€ 'completed'")
                            status = TaskStatus.COMPLETED
                        
                        # è®¡ç®—è¿›åº¦
                        progress = 1.0 if status == TaskStatus.COMPLETED else 0.0
                        if status == TaskStatus.FAILED:
                            progress = 0.0
                        elif status == TaskStatus.RUNNING:
                            progress = 0.5  # è¿è¡Œä¸­ä»»åŠ¡è®¾ç½®ä¸º50%è¿›åº¦
                        
                        # åˆ›å»ºTaskResultå¯¹è±¡ï¼Œæå–é…ç½®ä¿¡æ¯
                        config_data = task_data.get("config", {})
                        task_result = TaskResult(
                            task_id=task_id,
                            status=status,
                            start_time=start_time,
                            end_time=end_time,
                            result_data=task_data.get("result", {}),
                            error_message=task_data.get("error_message"),
                            progress=progress,
                            task_name=config_data.get("task_name", "æœªå‘½åä»»åŠ¡"),
                            search_query=config_data.get("search_query", ""),
                            papers_found=task_data.get("result", {}).get("papers_found", 0)
                        )
                        
                        self.task_results[task_id] = task_result
                        loaded_count += 1
                        
                    except Exception as task_error:
                        error_count += 1
                        logger.warning(f"åŠ è½½å•ä¸ªå†å²ä»»åŠ¡å¤±è´¥: {task_error}, ä»»åŠ¡æ•°æ®: {task_data}")
                        continue
            
            if loaded_count > 0:
                logger.info(f"âœ… æˆåŠŸåŠ è½½äº† {loaded_count} ä¸ªå†å²ä»»åŠ¡åˆ°å†…å­˜")
            if error_count > 0:
                logger.warning(f"âš ï¸  è·³è¿‡äº† {error_count} ä¸ªæ— æ•ˆçš„å†å²ä»»åŠ¡è®°å½•")
            
            # å¦‚æœæ‰€æœ‰ä»»åŠ¡éƒ½åŠ è½½å¤±è´¥ï¼Œè®°å½•è¯¦ç»†é”™è¯¯ä½†ä¸é˜»æ­¢åº”ç”¨å¯åŠ¨
            if loaded_count == 0 and len(recent_tasks) > 0:
                logger.error(f"âŒ æ‰€æœ‰ {len(recent_tasks)} ä¸ªå†å²ä»»åŠ¡è®°å½•éƒ½æ— æ³•åŠ è½½ï¼Œä½†åº”ç”¨å°†ç»§ç»­å¯åŠ¨")
                
        except Exception as e:
            logger.error(f"âŒ åŠ è½½å†å²æ•°æ®å¤±è´¥: {e}")
            logger.info("ğŸ”„ åº”ç”¨å°†åœ¨æ²¡æœ‰å†å²æ•°æ®çš„æƒ…å†µä¸‹ç»§ç»­å¯åŠ¨")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè®©åº”ç”¨ç»§ç»­å¯åŠ¨
    
    
    def _restart_scheduled_task_from_persistence(self, task_id: str, task_data: Dict[str, Any]):
        """ä»æŒä¹…åŒ–æ•°æ®é‡å¯å®šæ—¶ä»»åŠ¡ï¼ˆç”¨äºåˆå§‹åŒ–æ—¶è°ƒç”¨ï¼‰"""
        return self._restart_scheduled_task_from_persistence_timeout(task_id, task_data)
    
    def _restart_scheduled_task_from_persistence_timeout(self, task_id: str, task_data: Dict[str, Any]) -> bool:
        """å¸¦è¶…æ—¶ä¿æŠ¤çš„ä»»åŠ¡é‡å¯"""
        try:
            import threading
            timeout_seconds = 15
            result = [None]
            exception = [None]
            
            def restart_task():
                """åœ¨çº¿ç¨‹ä¸­é‡å¯ä»»åŠ¡"""
                try:
                    config_dict = task_data.get("config", {})
                    
                    # éªŒè¯é…ç½®æœ‰æ•ˆæ€§
                    is_valid, error_msg = self.validate_config(config_dict)
                    if not is_valid:
                        exception[0] = f"é…ç½®éªŒè¯å¤±è´¥: {error_msg}"
                        return
                    
                    # é‡æ–°åˆ›å»ºä»»åŠ¡
                    success, _, error_msg = self._create_scheduled_task_internal(task_id, config_dict)
                    if success:
                        result[0] = True
                        logger.info(f"âœ… æˆåŠŸé‡å¯æŒä¹…åŒ–å®šæ—¶ä»»åŠ¡: {task_id}")
                    else:
                        exception[0] = f"é‡å¯å¤±è´¥: {error_msg}"
                        
                except Exception as e:
                    exception[0] = f"é‡å¯å¼‚å¸¸: {str(e)}"
            
            # åœ¨å•ç‹¬çº¿ç¨‹ä¸­è¿è¡Œé‡å¯
            restart_thread = threading.Thread(target=restart_task)
            restart_thread.daemon = True
            restart_thread.start()
            
            # ç­‰å¾…é‡å¯å®Œæˆæˆ–è¶…æ—¶
            restart_thread.join(timeout=timeout_seconds)
            
            if restart_thread.is_alive():
                error_msg = "é‡å¯è¶…æ—¶"
                logger.error(f"âŒ é‡å¯å®šæ—¶ä»»åŠ¡ {task_id} è¶…æ—¶")
                self.data_manager.update_scheduled_task(task_id, {
                    "status": "error",
                    "error_message": error_msg
                })
                return False
            
            if exception[0]:
                logger.error(f"âŒ é‡å¯å®šæ—¶ä»»åŠ¡ {task_id} å¤±è´¥: {exception[0]}")
                self.data_manager.update_scheduled_task(task_id, {
                    "status": "error",
                    "error_message": exception[0]
                })
                return False
                
            if result[0]:
                return True
            else:
                error_msg = "é‡å¯å¤±è´¥: æœªçŸ¥é”™è¯¯"
                logger.error(f"âŒ é‡å¯å®šæ—¶ä»»åŠ¡ {task_id} å¤±è´¥: {error_msg}")
                self.data_manager.update_scheduled_task(task_id, {
                    "status": "error",
                    "error_message": error_msg
                })
                return False
                
        except Exception as e:
            error_msg = f"é‡å¯å¼‚å¸¸: {str(e)}"
            logger.error(f"âŒ é‡å¯å®šæ—¶ä»»åŠ¡ {task_id} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            self.data_manager.update_scheduled_task(task_id, {
                "status": "error",
                "error_message": error_msg
            })
            return False
    
    def _safe_parse_datetime(self, date_str, field_description):
        """å®‰å…¨è§£ææ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²ï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
        if not date_str:
            return None
        
        try:
            # å¦‚æœå·²ç»æ˜¯datetimeå¯¹è±¡ï¼Œç›´æ¥è¿”å›
            if isinstance(date_str, datetime):
                return date_str
            
            # å°è¯•è§£æISOæ ¼å¼
            if isinstance(date_str, str):
                # å¤„ç†å¸¦Zç»“å°¾çš„UTCæ—¶é—´
                if date_str.endswith('Z'):
                    return datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                # å¤„ç†æ ‡å‡†ISOæ ¼å¼
                elif 'T' in date_str:
                    return datetime.fromisoformat(date_str)
                # å¤„ç†å…¶ä»–å¸¸è§æ ¼å¼
                else:
                    # å°è¯•å¸¸è§çš„æ—¥æœŸæ ¼å¼
                    formats = [
                        '%Y-%m-%d %H:%M:%S',
                        '%Y-%m-%d %H:%M:%S.%f',
                        '%Y-%m-%dT%H:%M:%S',
                        '%Y-%m-%dT%H:%M:%S.%f',
                        '%Y-%m-%d'
                    ]
                    
                    for fmt in formats:
                        try:
                            return datetime.strptime(date_str, fmt)
                        except ValueError:
                            continue
            
            logger.warning(f"æ— æ³•è§£ææ—¥æœŸæ—¶é—´: {field_description} = {date_str}")
            return None
            
        except Exception as e:
            logger.warning(f"è§£ææ—¥æœŸæ—¶é—´æ—¶å‡ºé”™: {field_description} = {date_str}, é”™è¯¯: {e}")
            return None
    
    def get_available_models(self) -> List[str]:
        """è·å–å¯ç”¨çš„LLMæ¨¡å‹åˆ—è¡¨ - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒé”™è¯¯æ¢å¤å’Œè¯¦ç»†è¯Šæ–­"""
        try:
            # å¦‚æœLLMFactoryæœªåˆå§‹åŒ–ï¼Œå°è¯•åˆå§‹åŒ–
            if not self.llm_factory:
                logger.info("LLMFactoryæœªåˆå§‹åŒ–ï¼Œå°è¯•åˆå§‹åŒ–...")
                if not self._initialize_llm_factory_with_timeout():
                    logger.error("âŒ LLMFactory åˆå§‹åŒ–å¤±è´¥")
                    return self._get_fallback_models("LLMFactoryåˆå§‹åŒ–å¤±è´¥")
            
            # å°è¯•è·å–æ¨¡å‹åˆ—è¡¨
            chat_models = self.llm_factory.get_available_llm_models()
            
            if not chat_models:
                logger.warning("âš ï¸  LLMFactory è¿”å›äº†ç©ºçš„æ¨¡å‹åˆ—è¡¨")
                # å°è¯•è¯Šæ–­åŸå› 
                self._diagnose_llm_config_issues()
                return self._get_fallback_models("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")
            
            logger.info(f"âœ… æˆåŠŸè·å– {len(chat_models)} ä¸ªå¯ç”¨LLMæ¨¡å‹")
            return chat_models
            
        except ImportError as e:
            logger.error(f"âŒ LLMä¾èµ–åŒ…å¯¼å…¥å¤±è´¥: {e}")
            return self._get_fallback_models(f"ä¾èµ–åŒ…å¯¼å…¥å¤±è´¥: {e}")
        except FileNotFoundError as e:
            logger.error(f"âŒ LLMé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {e}")
            return self._get_fallback_models(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {e}")
        except Exception as e:
            logger.error(f"âŒ è·å–å¯ç”¨æ¨¡å‹å¤±è´¥: {e}")
            # å°è¯•è¯Šæ–­é—®é¢˜
            self._diagnose_llm_config_issues()
            return self._get_fallback_models(f"æœªçŸ¥é”™è¯¯: {e}")
    
    def _get_fallback_models(self, reason: str) -> List[str]:
        """è·å–å¤‡ç”¨æ¨¡å‹åˆ—è¡¨"""
        fallback_models = [
            "deepseek.DeepSeek_V3",
            "ollama.Qwen3_30B", 
            "ollama.DeepSeek_R1_14B"
        ]
        logger.info(f"ğŸ”„ ä½¿ç”¨å¤‡ç”¨æ¨¡å‹åˆ—è¡¨: {fallback_models} (åŸå› : {reason})")
        return fallback_models
    
    def _diagnose_llm_config_issues(self):
        """è¯Šæ–­LLMé…ç½®é—®é¢˜"""
        try:
            import os
            from pathlib import Path
            
            # æ£€æŸ¥é…ç½®æ–‡ä»¶
            # Try Docker path first (2 parents: /app/services/task_service.py -> /app/HomeSystem/...)
            config_path = Path(__file__).parent.parent / "HomeSystem" / "graph" / "config" / "llm_providers.yaml"
            
            # If Docker path doesn't exist, try local development path (3 parents)
            if not config_path.exists():
                config_path = Path(__file__).parent.parent.parent / "HomeSystem" / "graph" / "config" / "llm_providers.yaml"
            
            if not config_path.exists():
                logger.error(f"âŒ LLMé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            else:
                logger.info(f"âœ… LLMé…ç½®æ–‡ä»¶å­˜åœ¨: {config_path}")
            
            # æ£€æŸ¥ç¯å¢ƒå˜é‡
            api_keys = {
                'DEEPSEEK_API_KEY': os.getenv('DEEPSEEK_API_KEY'),
                'SILICONFLOW_API_KEY': os.getenv('SILICONFLOW_API_KEY'),
                'VOLCANO_API_KEY': os.getenv('VOLCANO_API_KEY'),
                'MOONSHOT_API_KEY': os.getenv('MOONSHOT_API_KEY'),
                'OLLAMA_BASE_URL': os.getenv('OLLAMA_BASE_URL')
            }
            
            logger.info("ğŸ” ç¯å¢ƒå˜é‡æ£€æŸ¥:")
            for key, value in api_keys.items():
                if key == 'OLLAMA_BASE_URL':
                    # Ollama URLå¯ä»¥ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å€¼
                    status = "âœ… å·²è®¾ç½®" if value else "â„¹ï¸  ä½¿ç”¨é»˜è®¤å€¼(http://localhost:11434)"
                else:
                    # APIå¯†é’¥æ£€æŸ¥
                    if not value:
                        status = "âŒ æœªè®¾ç½®"
                    elif value.startswith('your_'):
                        status = "âš ï¸  æœªé…ç½®(ä½¿ç”¨ç¤ºä¾‹å€¼)"
                    else:
                        status = "âœ… å·²è®¾ç½®"
                
                logger.info(f"  {key}: {status}")
            
            # æ£€æŸ¥Ollamaè¿æ¥
            self._check_ollama_connection()
            
        except Exception as e:
            logger.error(f"è¯Šæ–­LLMé…ç½®æ—¶å‡ºé”™: {e}")
    
    def _check_ollama_connection(self):
        """æ£€æŸ¥OllamaæœåŠ¡è¿æ¥"""
        try:
            import requests
            import os
            
            ollama_url = os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434')
            
            # å°è¯•è¿æ¥Ollama
            response = requests.get(f"{ollama_url}/api/tags", timeout=5)
            
            if response.status_code == 200:
                models_data = response.json()
                model_count = len(models_data.get('models', []))
                logger.info(f"âœ… OllamaæœåŠ¡è¿æ¥æ­£å¸¸ï¼Œå‘ç° {model_count} ä¸ªæœ¬åœ°æ¨¡å‹")
                
                # åˆ—å‡ºå¯ç”¨çš„æœ¬åœ°æ¨¡å‹
                if model_count > 0:
                    model_names = [model.get('name', 'unknown') for model in models_data.get('models', [])]
                    logger.info(f"   æœ¬åœ°æ¨¡å‹: {', '.join(model_names[:5])}{'...' if model_count > 5 else ''}")
            else:
                logger.warning(f"âš ï¸  OllamaæœåŠ¡å“åº”å¼‚å¸¸: HTTP {response.status_code}")
                
        except requests.ConnectionError:
            logger.warning(f"âš ï¸  æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ ({ollama_url})")
            logger.info("   è¯·æ£€æŸ¥Ollamaæ˜¯å¦å·²å¯åŠ¨: ollama serve")
        except requests.Timeout:
            logger.warning(f"âš ï¸  è¿æ¥OllamaæœåŠ¡è¶…æ—¶ ({ollama_url})")
        except ImportError:
            logger.warning("âš ï¸  requestsåŒ…æœªå®‰è£…ï¼Œæ— æ³•æ£€æŸ¥Ollamaè¿æ¥")
        except Exception as e:
            logger.warning(f"âš ï¸  æ£€æŸ¥Ollamaè¿æ¥æ—¶å‡ºé”™: {e}")
    
    def get_available_search_modes(self) -> List[Dict[str, str]]:
        """è·å–å¯ç”¨çš„æœç´¢æ¨¡å¼åˆ—è¡¨"""
        return [
            {'value': ArxivSearchMode.LATEST.value, 'label': 'æœ€æ–°è®ºæ–‡', 'description': 'æŒ‰æäº¤æ—¥æœŸé™åºæ’åˆ—'},
            {'value': ArxivSearchMode.MOST_RELEVANT.value, 'label': 'æœ€ç›¸å…³', 'description': 'æŒ‰ç›¸å…³æ€§æ’åº'},
            {'value': ArxivSearchMode.RECENTLY_UPDATED.value, 'label': 'æœ€è¿‘æ›´æ–°', 'description': 'æŒ‰æ›´æ–°æ—¥æœŸé™åºæ’åˆ—'},
            {'value': ArxivSearchMode.DATE_RANGE.value, 'label': 'æ—¥æœŸèŒƒå›´', 'description': 'æœç´¢æŒ‡å®šå¹´ä»½èŒƒå›´çš„è®ºæ–‡'},
            {'value': ArxivSearchMode.AFTER_YEAR.value, 'label': 'æŸå¹´ä¹‹å', 'description': 'æœç´¢æŸå¹´ä¹‹åçš„è®ºæ–‡'}
        ]
    
    def validate_config(self, config_dict: Dict[str, Any]) -> tuple[bool, Optional[str]]:
        """éªŒè¯é…ç½®å‚æ•° - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒç±»å‹è½¬æ¢å’Œè¯¦ç»†é”™è¯¯ä¿¡æ¯"""
        try:
            if not isinstance(config_dict, dict):
                return False, "é…ç½®å¿…é¡»æ˜¯å­—å…¸æ ¼å¼"
            
            # æ£€æŸ¥å¿…éœ€å‚æ•°
            required_fields = ['search_query', 'user_requirements', 'llm_model_name', 'task_name']
            for field in required_fields:
                value = config_dict.get(field)
                if not value or (isinstance(value, str) and not value.strip()):
                    if field == 'task_name':
                        return False, "ä»»åŠ¡åç§°ä¸èƒ½ä¸ºç©ºï¼Œè¯·è¾“å…¥æœ‰æ„ä¹‰çš„ä»»åŠ¡åç§°"
                    return False, f"ç¼ºå°‘å¿…éœ€å‚æ•°æˆ–å‚æ•°ä¸ºç©º: {field}"
            
            # ç‰¹æ®ŠéªŒè¯ä»»åŠ¡åç§°é•¿åº¦
            task_name = config_dict.get('task_name', '').strip()
            if len(task_name) < 1 or len(task_name) > 100:
                return False, "ä»»åŠ¡åç§°é•¿åº¦å¿…é¡»åœ¨1-100ä¸ªå­—ç¬¦ä¹‹é—´"
            
            # æ•°å€¼èŒƒå›´éªŒè¯ - æ”¯æŒå­—ç¬¦ä¸²è½¬æ¢
            validation_rules = [
                {
                    'field': 'relevance_threshold',
                    'default': 0.7,
                    'min': 0.0,
                    'max': 1.0,
                    'type': float,
                    'description': 'ç›¸å…³æ€§é˜ˆå€¼'
                },
                {
                    'field': 'deep_analysis_threshold', 
                    'default': 0.8,
                    'min': 0.0,
                    'max': 1.0,
                    'type': float,
                    'description': 'æ·±åº¦åˆ†æé˜ˆå€¼'
                },
                {
                    'field': 'max_papers_per_search',
                    'default': 20,
                    'min': 1,
                    'max': 30000,
                    'type': int,
                    'description': 'æ¯æ¬¡æœç´¢çš„æœ€å¤§è®ºæ–‡æ•°'
                },
                {
                    'field': 'ocr_char_limit_for_analysis',
                    'default': 10000,
                    'min': 1000,
                    'max': 50000,
                    'type': int,
                    'description': 'OCRå­—ç¬¦åˆ†æé™åˆ¶'
                }
            ]
            
            for rule in validation_rules:
                field = rule['field']
                value = config_dict.get(field, rule['default'])
                
                # ç±»å‹è½¬æ¢å’ŒéªŒè¯
                try:
                    if rule['type'] == float:
                        converted_value = float(value)
                    elif rule['type'] == int:
                        converted_value = int(float(value))  # æ”¯æŒ "20.0" -> 20
                    else:
                        converted_value = value
                    
                    # èŒƒå›´æ£€æŸ¥
                    if not (rule['min'] <= converted_value <= rule['max']):
                        return False, f"{rule['description']} å¿…é¡»åœ¨ {rule['min']}-{rule['max']} èŒƒå›´å†…ï¼Œå½“å‰å€¼: {converted_value}"
                    
                    # æ›´æ–°é…ç½®ä¸­çš„å€¼ï¼ˆç¡®ä¿ç±»å‹æ­£ç¡®ï¼‰
                    config_dict[field] = converted_value
                    
                except (ValueError, TypeError) as e:
                    return False, f"{rule['description']} æ ¼å¼æ— æ•ˆ: {value} (é”™è¯¯: {e})"
            
            # å¸ƒå°”å€¼éªŒè¯å’Œè½¬æ¢
            boolean_fields = ['enable_deep_analysis']
            for field in boolean_fields:
                if field in config_dict:
                    value = config_dict[field]
                    if isinstance(value, str):
                        if value.lower() in ['true', '1', 'yes', 'on']:
                            config_dict[field] = True
                        elif value.lower() in ['false', '0', 'no', 'off']:
                            config_dict[field] = False
                        else:
                            return False, f"{field} å¿…é¡»æ˜¯å¸ƒå°”å€¼"
                    elif not isinstance(value, bool):
                        return False, f"{field} å¿…é¡»æ˜¯å¸ƒå°”å€¼"
            
            # æ¨¡å‹å¯ç”¨æ€§æ£€æŸ¥ï¼ˆä½¿ç”¨æ›´å®½æ¾çš„æ£€æŸ¥ï¼‰
            llm_model_name = config_dict.get('llm_model_name')
            available_models = self.get_available_models()
            
            if llm_model_name not in available_models:
                # è®°å½•è­¦å‘Šä½†ä¸é˜»æ­¢é…ç½®ï¼ˆå…è®¸ç”¨æˆ·ä½¿ç”¨æ–°æ¨¡å‹ï¼‰
                logger.warning(f"âš ï¸  LLMæ¨¡å‹ '{llm_model_name}' å½“å‰ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­")
                logger.info(f"   å¯ç”¨æ¨¡å‹: {', '.join(available_models[:5])}{'...' if len(available_models) > 5 else ''}")
                # ä¸è¿”å›é”™è¯¯ï¼Œå…è®¸ç”¨æˆ·ä½¿ç”¨æœªåœ¨åˆ—è¡¨ä¸­çš„æ¨¡å‹
            
            # éªŒè¯æœç´¢æ¨¡å¼ç›¸å…³å‚æ•°
            search_mode = config_dict.get('search_mode', 'latest')
            try:
                mode_enum = ArxivSearchMode(search_mode)
            except ValueError:
                available_modes = [mode.value for mode in ArxivSearchMode]
                return False, f"æ— æ•ˆçš„æœç´¢æ¨¡å¼: {search_mode}ï¼Œå¯ç”¨æ¨¡å¼: {', '.join(available_modes)}"
            
            # éªŒè¯æ—¥æœŸèŒƒå›´æœç´¢å‚æ•°
            if mode_enum == ArxivSearchMode.DATE_RANGE:
                start_year = config_dict.get('start_year')
                end_year = config_dict.get('end_year')
                
                if start_year is None or end_year is None:
                    return False, "æ—¥æœŸèŒƒå›´æœç´¢æ¨¡å¼éœ€è¦æä¾›èµ·å§‹å¹´ä»½å’Œç»“æŸå¹´ä»½"
                
                # ç±»å‹è½¬æ¢
                try:
                    start_year = int(start_year)
                    end_year = int(end_year)
                    config_dict['start_year'] = start_year
                    config_dict['end_year'] = end_year
                except (ValueError, TypeError):
                    return False, "èµ·å§‹å¹´ä»½å’Œç»“æŸå¹´ä»½å¿…é¡»æ˜¯æ•´æ•°"
                
                # é€»è¾‘æ£€æŸ¥
                if start_year > end_year:
                    return False, f"èµ·å§‹å¹´ä»½ ({start_year}) ä¸èƒ½å¤§äºç»“æŸå¹´ä»½ ({end_year})"
                if start_year < 1991:  # ArXiv 1991å¹´å¼€å§‹
                    return False, f"èµ·å§‹å¹´ä»½ ({start_year}) ä¸èƒ½æ—©äº1991å¹´"
                
                current_year = datetime.now().year
                if end_year > current_year:
                    return False, f"ç»“æŸå¹´ä»½ ({end_year}) ä¸èƒ½å¤§äºå½“å‰å¹´ä»½ ({current_year})"
                
            # éªŒè¯æŸå¹´ä¹‹åæœç´¢å‚æ•°
            elif mode_enum == ArxivSearchMode.AFTER_YEAR:
                after_year = config_dict.get('after_year')
                if after_year is None:
                    return False, "æŸå¹´ä¹‹åæœç´¢æ¨¡å¼éœ€è¦æä¾›after_yearå‚æ•°"
                
                try:
                    after_year = int(after_year)
                    config_dict['after_year'] = after_year
                except (ValueError, TypeError):
                    return False, "after_yearå¿…é¡»æ˜¯æ•´æ•°"
                
                if after_year < 1991:
                    return False, f"after_year ({after_year}) ä¸èƒ½æ—©äº1991å¹´"
                
                current_year = datetime.now().year
                if after_year > current_year:
                    return False, f"after_year ({after_year}) ä¸èƒ½å¤§äºå½“å‰å¹´ä»½ ({current_year})"
            
            logger.info("âœ… é…ç½®éªŒè¯é€šè¿‡")
            return True, None
            
        except Exception as e:
            error_msg = f"é…ç½®éªŒè¯æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}"
            logger.error(error_msg)
            return False, error_msg
    
    def _run_task_async(self, task_id: str, config_dict: Dict[str, Any]):
        """åœ¨å•ç‹¬çº¿ç¨‹ä¸­å¼‚æ­¥è¿è¡Œä»»åŠ¡"""
        def run_in_thread():
            # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                # è¿è¡Œå¼‚æ­¥ä»»åŠ¡
                result = loop.run_until_complete(self._execute_task_internal(task_id, config_dict))
                return result
            finally:
                loop.close()
        
        return run_in_thread
    
    async def _execute_task_internal(self, task_id: str, config_dict: Dict[str, Any]) -> TaskResult:
        """å†…éƒ¨ä»»åŠ¡æ‰§è¡Œé€»è¾‘"""
        task_result = None
        
        with self.lock:
            task_result = self.task_results.get(task_id)
        
        if not task_result:
            return None
        
        try:
            logger.info(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task_id}")
            
            # æ›´æ–°çŠ¶æ€ä¸ºè¿è¡Œä¸­
            with self.lock:
                task_result.status = TaskStatus.RUNNING
                task_result.progress = 0.1
            
            # åˆ›å»ºPaperGatherTaskConfig
            # ä¸ºå³æ—¶æ‰§è¡Œè®¾ç½®interval_secondsä¸º0ï¼Œé¿å…é‡å¤å‚æ•°
            config_dict_copy = config_dict.copy()
            config_dict_copy['interval_seconds'] = 0  # å³æ—¶æ‰§è¡Œä¸éœ€è¦é—´éš”
            
            # è¿‡æ»¤æ‰éPaperGatherTaskConfigå‚æ•°
            valid_params = {
                'interval_seconds', 'search_query', 'max_papers_per_search', 
                'user_requirements', 'llm_model_name', 'abstract_analysis_model',
                'full_paper_analysis_model', 'deep_analysis_model', 'vision_model',
                'relevance_threshold', 'deep_analysis_threshold', 'ocr_char_limit_for_analysis',
                'enable_deep_analysis', 'custom_settings',
                # ç”¨æˆ·æç¤ºè¯å‚æ•°
                'enable_user_prompt', 'user_prompt',
                # è¿œç¨‹OCRå‚æ•°
                'enable_remote_ocr', 'remote_ocr_endpoint', 'remote_ocr_timeout',
                # è§†é¢‘åˆ†æå‚æ•°
                'enable_video_analysis', 'video_analysis_model',
                # æ–°å¢æœç´¢æ¨¡å¼ç›¸å…³å‚æ•°
                'search_mode', 'start_year', 'end_year', 'after_year',
                # ä»»åŠ¡è¿½è¸ªç›¸å…³å‚æ•°
                'task_name', 'task_id'
            }
            filtered_config = {k: v for k, v in config_dict_copy.items() if k in valid_params}
            
            # è®°å½•æ¨¡å‹é…ç½®å‚æ•°ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            model_params = {k: v for k, v in filtered_config.items() 
                          if k in ['llm_model_name', 'deep_analysis_model', 'vision_model', 
                                  'enable_deep_analysis']}
            logger.info(f"ğŸ¯ ä»»åŠ¡ {task_id} ä½¿ç”¨çš„æ¨¡å‹é…ç½®: {model_params}")
            
            # æ·»åŠ ä»»åŠ¡è¿½è¸ªä¿¡æ¯
            filtered_config['task_id'] = task_id  # ä½¿ç”¨ç”Ÿæˆçš„ä»»åŠ¡ID
            if 'task_name' not in filtered_config:
                filtered_config['task_name'] = 'paper_gather'  # é»˜è®¤ä»»åŠ¡åç§°
            
            # è½¬æ¢æœç´¢æ¨¡å¼å­—ç¬¦ä¸²ä¸ºæšä¸¾
            if 'search_mode' in filtered_config and isinstance(filtered_config['search_mode'], str):
                filtered_config['search_mode'] = ArxivSearchMode(filtered_config['search_mode'])
            
            config = PaperGatherTaskConfig(**filtered_config)
            
            # åˆ›å»ºå¹¶æ‰§è¡Œä»»åŠ¡ï¼Œå³æ—¶ä»»åŠ¡ä¸å»¶è¿Ÿé¦–æ¬¡è¿è¡Œ
            paper_task = PaperGatherTask(config=config, delay_first_run=False)
            
            # æ›´æ–°è¿›åº¦
            with self.lock:
                task_result.progress = 0.3
            
            # æ‰§è¡Œä»»åŠ¡
            result = await paper_task.run()
            
            # ä»»åŠ¡å®Œæˆï¼Œæ›´æ–°ç»“æœ
            with self.lock:
                task_result.status = TaskStatus.COMPLETED
                task_result.end_time = datetime.now()
                task_result.result_data = result
                task_result.progress = 1.0
                # æ›´æ–°æ‰¾åˆ°çš„è®ºæ–‡æ•°é‡
                task_result.papers_found = result.get("papers_found", 0)
            
            # ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨
            self._save_task_to_persistent_storage(task_id, config_dict_copy, result, 
                                                 task_result.start_time, task_result.end_time, "completed")
            
            logger.info(f"ä»»åŠ¡æ‰§è¡Œå®Œæˆ: {task_id}")
            return task_result
            
        except Exception as e:
            error_msg = f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(f"{error_msg} (ä»»åŠ¡ID: {task_id})")
            
            with self.lock:
                task_result.status = TaskStatus.FAILED
                task_result.end_time = datetime.now()
                task_result.error_message = error_msg
                task_result.progress = 0.0
            
            # ä¿å­˜å¤±è´¥ä»»åŠ¡åˆ°æŒä¹…åŒ–å­˜å‚¨
            self._save_task_to_persistent_storage(task_id, config_dict_copy, {"error": error_msg}, 
                                                 task_result.start_time, task_result.end_time, "failed")
            
            return task_result
    
    def _save_task_to_persistent_storage(self, task_id: str, config_dict: Dict[str, Any], 
                                       result_data: Dict[str, Any], start_time: datetime, 
                                       end_time: datetime, status: str):
        """ä¿å­˜ä»»åŠ¡åˆ°æŒä¹…åŒ–å­˜å‚¨"""
        try:
            # åœ¨åå°çº¿ç¨‹ä¸­å¼‚æ­¥ä¿å­˜ï¼Œé¿å…é˜»å¡ä¸»æµç¨‹
            def save_async():
                self.data_manager.save_task_complete(
                    task_id=task_id,
                    config_dict=config_dict,
                    result_data=result_data,
                    start_time=start_time,
                    end_time=end_time,
                    status=status
                )
            
            # æäº¤åˆ°çº¿ç¨‹æ± æ‰§è¡Œ
            self.executor.submit(save_async)
            
        except Exception as e:
            logger.error(f"æäº¤æŒä¹…åŒ–å­˜å‚¨ä»»åŠ¡å¤±è´¥: {e}")
    
    def start_immediate_task(self, config_dict: Dict[str, Any]) -> str:
        """
        å¯åŠ¨å³æ—¶æ‰§è¡Œä»»åŠ¡ - éé˜»å¡æ–¹å¼
        è¿”å›ä»»åŠ¡IDï¼Œä»»åŠ¡åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œ
        """
        task_id = str(uuid.uuid4())
        start_time = datetime.now()
        
        # åˆ›å»ºä»»åŠ¡ç»“æœè®°å½•ï¼ŒåŒ…å«é…ç½®ä¿¡æ¯
        task_result = TaskResult(
            task_id=task_id,
            status=TaskStatus.PENDING,
            start_time=start_time,
            task_name=config_dict.get("task_name", "æœªå‘½åä»»åŠ¡"),
            search_query=config_dict.get("search_query", ""),
            papers_found=0
        )
        
        with self.lock:
            self.task_results[task_id] = task_result
        
        # æäº¤ä»»åŠ¡åˆ°çº¿ç¨‹æ± æ‰§è¡Œ
        future = self.executor.submit(self._run_task_async(task_id, config_dict))
        
        logger.info(f"å³æ—¶ä»»åŠ¡å·²æäº¤åˆ°çº¿ç¨‹æ± : {task_id}")
        return task_id
    
    def start_scheduled_task(self, config_dict: Dict[str, Any]) -> tuple[bool, str, Optional[str]]:
        """
        å¯åŠ¨åå°å®šæ—¶ä»»åŠ¡ - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒæŒä¹…åŒ–
        """
        task_id = str(uuid.uuid4())
        try:
            logger.info(f"ğŸš€ å¼€å§‹åˆ›å»ºå®šæ—¶ä»»åŠ¡: {task_id}")
            logger.debug(f"ä»»åŠ¡é…ç½®: {config_dict}")
            
            # å…ˆä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨
            logger.info(f"ğŸ“ ä¿å­˜ä»»åŠ¡åˆ°æŒä¹…åŒ–å­˜å‚¨: {task_id}")
            success = self.data_manager.save_scheduled_task(task_id, config_dict, "running")
            if not success:
                error_msg = "ä¿å­˜å®šæ—¶ä»»åŠ¡åˆ°æŒä¹…åŒ–å­˜å‚¨å¤±è´¥"
                logger.error(f"âŒ {error_msg}")
                return False, "", error_msg
            
            logger.info(f"âœ… ä»»åŠ¡å·²ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨: {task_id}")
            
            # åˆ›å»ºè¿è¡Œæ—¶ä»»åŠ¡
            logger.info(f"âš™ï¸  åˆ›å»ºè¿è¡Œæ—¶ä»»åŠ¡: {task_id}")
            success, _, error_msg = self._create_scheduled_task_internal(task_id, config_dict)
            if success:
                # æ›´æ–°æŒä¹…åŒ–æ•°æ®ç¼“å­˜
                with self.lock:
                    self.persistent_scheduled_tasks[task_id] = {
                        "task_id": task_id,
                        "config": config_dict,
                        "status": "running",
                        "created_at": datetime.now().isoformat(),
                        "updated_at": datetime.now().isoformat(),
                        "execution_count": 0,
                        "last_executed_at": None,
                        "next_execution_at": None,
                        "error_message": None
                    }
                
                logger.info(f"ğŸ‰ å®šæ—¶ä»»åŠ¡åˆ›å»ºæˆåŠŸ: {task_id} (åç§°: {config_dict.get('task_name', 'unknown')})")
                return True, task_id, None
            else:
                logger.error(f"âŒ è¿è¡Œæ—¶ä»»åŠ¡åˆ›å»ºå¤±è´¥: {task_id}, é”™è¯¯: {error_msg}")
                # åˆ›å»ºå¤±è´¥ï¼Œåˆ é™¤æŒä¹…åŒ–æ•°æ®
                logger.info(f"ğŸ§¹ æ¸…ç†æŒä¹…åŒ–æ•°æ®: {task_id}")
                self.data_manager.delete_scheduled_task(task_id)
                return False, "", error_msg
            
        except Exception as e:
            error_msg = f"å¯åŠ¨åå°ä»»åŠ¡å¤±è´¥: {str(e)}"
            logger.error(f"âŒ å®šæ—¶ä»»åŠ¡åˆ›å»ºå¼‚å¸¸: {task_id}, é”™è¯¯: {error_msg}")
            logger.exception("å®šæ—¶ä»»åŠ¡åˆ›å»ºå¼‚å¸¸è¯¦æƒ…:")
            
            # ç¡®ä¿æ¸…ç†éƒ¨åˆ†åˆ›å»ºçš„èµ„æº
            try:
                self.data_manager.delete_scheduled_task(task_id)
                with self.lock:
                    if task_id in self.persistent_scheduled_tasks:
                        del self.persistent_scheduled_tasks[task_id]
                    if task_id in self.scheduled_tasks:
                        del self.scheduled_tasks[task_id]
                logger.info(f"ğŸ§¹ å·²æ¸…ç†å¼‚å¸¸ä»»åŠ¡çš„æ®‹ç•™æ•°æ®: {task_id}")
            except Exception as cleanup_error:
                logger.warning(f"âš ï¸  æ¸…ç†å¼‚å¸¸ä»»åŠ¡æ•°æ®å¤±è´¥: {cleanup_error}")
                
            return False, "", error_msg
    
    def _create_scheduled_task_internal(self, task_id: str, config_dict: Dict[str, Any]) -> tuple[bool, str, Optional[str]]:
        """
        å†…éƒ¨æ–¹æ³•ï¼šåˆ›å»ºå®šæ—¶ä»»åŠ¡çš„è¿è¡Œæ—¶å®ä¾‹
        """
        try:
            # åˆ›å»ºPaperGatherTaskConfigï¼ŒåŒ…å«å®šæ—¶é—´éš”
            # è¿‡æ»¤æ‰éPaperGatherTaskConfigå‚æ•°
            valid_params = {
                'interval_seconds', 'search_query', 'max_papers_per_search', 
                'user_requirements', 'llm_model_name', 'abstract_analysis_model',
                'full_paper_analysis_model', 'deep_analysis_model', 'vision_model',
                'relevance_threshold', 'deep_analysis_threshold', 'ocr_char_limit_for_analysis',
                'enable_deep_analysis', 'custom_settings',
                # ç”¨æˆ·æç¤ºè¯å‚æ•°
                'enable_user_prompt', 'user_prompt',
                # è¿œç¨‹OCRå‚æ•°
                'enable_remote_ocr', 'remote_ocr_endpoint', 'remote_ocr_timeout',
                # è§†é¢‘åˆ†æå‚æ•°
                'enable_video_analysis', 'video_analysis_model',
                # æ–°å¢æœç´¢æ¨¡å¼ç›¸å…³å‚æ•°
                'search_mode', 'start_year', 'end_year', 'after_year',
                # ä»»åŠ¡è¿½è¸ªç›¸å…³å‚æ•°
                'task_name', 'task_id'
            }
            filtered_config = {k: v for k, v in config_dict.items() if k in valid_params}
            
            # è®°å½•æ¨¡å‹é…ç½®å‚æ•°ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            model_params = {k: v for k, v in filtered_config.items() 
                          if k in ['llm_model_name', 'deep_analysis_model', 'vision_model', 
                                  'enable_deep_analysis']}
            logger.info(f"ğŸ¯ å®šæ—¶ä»»åŠ¡ {task_id} ä½¿ç”¨çš„æ¨¡å‹é…ç½®: {model_params}")
            
            # æ·»åŠ ä»»åŠ¡è¿½è¸ªä¿¡æ¯
            filtered_config['task_id'] = task_id  # ä½¿ç”¨æŒ‡å®šçš„ä»»åŠ¡ID
            if 'task_name' not in filtered_config:
                filtered_config['task_name'] = 'paper_gather_scheduled'  # å®šæ—¶ä»»åŠ¡åç§°
            
            # è½¬æ¢æœç´¢æ¨¡å¼å­—ç¬¦ä¸²ä¸ºæšä¸¾
            if 'search_mode' in filtered_config and isinstance(filtered_config['search_mode'], str):
                filtered_config['search_mode'] = ArxivSearchMode(filtered_config['search_mode'])
            
            config = PaperGatherTaskConfig(**filtered_config)
            
            # åˆ›å»ºä»»åŠ¡ï¼Œå¯ç”¨å»¶è¿Ÿé¦–æ¬¡è¿è¡Œ
            paper_task = PaperGatherTask(config=config, delay_first_run=True)
            
            with self.lock:
                self.scheduled_tasks[task_id] = paper_task
            
            # å¦‚æœTaskScheduleræœªåˆå§‹åŒ–æˆ–æœªè¿è¡Œï¼Œåˆ™å¯åŠ¨
            if not self.scheduler_running:
                self._start_task_scheduler()
            
            # ç­‰å¾…è°ƒåº¦å™¨åˆå§‹åŒ–å®Œæˆï¼ˆæœ€å¤šç­‰å¾…5ç§’ï¼‰
            import time
            max_wait = 5.0
            wait_interval = 0.1
            waited = 0.0
            
            while self.task_scheduler is None and waited < max_wait:
                time.sleep(wait_interval)
                waited += wait_interval
            
            # æ·»åŠ ä»»åŠ¡åˆ°è°ƒåº¦å™¨
            if self.task_scheduler:
                self.task_scheduler.add_task(paper_task)
            else:
                raise Exception("ä»»åŠ¡è°ƒåº¦å™¨åˆå§‹åŒ–è¶…æ—¶")
            
            logger.info(f"è¿è¡Œæ—¶å®šæ—¶ä»»åŠ¡å·²åˆ›å»º: {task_id}, é—´éš”: {config.interval_seconds}ç§’")
            return True, task_id, None
            
        except Exception as e:
            error_msg = f"åˆ›å»ºè¿è¡Œæ—¶å®šæ—¶ä»»åŠ¡å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return False, "", error_msg
    
    def _start_task_scheduler(self):
        """å¯åŠ¨TaskScheduleråœ¨åå°çº¿ç¨‹ï¼ˆä¸ä½¿ç”¨ä¿¡å·å¤„ç†ï¼‰"""
        if self.scheduler_running:
            return
        
        def run_scheduler():
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                self.task_scheduler = TaskScheduler()
                self.scheduler_shutdown_event = asyncio.Event()
                self.scheduler_running = True
                logger.info("TaskSchedulerå·²å¯åŠ¨")
                
                # å¯åŠ¨è°ƒåº¦å™¨
                loop.run_until_complete(self._run_scheduler_loop())
            except Exception as e:
                logger.error(f"TaskSchedulerè¿è¡Œå¼‚å¸¸: {e}")
            finally:
                self.scheduler_running = False
                loop.close()
        
        self.scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
        self.scheduler_thread.start()
    
    async def _run_scheduler_loop(self):
        """è¿è¡Œè°ƒåº¦å™¨å¾ªç¯ï¼ˆä¸ä½¿ç”¨ä¿¡å·å¤„ç†ï¼‰"""
        try:
            # å¯åŠ¨è°ƒåº¦å™¨ä»»åŠ¡
            scheduler_task = asyncio.create_task(self.task_scheduler.start())
            
            # åœ¨Webç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬ä¸ä½¿ç”¨ä¿¡å·å¤„ç†ï¼Œè€Œæ˜¯è®©ä»»åŠ¡æŒç»­è¿è¡Œ
            # è°ƒåº¦å™¨ä¼šåœ¨å®ˆæŠ¤çº¿ç¨‹ä¸­è¿è¡Œï¼Œå½“ä¸»è¿›ç¨‹ç»“æŸæ—¶è‡ªåŠ¨ç»ˆæ­¢
            await scheduler_task
            
        except Exception as e:
            logger.error(f"è°ƒåº¦å™¨å¾ªç¯å‡ºé”™: {e}")
        finally:
            logger.info("TaskSchedulerå·²åœæ­¢")
    
    def stop_scheduled_task(self, task_id: str) -> tuple[bool, Optional[str]]:
        """åœæ­¢åå°å®šæ—¶ä»»åŠ¡ - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒæŒä¹…åŒ–"""
        try:
            with self.lock:
                # æ£€æŸ¥è¿è¡Œæ—¶ä»»åŠ¡
                if task_id in self.scheduled_tasks:
                    task = self.scheduled_tasks[task_id]
                    
                    # ä»è°ƒåº¦å™¨ä¸­ç§»é™¤ä»»åŠ¡
                    if self.task_scheduler:
                        self.task_scheduler.remove_task(task.name)
                    
                    # æ¸…ç†è¿è¡Œæ—¶ä»»åŠ¡è®°å½•
                    del self.scheduled_tasks[task_id]
                
                # æ£€æŸ¥æŒä¹…åŒ–ä»»åŠ¡
                if task_id in self.persistent_scheduled_tasks:
                    # æ¸…ç†æŒä¹…åŒ–ç¼“å­˜
                    del self.persistent_scheduled_tasks[task_id]
            
            # æ›´æ–°æŒä¹…åŒ–å­˜å‚¨çŠ¶æ€
            success = self.data_manager.update_scheduled_task(task_id, {
                "status": "stopped",
                "error_message": None
            })
            
            if not success:
                logger.warning(f"æ›´æ–°æŒä¹…åŒ–å®šæ—¶ä»»åŠ¡çŠ¶æ€å¤±è´¥: {task_id}")
            
            logger.info(f"åå°å®šæ—¶ä»»åŠ¡å·²åœæ­¢: {task_id}")
            return True, None
            
        except Exception as e:
            error_msg = f"åœæ­¢åå°ä»»åŠ¡å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return False, error_msg
    
    def get_scheduled_tasks(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰åå°å®šæ—¶ä»»åŠ¡çŠ¶æ€ - å¢å¼ºç‰ˆæœ¬ï¼ŒåŒ…å«æŒä¹…åŒ–ä¿¡æ¯"""
        try:
            # é¦–å…ˆåˆ·æ–°æŒä¹…åŒ–ä»»åŠ¡æ•°æ®ï¼Œç¡®ä¿æ˜¾ç¤ºæœ€æ–°æ•°æ®
            self._refresh_persistent_tasks()
            
            tasks = []
            with self.lock:
                # éå†æŒä¹…åŒ–ä»»åŠ¡æ•°æ®ï¼ˆè¿™æ˜¯æƒå¨æ•°æ®æºï¼‰
                for task_id, persistent_data in self.persistent_scheduled_tasks.items():
                    # è·å–è¿è¡Œæ—¶ä»»åŠ¡ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    runtime_task = self.scheduled_tasks.get(task_id)
                    next_execution_at = None
                    next_run_in_seconds = 0
                    
                    if runtime_task:
                        # ä»è¿è¡Œæ—¶ä»»åŠ¡è·å–ç²¾ç¡®çš„ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
                        try:
                            next_run_time = runtime_task.get_next_run_time()
                            if next_run_time:
                                next_execution_at = next_run_time.isoformat()
                                next_run_in_seconds = max(0, (next_run_time - datetime.now()).total_seconds())
                        except Exception as e:
                            logger.warning(f"è·å–ä»»åŠ¡ {task_id} ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´å¤±è´¥: {e}")
                    
                    task_info = {
                        'task_id': task_id,
                        'name': persistent_data.get('config', {}).get('task_name', 'paper_gather_scheduled'),
                        'interval_seconds': persistent_data.get('config', {}).get('interval_seconds', 3600),
                        'config': persistent_data.get('config', {}),
                        'status': persistent_data.get('status', 'unknown'),
                        'created_at': persistent_data.get('created_at'),
                        'updated_at': persistent_data.get('updated_at'),
                        'execution_count': persistent_data.get('execution_count', 0),
                        'last_executed_at': persistent_data.get('last_executed_at'),
                        'next_execution_at': next_execution_at or persistent_data.get('next_execution_at'),
                        'next_run_in_seconds': next_run_in_seconds,
                        'error_message': persistent_data.get('error_message'),
                        'is_running': task_id in self.scheduled_tasks,  # è¿è¡Œæ—¶çŠ¶æ€
                        'task_is_executing': runtime_task.is_running if (runtime_task and hasattr(runtime_task, 'is_running')) else False,
                        'manual_trigger_requested': runtime_task.manual_trigger_requested if (runtime_task and hasattr(runtime_task, 'manual_trigger_requested')) else False
                    }
                    tasks.append(task_info)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰è¿è¡Œæ—¶ä»»åŠ¡ä½†æ²¡æœ‰æŒä¹…åŒ–æ•°æ®çš„æƒ…å†µï¼ˆå¼‚å¸¸æƒ…å†µï¼‰
                for task_id, task in self.scheduled_tasks.items():
                    if task_id not in self.persistent_scheduled_tasks:
                        logger.warning(f"å‘ç°æœªæŒä¹…åŒ–çš„è¿è¡Œæ—¶ä»»åŠ¡: {task_id}")
                        task_info = {
                            'task_id': task_id,
                            'name': getattr(task, 'name', f'task_{task_id[:8]}'),
                            'interval_seconds': getattr(task, 'interval_seconds', 3600),
                            'config': task.config.get_config_dict() if hasattr(task.config, 'get_config_dict') else {},
                            'status': 'running',
                            'created_at': None,
                            'updated_at': None,
                            'execution_count': 0,
                            'last_executed_at': None,
                            'next_execution_at': None,
                            'error_message': None,
                            'is_running': True,
                            'task_is_executing': False,
                            'manual_trigger_requested': False
                        }
                        tasks.append(task_info)
            
            # æŒ‰åˆ›å»ºæ—¶é—´æ’åº
            tasks.sort(key=lambda x: x.get('created_at', ''), reverse=True)
            logger.info(f"è·å–åˆ° {len(tasks)} ä¸ªå®šæ—¶ä»»åŠ¡ç”¨äºæ˜¾ç¤º")
            return tasks
            
        except Exception as e:
            logger.error(f"è·å–å®šæ—¶ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def get_running_tasks_count(self) -> int:
        """è·å–è¿è¡Œä¸­ä»»åŠ¡çš„æ€»æ•°ï¼ˆåŒ…æ‹¬å³æ—¶ä»»åŠ¡å’Œå®šæ—¶ä»»åŠ¡ï¼‰"""
        running_count = 0
        
        with self.lock:
            # ç»Ÿè®¡è¿è¡Œä¸­çš„å³æ—¶ä»»åŠ¡
            for task_result in self.task_results.values():
                if task_result.status in [TaskStatus.PENDING, TaskStatus.RUNNING]:
                    running_count += 1
            
            # ç»Ÿè®¡å®šæ—¶ä»»åŠ¡ï¼ˆéƒ½è§†ä¸ºè¿è¡Œä¸­ï¼‰
            running_count += len(self.scheduled_tasks)
        
        return running_count
    
    def get_running_tasks_detail(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰è¿è¡Œä¸­ä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯"""
        running_tasks = []
        
        with self.lock:
            # æ·»åŠ è¿è¡Œä¸­çš„å³æ—¶ä»»åŠ¡
            for task_id, task_result in self.task_results.items():
                if task_result.status in [TaskStatus.PENDING, TaskStatus.RUNNING]:
                    running_tasks.append({
                        'task_id': task_id,
                        'type': 'immediate',
                        'status': task_result.status.value,
                        'start_time': task_result.start_time.isoformat(),
                        'progress': task_result.progress,
                        'name': f"å³æ—¶ä»»åŠ¡ {task_id[:8]}..."
                    })
            
            # æ·»åŠ å®šæ—¶ä»»åŠ¡
            for task_id, task in self.scheduled_tasks.items():
                running_tasks.append({
                    'task_id': task_id,
                    'type': 'scheduled',
                    'status': 'running',
                    'name': task.name,
                    'interval_seconds': task.interval_seconds
                })
        
        return running_tasks
    
    def get_task_result(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä»»åŠ¡æ‰§è¡Œç»“æœ"""
        with self.lock:
            task_result = self.task_results.get(task_id)
            return task_result.to_dict() if task_result else None
    
    def get_all_task_results(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œç»“æœ"""
        with self.lock:
            return [result.to_dict() for result in self.task_results.values()]
    
    def cleanup_old_results(self, keep_last_n: int = 50):
        """æ¸…ç†æ—§çš„ä»»åŠ¡ç»“æœï¼Œåªä¿ç•™æœ€è¿‘çš„Nä¸ª"""
        with self.lock:
            if len(self.task_results) <= keep_last_n:
                return
            
            # æŒ‰æ—¶é—´æ’åºï¼Œä¿ç•™æœ€æ–°çš„
            sorted_results = sorted(
                self.task_results.items(), 
                key=lambda x: x[1].start_time, 
                reverse=True
            )
            
            # ä¿ç•™æœ€æ–°çš„Nä¸ªç»“æœ
            keep_results = dict(sorted_results[:keep_last_n])
            self.task_results = keep_results
            
            logger.info(f"æ¸…ç†æ—§ä»»åŠ¡ç»“æœï¼Œä¿ç•™æœ€è¿‘çš„ {keep_last_n} ä¸ª")
    
    def get_task_history(self, limit: int = 100, start_date: Optional[datetime] = None,
                        end_date: Optional[datetime] = None, status_filter: Optional[str] = None) -> List[Dict[str, Any]]:
        """è·å–ä»»åŠ¡å†å²è®°å½•"""
        try:
            return self.data_manager.load_task_history(
                limit=limit,
                start_date=start_date,
                end_date=end_date,
                status_filter=status_filter
            )
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡å†å²å¤±è´¥: {e}")
            return []
    
    def get_task_config_by_id(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–æŒ‡å®šä»»åŠ¡çš„é…ç½®ï¼ˆæ”¯æŒç‰ˆæœ¬å…¼å®¹æ€§ï¼‰"""
        try:
            config = self.data_manager.get_task_config_compatible(task_id)
            if config:
                # å¤„ç†æšä¸¾åºåˆ—åŒ–é—®é¢˜
                config = self._serialize_config_for_json(config)
            return config
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡é…ç½®å¤±è´¥: {e}")
            return None
    
    def _serialize_config_for_json(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """å°†é…ç½®ä¸­çš„ç‰¹æ®Šå¯¹è±¡åºåˆ—åŒ–ä¸ºJSONå¯åºåˆ—åŒ–çš„æ ¼å¼"""
        serialized_config = config.copy()
        
        # å¤„ç†ArxivSearchModeæšä¸¾
        if 'search_mode' in serialized_config and isinstance(serialized_config['search_mode'], ArxivSearchMode):
            serialized_config['search_mode'] = serialized_config['search_mode'].value
        
        return serialized_config
    
    def save_config_preset(self, name: str, config_dict: Dict[str, Any], description: str = "") -> tuple[bool, Optional[str]]:
        """ä¿å­˜é…ç½®é¢„è®¾"""
        try:
            # é…ç½®éªŒè¯
            is_valid, error_msg = self.validate_config(config_dict)
            if not is_valid:
                return False, error_msg
            
            success = self.data_manager.save_config_preset(name, config_dict, description)
            return success, None if success else "ä¿å­˜é¢„è®¾å¤±è´¥"
            
        except Exception as e:
            error_msg = f"ä¿å­˜é…ç½®é¢„è®¾å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return False, error_msg
    
    def load_config_presets(self) -> List[Dict[str, Any]]:
        """åŠ è½½æ‰€æœ‰é…ç½®é¢„è®¾"""
        try:
            presets = self.data_manager.load_config_presets()
            # å¤„ç†æ¯ä¸ªé¢„è®¾ä¸­çš„åºåˆ—åŒ–é—®é¢˜
            for preset in presets:
                if 'config' in preset:
                    preset['config'] = self._serialize_config_for_json(preset['config'])
            return presets
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®é¢„è®¾å¤±è´¥: {e}")
            return []
    
    def delete_config_preset(self, preset_id: str) -> tuple[bool, Optional[str]]:
        """åˆ é™¤é…ç½®é¢„è®¾"""
        try:
            success = self.data_manager.delete_config_preset(preset_id)
            return success, None if success else "åˆ é™¤é¢„è®¾å¤±è´¥"
            
        except Exception as e:
            error_msg = f"åˆ é™¤é…ç½®é¢„è®¾å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return False, error_msg
    
    def update_task_history(self, task_id: str, updated_data: Dict[str, Any]) -> tuple[bool, Optional[str]]:
        """æ›´æ–°å†å²ä»»åŠ¡è®°å½•"""
        try:
            # éªŒè¯æ›´æ–°æ•°æ®
            if "config" in updated_data:
                # éªŒè¯é…ç½®çš„æœ‰æ•ˆæ€§
                is_valid, error_msg = self.validate_config(updated_data["config"])
                if not is_valid:
                    return False, f"é…ç½®éªŒè¯å¤±è´¥: {error_msg}"
            
            # æ›´æ–°æŒä¹…åŒ–å­˜å‚¨
            success = self.data_manager.update_task_history(task_id, updated_data)
            
            if success and "config" in updated_data:
                # åŒæ­¥æ›´æ–°å†…å­˜ç¼“å­˜ä¸­çš„ä»»åŠ¡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                with self.lock:
                    if task_id in self.task_results:
                        # è¿™é‡Œæš‚ä¸æ›´æ–°å†…å­˜ä¸­çš„ä»»åŠ¡é…ç½®ï¼Œå› ä¸ºTaskResultå¯¹è±¡ä¸åŒ…å«configå­—æ®µ
                        # å†…å­˜ä¸­ä¸»è¦æ˜¯è¿è¡Œæ—¶çŠ¶æ€ï¼Œå†å²é…ç½®å­˜å‚¨åœ¨æŒä¹…åŒ–å±‚
                        logger.info(f"ä»»åŠ¡ {task_id} é…ç½®å·²åœ¨æŒä¹…åŒ–å­˜å‚¨ä¸­æ›´æ–°")
            
            return success, None if success else "æ›´æ–°å†å²ä»»åŠ¡å¤±è´¥ï¼Œæœªæ‰¾åˆ°æŒ‡å®šä»»åŠ¡"
            
        except Exception as e:
            error_msg = f"æ›´æ–°å†å²ä»»åŠ¡å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return False, error_msg
    
    def delete_task_history(self, task_id: str) -> tuple[bool, Optional[str]]:
        """åˆ é™¤å†å²ä»»åŠ¡è®°å½•"""
        try:
            # ä»æŒä¹…åŒ–å­˜å‚¨åˆ é™¤
            success = self.data_manager.delete_task_history(task_id)
            
            if success:
                # åŒæ­¥åˆ é™¤å†…å­˜ç¼“å­˜ä¸­çš„ä»»åŠ¡
                with self.lock:
                    if task_id in self.task_results:
                        del self.task_results[task_id]
                        logger.info(f"å·²ä»å†…å­˜ç¼“å­˜ä¸­åˆ é™¤ä»»åŠ¡: {task_id}")
                
            return success, None if success else "åˆ é™¤å†å²ä»»åŠ¡å¤±è´¥ï¼Œæœªæ‰¾åˆ°æŒ‡å®šä»»åŠ¡"
            
        except Exception as e:
            error_msg = f"åˆ é™¤å†å²ä»»åŠ¡å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return False, error_msg
    
    def start_task_from_config(self, config_dict: Dict[str, Any], mode: TaskMode = TaskMode.IMMEDIATE) -> tuple[bool, str, Optional[str]]:
        """åŸºäºé…ç½®å¯åŠ¨ä»»åŠ¡"""
        try:
            # åº”ç”¨é…ç½®å…¼å®¹æ€§å¤„ç†
            compatible_config = ConfigVersionManager.ensure_config_compatibility(config_dict)
            
            # é…ç½®éªŒè¯
            is_valid, error_msg = self.validate_config(compatible_config)
            if not is_valid:
                return False, "", error_msg
            
            # æ ¹æ®æ¨¡å¼å¯åŠ¨ä»»åŠ¡
            if mode == TaskMode.IMMEDIATE:
                task_id = self.start_immediate_task(compatible_config)
                return True, task_id, None
            else:
                success, task_id, error_msg = self.start_scheduled_task(compatible_config)
                return success, task_id, error_msg
                
        except Exception as e:
            error_msg = f"å¯åŠ¨ä»»åŠ¡å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return False, "", error_msg
    
    def get_data_statistics(self) -> Dict[str, Any]:
        """è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        try:
            stats = self.data_manager.get_statistics()
            
            # æ·»åŠ è¿è¡Œæ—¶ç»Ÿè®¡
            with self.lock:
                stats["memory_tasks"] = len(self.task_results)
                stats["running_tasks"] = len([r for r in self.task_results.values() 
                                            if r.status in [TaskStatus.PENDING, TaskStatus.RUNNING]])
                stats["scheduled_tasks"] = len(self.scheduled_tasks)
            
            return stats
            
        except Exception as e:
            logger.error(f"è·å–æ•°æ®ç»Ÿè®¡å¤±è´¥: {e}")
            return {}
    
    def cancel_task(self, task_id: str) -> tuple[bool, Optional[str]]:
        """å–æ¶ˆæ­£åœ¨è¿è¡Œçš„ä»»åŠ¡"""
        try:
            with self.lock:
                task_result = self.task_results.get(task_id)
                if not task_result:
                    return False, "ä»»åŠ¡ä¸å­˜åœ¨"
                
                if task_result.status not in [TaskStatus.PENDING, TaskStatus.RUNNING]:
                    return False, "ä»»åŠ¡å·²å®Œæˆæˆ–å¤±è´¥ï¼Œæ— æ³•å–æ¶ˆ"
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                task_result.status = TaskStatus.STOPPED
                task_result.end_time = datetime.now()
                task_result.error_message = "ç”¨æˆ·å–æ¶ˆä»»åŠ¡"
            
            logger.info(f"ä»»åŠ¡å·²å–æ¶ˆ: {task_id}")
            return True, None
            
        except Exception as e:
            error_msg = f"å–æ¶ˆä»»åŠ¡å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return False, error_msg
    
    # === æ–°å¢å®šæ—¶ä»»åŠ¡ç®¡ç†æ–¹æ³• ===
    
    def pause_scheduled_task(self, task_id: str) -> tuple[bool, Optional[str]]:
        """æš‚åœå®šæ—¶ä»»åŠ¡"""
        try:
            with self.lock:
                # æ£€æŸ¥å¹¶åœæ­¢è¿è¡Œæ—¶ä»»åŠ¡
                if task_id in self.scheduled_tasks:
                    task = self.scheduled_tasks[task_id]
                    
                    # ä»è°ƒåº¦å™¨ä¸­ç§»é™¤ä»»åŠ¡
                    if self.task_scheduler:
                        self.task_scheduler.remove_task(task.name)
                    
                    # æ¸…ç†è¿è¡Œæ—¶ä»»åŠ¡è®°å½•
                    del self.scheduled_tasks[task_id]
            
            # æ›´æ–°æŒä¹…åŒ–å­˜å‚¨çŠ¶æ€ä¸ºæš‚åœ
            success = self.data_manager.update_scheduled_task(task_id, {
                "status": "paused",
                "error_message": None
            })
            
            if success:
                # æ›´æ–°å†…å­˜ç¼“å­˜
                with self.lock:
                    if task_id in self.persistent_scheduled_tasks:
                        self.persistent_scheduled_tasks[task_id]["status"] = "paused"
                        self.persistent_scheduled_tasks[task_id]["updated_at"] = datetime.now().isoformat()
                
                logger.info(f"å®šæ—¶ä»»åŠ¡å·²æš‚åœ: {task_id}")
                return True, None
            else:
                return False, "æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥"
            
        except Exception as e:
            error_msg = f"æš‚åœå®šæ—¶ä»»åŠ¡å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return False, error_msg
    
    def resume_scheduled_task(self, task_id: str) -> tuple[bool, Optional[str]]:
        """æ¢å¤å®šæ—¶ä»»åŠ¡"""
        try:
            # è·å–æŒä¹…åŒ–ä»»åŠ¡æ•°æ®
            task_data = self.data_manager.get_scheduled_task(task_id)
            if not task_data:
                return False, "ä»»åŠ¡ä¸å­˜åœ¨"
            
            # å…ˆéªŒè¯å’ŒåŒæ­¥çŠ¶æ€
            validation_success, validation_error = self._validate_task_status_consistency(task_id)
            if not validation_success:
                logger.warning(f"ä»»åŠ¡çŠ¶æ€ä¸ä¸€è‡´ï¼Œå°è¯•è‡ªåŠ¨åŒæ­¥: {validation_error}")
                sync_success, sync_error = self._sync_task_status(task_id)
                if not sync_success:
                    return False, f"çŠ¶æ€åŒæ­¥å¤±è´¥: {sync_error}"
                # é‡æ–°è·å–ä»»åŠ¡æ•°æ®
                task_data = self.data_manager.get_scheduled_task(task_id)
            
            current_status = task_data.get("status")
            if current_status not in ["paused", "stopped"]:
                return False, f"ä»»åŠ¡çŠ¶æ€ä¸æ˜¯æš‚åœæˆ–åœæ­¢çŠ¶æ€ï¼Œå½“å‰çŠ¶æ€: {current_status}"
            
            # éªŒè¯é…ç½®æœ‰æ•ˆæ€§
            config_dict = task_data.get("config", {})
            is_valid, error_msg = self.validate_config(config_dict)
            if not is_valid:
                return False, f"ä»»åŠ¡é…ç½®æ— æ•ˆ: {error_msg}"
            
            # é‡æ–°åˆ›å»ºè¿è¡Œæ—¶ä»»åŠ¡
            success, _, error_msg = self._create_scheduled_task_internal(task_id, config_dict)
            if success:
                # æ›´æ–°æŒä¹…åŒ–å­˜å‚¨çŠ¶æ€
                self.data_manager.update_scheduled_task(task_id, {
                    "status": "running",
                    "error_message": None
                })
                
                # æ›´æ–°å†…å­˜ç¼“å­˜
                with self.lock:
                    if task_id in self.persistent_scheduled_tasks:
                        self.persistent_scheduled_tasks[task_id]["status"] = "running"
                        self.persistent_scheduled_tasks[task_id]["updated_at"] = datetime.now().isoformat()
                
                logger.info(f"å®šæ—¶ä»»åŠ¡å·²æ¢å¤: {task_id}")
                return True, None
            else:
                return False, f"é‡æ–°åˆ›å»ºä»»åŠ¡å¤±è´¥: {error_msg}"
            
        except Exception as e:
            error_msg = f"æ¢å¤å®šæ—¶ä»»åŠ¡å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return False, error_msg
    
    def update_scheduled_task_config(self, task_id: str, new_config: Dict[str, Any]) -> tuple[bool, Optional[str]]:
        """æ›´æ–°å®šæ—¶ä»»åŠ¡é…ç½®"""
        try:
            # éªŒè¯æ–°é…ç½®
            is_valid, error_msg = self.validate_config(new_config)
            if not is_valid:
                return False, f"æ–°é…ç½®éªŒè¯å¤±è´¥: {error_msg}"
            
            # è·å–ç°æœ‰ä»»åŠ¡æ•°æ®
            task_data = self.data_manager.get_scheduled_task(task_id)
            if not task_data:
                return False, "ä»»åŠ¡ä¸å­˜åœ¨"
            
            old_status = task_data.get("status")
            was_running = old_status == "running" and task_id in self.scheduled_tasks
            
            # å¦‚æœä»»åŠ¡æ­£åœ¨è¿è¡Œï¼Œå…ˆåœæ­¢å®ƒ
            if was_running:
                pause_success, pause_error = self.pause_scheduled_task(task_id)
                if not pause_success:
                    return False, f"æš‚åœä»»åŠ¡å¤±è´¥: {pause_error}"
            
            # æ›´æ–°æŒä¹…åŒ–é…ç½®ï¼ŒçŠ¶æ€åº”è¯¥ä¿æŒå½“å‰çš„å®é™…çŠ¶æ€
            # å¦‚æœåˆšåˆšæš‚åœäº†ä»»åŠ¡ï¼ŒçŠ¶æ€åº”è¯¥æ˜¯ "paused"
            current_status = "paused" if was_running else old_status
            
            success = self.data_manager.update_scheduled_task(task_id, {
                "config": new_config,
                "status": current_status,  # ä½¿ç”¨å½“å‰å®é™…çŠ¶æ€
                "error_message": None
            })
            
            if not success:
                return False, "æ›´æ–°æŒä¹…åŒ–é…ç½®å¤±è´¥"
            
            # æ›´æ–°å†…å­˜ç¼“å­˜
            with self.lock:
                if task_id in self.persistent_scheduled_tasks:
                    self.persistent_scheduled_tasks[task_id]["config"] = new_config
                    self.persistent_scheduled_tasks[task_id]["status"] = current_status
                    self.persistent_scheduled_tasks[task_id]["updated_at"] = datetime.now().isoformat()
            
            # å¦‚æœä¹‹å‰åœ¨è¿è¡Œï¼Œé‡æ–°å¯åŠ¨
            if was_running:
                logger.info(f"ä»»åŠ¡ä¹‹å‰åœ¨è¿è¡Œï¼Œå°è¯•æ¢å¤ä»»åŠ¡: {task_id}")
                resume_success, resume_error = self.resume_scheduled_task(task_id)
                if not resume_success:
                    logger.warning(f"é…ç½®æ›´æ–°æˆåŠŸä½†æ¢å¤ä»»åŠ¡å¤±è´¥: {resume_error}")
                    return True, f"é…ç½®å·²æ›´æ–°ï¼Œä½†æ¢å¤ä»»åŠ¡å¤±è´¥: {resume_error}"
                else:
                    logger.info(f"ä»»åŠ¡æ¢å¤æˆåŠŸ: {task_id}")
            
            logger.info(f"å®šæ—¶ä»»åŠ¡é…ç½®å·²æ›´æ–°: {task_id}")
            return True, None
            
        except Exception as e:
            error_msg = f"æ›´æ–°å®šæ—¶ä»»åŠ¡é…ç½®å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return False, error_msg
    
    def get_scheduled_task_detail(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å®šæ—¶ä»»åŠ¡è¯¦æƒ…"""
        try:
            # ä»æŒä¹…åŒ–å­˜å‚¨è·å–æœ€æ–°æ•°æ®
            task_data = self.data_manager.get_scheduled_task(task_id)
            if not task_data:
                return None
            
            # éªŒè¯çŠ¶æ€ä¸€è‡´æ€§
            validation_success, validation_error = self._validate_task_status_consistency(task_id)
            if not validation_success:
                logger.warning(f"è·å–ä»»åŠ¡è¯¦æƒ…æ—¶å‘ç°çŠ¶æ€ä¸ä¸€è‡´: {validation_error}")
                # å°è¯•è‡ªåŠ¨åŒæ­¥
                sync_success, sync_error = self._sync_task_status(task_id)
                if sync_success:
                    # é‡æ–°è·å–æ•°æ®
                    task_data = self.data_manager.get_scheduled_task(task_id)
                    logger.info(f"ä»»åŠ¡ {task_id} çŠ¶æ€å·²è‡ªåŠ¨åŒæ­¥")
            
            # æ·»åŠ è¿è¡Œæ—¶çŠ¶æ€ä¿¡æ¯
            with self.lock:
                task_data["is_running"] = task_id in self.scheduled_tasks
            
            return task_data
            
        except Exception as e:
            logger.error(f"è·å–å®šæ—¶ä»»åŠ¡è¯¦æƒ…å¤±è´¥: {e}")
            return None
    
    def delete_scheduled_task_permanently(self, task_id: str) -> tuple[bool, Optional[str]]:
        """æ°¸ä¹…åˆ é™¤å®šæ—¶ä»»åŠ¡ï¼ˆåŒ…æ‹¬æŒä¹…åŒ–æ•°æ®ï¼‰"""
        try:
            # å…ˆåœæ­¢ä»»åŠ¡
            self.stop_scheduled_task(task_id)
            
            # åˆ é™¤æŒä¹…åŒ–æ•°æ®
            success = self.data_manager.delete_scheduled_task(task_id)
            
            # æ¸…ç†å†…å­˜ç¼“å­˜
            with self.lock:
                if task_id in self.persistent_scheduled_tasks:
                    del self.persistent_scheduled_tasks[task_id]
            
            if success:
                logger.info(f"å®šæ—¶ä»»åŠ¡å·²æ°¸ä¹…åˆ é™¤: {task_id}")
                return True, None
            else:
                return False, "åˆ é™¤æŒä¹…åŒ–æ•°æ®å¤±è´¥"
            
        except Exception as e:
            error_msg = f"æ°¸ä¹…åˆ é™¤å®šæ—¶ä»»åŠ¡å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return False, error_msg
    
    def _validate_task_status_consistency(self, task_id: str) -> tuple[bool, Optional[str]]:
        """éªŒè¯ä»»åŠ¡çŠ¶æ€ä¸€è‡´æ€§"""
        try:
            # è·å–æŒä¹…åŒ–çŠ¶æ€
            persistent_data = self.data_manager.get_scheduled_task(task_id)
            if not persistent_data:
                return False, "ä»»åŠ¡ä¸å­˜åœ¨"
            
            persistent_status = persistent_data.get("status")
            
            # æ£€æŸ¥è¿è¡Œæ—¶çŠ¶æ€
            with self.lock:
                is_runtime_active = task_id in self.scheduled_tasks
                memory_status = self.persistent_scheduled_tasks.get(task_id, {}).get("status")
            
            # çŠ¶æ€ä¸€è‡´æ€§æ£€æŸ¥
            status_inconsistent = False
            issues = []
            
            # æ£€æŸ¥æŒä¹…åŒ–çŠ¶æ€ä¸å†…å­˜çŠ¶æ€æ˜¯å¦ä¸€è‡´
            if persistent_status != memory_status:
                status_inconsistent = True
                issues.append(f"æŒä¹…åŒ–çŠ¶æ€({persistent_status})ä¸å†…å­˜çŠ¶æ€({memory_status})ä¸ä¸€è‡´")
            
            # æ£€æŸ¥è¿è¡Œæ—¶çŠ¶æ€ä¸çŠ¶æ€æ ‡è®°æ˜¯å¦ä¸€è‡´
            if persistent_status == "running" and not is_runtime_active:
                status_inconsistent = True
                issues.append("çŠ¶æ€æ ‡è®°ä¸ºè¿è¡Œä¸­ä½†è¿è¡Œæ—¶ä»»åŠ¡ä¸å­˜åœ¨")
            elif persistent_status != "running" and is_runtime_active:
                status_inconsistent = True
                issues.append("çŠ¶æ€æ ‡è®°ä¸ºéè¿è¡Œä½†è¿è¡Œæ—¶ä»»åŠ¡å­˜åœ¨")
            
            if status_inconsistent:
                error_msg = f"ä»»åŠ¡ {task_id} çŠ¶æ€ä¸ä¸€è‡´: {'; '.join(issues)}"
                logger.warning(error_msg)
                return False, error_msg
            
            return True, None
            
        except Exception as e:
            error_msg = f"çŠ¶æ€ä¸€è‡´æ€§éªŒè¯å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return False, error_msg
    
    def _sync_task_status(self, task_id: str) -> tuple[bool, Optional[str]]:
        """åŒæ­¥ä»»åŠ¡çŠ¶æ€ï¼Œä»¥è¿è¡Œæ—¶çŠ¶æ€ä¸ºå‡†"""
        try:
            with self.lock:
                is_runtime_active = task_id in self.scheduled_tasks
                
                # ç¡®å®šæ­£ç¡®çš„çŠ¶æ€
                correct_status = "running" if is_runtime_active else "paused"
                
                # æ›´æ–°æŒä¹…åŒ–çŠ¶æ€
                success = self.data_manager.update_scheduled_task(task_id, {
                    "status": correct_status
                })
                
                if success:
                    # æ›´æ–°å†…å­˜ç¼“å­˜
                    if task_id in self.persistent_scheduled_tasks:
                        self.persistent_scheduled_tasks[task_id]["status"] = correct_status
                        self.persistent_scheduled_tasks[task_id]["updated_at"] = datetime.now().isoformat()
                    
                    logger.info(f"ä»»åŠ¡ {task_id} çŠ¶æ€å·²åŒæ­¥ä¸º: {correct_status}")
                    return True, None
                else:
                    return False, "æ›´æ–°æŒä¹…åŒ–çŠ¶æ€å¤±è´¥"
                    
        except Exception as e:
            error_msg = f"çŠ¶æ€åŒæ­¥å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return False, error_msg
    
    def trigger_scheduled_task_manual(self, task_id: str) -> tuple[bool, Optional[str]]:
        """æ‰‹åŠ¨è§¦å‘å®šæ—¶ä»»åŠ¡æ‰§è¡Œ"""
        try:
            with self.lock:
                # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨ä¸”æ­£åœ¨è¿è¡Œ
                if task_id not in self.scheduled_tasks:
                    return False, "å®šæ—¶ä»»åŠ¡ä¸å­˜åœ¨æˆ–æœªåœ¨è¿è¡Œ"
                
                task = self.scheduled_tasks[task_id]
                
                # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
                if not task.enabled:
                    return False, "ä»»åŠ¡å·²è¢«ç¦ç”¨"
                
                if task.is_running:
                    return False, "ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­ï¼Œè¯·ç­‰å¾…å®Œæˆåå†è¯•"
                
                # æ‰‹åŠ¨è§¦å‘ä»»åŠ¡
                success = task.trigger_manual_run()
                if success:
                    logger.info(f"æˆåŠŸæ‰‹åŠ¨è§¦å‘å®šæ—¶ä»»åŠ¡: {task_id} ({task.name})")
                    
                    # æ›´æ–°æŒä¹…åŒ–æ•°æ®ä¸­çš„æ‰§è¡Œç»Ÿè®¡
                    if task_id in self.persistent_scheduled_tasks:
                        self.persistent_scheduled_tasks[task_id]["last_manual_trigger"] = datetime.now().isoformat()
                    
                    return True, None
                else:
                    return False, "è§¦å‘ä»»åŠ¡å¤±è´¥"
            
        except Exception as e:
            error_msg = f"æ‰‹åŠ¨è§¦å‘å®šæ—¶ä»»åŠ¡å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return False, error_msg

    def _cleanup_resources(self) -> None:
        """æ¸…ç†æ‰€æœ‰èµ„æºï¼Œç¡®ä¿ä¼˜é›…å…³é—­"""
        if self._executor_shutdown:
            return
            
        logger.info("ğŸ§¹ å¼€å§‹æ¸…ç† PaperGatherService èµ„æº...")
        
        try:
            # åœæ­¢æ‰€æœ‰å®šæ—¶ä»»åŠ¡
            with self.lock:
                for task_id in list(self.scheduled_tasks.keys()):
                    try:
                        self.stop_scheduled_task(task_id)
                    except Exception as e:
                        logger.warning(f"åœæ­¢ä»»åŠ¡ {task_id} æ—¶å‡ºç°å¼‚å¸¸: {e}")
            
            # åœæ­¢è°ƒåº¦å™¨
            if self.scheduler_running and self.scheduler_thread:
                try:
                    self.scheduler_running = False
                    if self.scheduler_thread.is_alive():
                        self.scheduler_thread.join(timeout=5)
                        logger.info("è°ƒåº¦å™¨çº¿ç¨‹å·²åœæ­¢")
                except Exception as e:
                    logger.warning(f"åœæ­¢è°ƒåº¦å™¨çº¿ç¨‹æ—¶å‡ºç°å¼‚å¸¸: {e}")
            
            # å…³é—­çº¿ç¨‹æ± æ‰§è¡Œå™¨
            if self.executor and not self.executor._shutdown:
                logger.info("å…³é—­çº¿ç¨‹æ± æ‰§è¡Œå™¨...")
                try:
                    # ç»™æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡ä¸€ç‚¹æ—¶é—´å®Œæˆ
                    self.executor.shutdown(wait=True)
                    logger.info("âœ… çº¿ç¨‹æ± æ‰§è¡Œå™¨å·²å…³é—­")
                except Exception as e:
                    logger.warning(f"å…³é—­çº¿ç¨‹æ± æ‰§è¡Œå™¨æ—¶å‡ºç°å¼‚å¸¸: {e}")
                    # å¼ºåˆ¶å…³é—­
                    try:
                        self.executor.shutdown(wait=False)
                    except Exception:
                        pass
            
            self._executor_shutdown = True
            logger.info("âœ… PaperGatherService èµ„æºæ¸…ç†å®Œæˆ")
        
        except Exception as e:
            logger.error(f"âŒ èµ„æºæ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")

    def get_all_tasks_unified(self) -> List[Dict[str, Any]]:
        """è·å–ç»Ÿä¸€çš„ä»»åŠ¡åˆ—è¡¨æ•°æ®ï¼ŒåŒ…å«ä¸€æ¬¡æ€§ä»»åŠ¡å’Œå®šæ—¶ä»»åŠ¡"""
        try:
            unified_tasks = []
            
            # è·å–ä¸€æ¬¡æ€§ä»»åŠ¡ï¼ˆæ‰§è¡Œå†å²ï¼‰
            immediate_tasks = self.get_all_task_results()
            for task in immediate_tasks:
                unified_task = {
                    'task_id': task.get('task_id'),
                    'task_name': task.get('task_name', task.get('task_id', '')[:8] + '...'),
                    'task_type': 'immediate',
                    'status': task.get('status'),
                    'start_time': task.get('start_time'),
                    'end_time': task.get('end_time'),
                    'duration': task.get('duration'),
                    'progress': task.get('progress', 0.0),
                    'search_query': task.get('search_query'),
                    'papers_found': task.get('papers_found'),
                    'llm_model_name': task.get('result_data', {}).get('llm_model_name'),
                    'error_message': task.get('error_message'),
                    'execution_count': 1,  # ä¸€æ¬¡æ€§ä»»åŠ¡æ‰§è¡Œæ¬¡æ•°ä¸º1
                    'interval_seconds': None,
                    'last_executed_at': task.get('end_time'),
                    'next_execution_at': None,
                    'is_running': False
                }
                unified_tasks.append(unified_task)
            
            # è·å–å®šæ—¶ä»»åŠ¡
            scheduled_tasks = self.get_scheduled_tasks()
            for task in scheduled_tasks:
                config = task.get('config', {})
                unified_task = {
                    'task_id': task.get('task_id'),
                    'task_name': config.get('task_name', task.get('name', '')),
                    'task_type': 'scheduled',
                    'status': task.get('status'),
                    'start_time': task.get('created_at'),
                    'end_time': None,  # å®šæ—¶ä»»åŠ¡æ²¡æœ‰ç»“æŸæ—¶é—´
                    'duration': None,
                    'progress': 0.0,  # å®šæ—¶ä»»åŠ¡æ²¡æœ‰è¿›åº¦æ¦‚å¿µ
                    'search_query': config.get('search_query'),
                    'papers_found': None,  # å®šæ—¶ä»»åŠ¡çš„è®ºæ–‡æ•°é‡éœ€è¦å•ç‹¬ç»Ÿè®¡
                    'llm_model_name': config.get('llm_model_name'),
                    'error_message': task.get('error_message'),
                    'execution_count': task.get('execution_count', 0),
                    'interval_seconds': task.get('interval_seconds'),
                    'last_executed_at': task.get('last_executed_at'),
                    'next_execution_at': task.get('next_execution_at'),
                    'is_running': task.get('is_running', False)
                }
                unified_tasks.append(unified_task)
            
            # æŒ‰åˆ›å»ºæ—¶é—´é™åºæ’åº
            unified_tasks.sort(key=lambda x: x.get('start_time', ''), reverse=True)
            
            logger.info(f"è·å–ç»Ÿä¸€ä»»åŠ¡åˆ—è¡¨: {len(immediate_tasks)} ä¸ªä¸€æ¬¡æ€§ä»»åŠ¡, {len(scheduled_tasks)} ä¸ªå®šæ—¶ä»»åŠ¡")
            return unified_tasks
            
        except Exception as e:
            logger.error(f"è·å–ç»Ÿä¸€ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def __del__(self):
        """ææ„å‡½æ•°ç¡®ä¿èµ„æºé‡Šæ”¾"""
        try:
            self._cleanup_resources()
        except Exception:
            pass  # å¿½ç•¥ææ„æ—¶çš„å¼‚å¸¸


# å…¨å±€æœåŠ¡å®ä¾‹
paper_gather_service = PaperGatherService()