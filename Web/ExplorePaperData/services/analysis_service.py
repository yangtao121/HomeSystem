"""
æ·±åº¦è®ºæ–‡åˆ†ææœåŠ¡
å¤„ç†è®ºæ–‡æ·±åº¦åˆ†æçš„ä¸šåŠ¡é€»è¾‘
"""
import os
import sys
import threading
import time
import logging
import re
from pathlib import Path
from typing import Dict, Any, Optional, Tuple
from datetime import datetime

# æ·»åŠ  HomeSystem æ¨¡å—è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', '..'))

from database import PaperService

logger = logging.getLogger(__name__)


class DeepAnalysisService:
    """æ·±åº¦è®ºæ–‡åˆ†ææœåŠ¡ç±»"""
    
    def __init__(self, paper_service: PaperService):
        self.paper_service = paper_service
        self.analysis_threads = {}  # å­˜å‚¨æ­£åœ¨è¿›è¡Œçš„åˆ†æçº¿ç¨‹
        
        # é»˜è®¤é…ç½®
        self.default_config = {
            'analysis_model': 'deepseek.DeepSeek_V3',
            'vision_model': 'ollama.Qwen2_5_VL_7B',
            'timeout': 600  # 10åˆ†é’Ÿè¶…æ—¶
        }
    
    def start_analysis(self, arxiv_id: str, config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        å¯åŠ¨è®ºæ–‡æ·±åº¦åˆ†æ
        
        Args:
            arxiv_id: ArXivè®ºæ–‡ID
            config: åˆ†æé…ç½®ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Dict: æ“ä½œç»“æœ
        """
        try:
            logger.info(f"ğŸš€ å¼€å§‹å¯åŠ¨æ·±åº¦åˆ†æ - ArXiv ID: {arxiv_id}")
            
            # æ£€æŸ¥è®ºæ–‡æ˜¯å¦å­˜åœ¨
            paper = self.paper_service.get_paper_detail(arxiv_id)
            if not paper:
                logger.error(f"âŒ è®ºæ–‡ä¸å­˜åœ¨: {arxiv_id}")
                return {
                    'success': False,
                    'error': f'è®ºæ–‡ {arxiv_id} ä¸å­˜åœ¨'
                }
            
            logger.info(f"âœ… è®ºæ–‡å­˜åœ¨æ£€æŸ¥é€šè¿‡: {arxiv_id}")
            
            # æ£€æŸ¥æ˜¯å¦å·²åœ¨åˆ†æä¸­
            if arxiv_id in self.analysis_threads:
                thread = self.analysis_threads[arxiv_id]
                if thread.is_alive():
                    logger.warning(f"âš ï¸ è®ºæ–‡å·²åœ¨åˆ†æä¸­: {arxiv_id}")
                    return {
                        'success': False,
                        'error': 'è¯¥è®ºæ–‡æ­£åœ¨åˆ†æä¸­ï¼Œè¯·ç¨å'
                    }
                else:
                    # æ¸…ç†å·²å®Œæˆçš„çº¿ç¨‹
                    del self.analysis_threads[arxiv_id]
                    logger.info(f"ğŸ§¹ æ¸…ç†äº†å·²å®Œæˆçš„çº¿ç¨‹: {arxiv_id}")
            
            # æ£€æŸ¥è®ºæ–‡æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
            paper_folder = f"/mnt/nfs_share/code/homesystem/data/paper_analyze/{arxiv_id}"
            logger.info(f"ğŸ“ æ£€æŸ¥è®ºæ–‡æ–‡ä»¶å¤¹: {paper_folder}")
            
            if not os.path.exists(paper_folder):
                logger.error(f"âŒ è®ºæ–‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {paper_folder}")
                return {
                    'success': False,
                    'error': f'è®ºæ–‡æ•°æ®æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {paper_folder}'
                }
            
            logger.info(f"âœ… è®ºæ–‡æ–‡ä»¶å¤¹å­˜åœ¨æ£€æŸ¥é€šè¿‡: {paper_folder}")
            
            # æ›´æ–°åˆ†æçŠ¶æ€ä¸ºå¤„ç†ä¸­
            self.paper_service.update_analysis_status(arxiv_id, 'processing')
            
            # åˆå¹¶é…ç½®
            analysis_config = {**self.default_config, **(config or {})}
            
            # åˆ›å»ºå¹¶å¯åŠ¨åˆ†æçº¿ç¨‹
            thread = threading.Thread(
                target=self._run_analysis,
                args=(arxiv_id, paper_folder, analysis_config),
                daemon=True
            )
            thread.start()
            
            # ä¿å­˜çº¿ç¨‹å¼•ç”¨
            self.analysis_threads[arxiv_id] = thread
            
            logger.info(f"Started deep analysis for paper {arxiv_id}")
            
            return {
                'success': True,
                'message': 'æ·±åº¦åˆ†æå·²å¯åŠ¨',
                'status': 'processing'
            }
            
        except Exception as e:
            logger.error(f"Failed to start analysis for {arxiv_id}: {e}")
            # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
            try:
                self.paper_service.update_analysis_status(arxiv_id, 'failed')
            except:
                pass
            
            return {
                'success': False,
                'error': f'å¯åŠ¨åˆ†æå¤±è´¥: {str(e)}'
            }
    
    def _run_analysis(self, arxiv_id: str, paper_folder: str, config: Dict[str, Any]):
        """
        æ‰§è¡Œè®ºæ–‡åˆ†æï¼ˆåœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œï¼‰
        
        Args:
            arxiv_id: ArXivè®ºæ–‡ID
            paper_folder: è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„
            config: åˆ†æé…ç½®
        """
        try:
            logger.info(f"Starting analysis for {arxiv_id} with config: {config}")
            
            # åŠ¨æ€å¯¼å…¥æ·±åº¦åˆ†ææ™ºèƒ½ä½“ï¼ˆå»¶è¿Ÿå¯¼å…¥é¿å…å¯åŠ¨æ—¶çš„å…¼å®¹æ€§é—®é¢˜ï¼‰
            try:
                from HomeSystem.graph.deep_paper_analysis_agent import create_deep_paper_analysis_agent
                logger.info("âœ… Successfully imported deep paper analysis agent")
            except Exception as import_error:
                logger.error(f"âŒ Failed to import deep paper analysis agent: {import_error}")
                self.paper_service.update_analysis_status(arxiv_id, 'failed')
                return
            
            # åˆ›å»ºæ·±åº¦åˆ†ææ™ºèƒ½ä½“
            logger.info("ğŸ¤– Creating deep paper analysis agent...")
            agent = create_deep_paper_analysis_agent(
                analysis_model=config['analysis_model'],
                vision_model=config['vision_model']
            )
            logger.info("âœ… Deep paper analysis agent created successfully")
            
            # æ‰§è¡Œåˆ†æ
            analysis_result, report_content = agent.analyze_and_generate_report(
                folder_path=paper_folder,
                thread_id=f"web_analysis_{arxiv_id}_{int(time.time())}"
            )
            
            # æ£€æŸ¥åˆ†ææ˜¯å¦æˆåŠŸ
            if 'error' in analysis_result:
                logger.error(f"Analysis failed for {arxiv_id}: {analysis_result['error']}")
                self.paper_service.update_analysis_status(arxiv_id, 'failed')
                return
            
            # å¤„ç†åˆ†æç»“æœ
            if analysis_result.get('analysis_result') or report_content:
                # ä½¿ç”¨åˆ†æç»“æœæˆ–æŠ¥å‘Šå†…å®¹
                final_content = analysis_result.get('analysis_result') or report_content
                
                # å¤„ç†å›¾ç‰‡è·¯å¾„
                processed_content = self._process_image_paths(final_content, arxiv_id)
                
                # ä¿å­˜åˆ†æç»“æœ
                self.paper_service.save_analysis_result(arxiv_id, processed_content)
                
                # ä¿å­˜åˆ°æ–‡ä»¶
                analysis_file = os.path.join(paper_folder, f"{arxiv_id}_analysis.md")
                with open(analysis_file, 'w', encoding='utf-8') as f:
                    f.write(processed_content)
                
                logger.info(f"Analysis completed for {arxiv_id}, saved {len(processed_content)} characters")
                
                # æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
                self.paper_service.update_analysis_status(arxiv_id, 'completed')
            else:
                logger.warning(f"No analysis result generated for {arxiv_id}")
                self.paper_service.update_analysis_status(arxiv_id, 'failed')
                
        except Exception as e:
            logger.error(f"Analysis failed for {arxiv_id}: {e}")
            # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
            try:
                self.paper_service.update_analysis_status(arxiv_id, 'failed')
            except:
                pass
        finally:
            # æ¸…ç†çº¿ç¨‹å¼•ç”¨
            if arxiv_id in self.analysis_threads:
                del self.analysis_threads[arxiv_id]
    
    def _process_image_paths(self, content: str, arxiv_id: str) -> str:
        """
        å¤„ç†Markdownå†…å®¹ä¸­çš„å›¾ç‰‡è·¯å¾„ï¼Œå°†ç›¸å¯¹è·¯å¾„è½¬æ¢ä¸ºå¯è®¿é—®çš„URLè·¯å¾„
        
        Args:
            content: åŸå§‹Markdownå†…å®¹
            arxiv_id: ArXivè®ºæ–‡ID
            
        Returns:
            str: å¤„ç†åçš„Markdownå†…å®¹
        """
        try:
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…Markdownå›¾ç‰‡è¯­æ³•
            img_pattern = r'!\[(.*?)\]\((imgs/[^)]+)\)'
            
            def replace_image_path(match):
                alt_text = match.group(1)
                relative_path = match.group(2)
                # è½¬æ¢ä¸ºFlaskå¯è®¿é—®çš„URLè·¯å¾„
                new_path = f"/paper/{arxiv_id}/analysis_images/{relative_path.replace('imgs/', '')}"
                return f"![{alt_text}]({new_path})"
            
            # æ›¿æ¢æ‰€æœ‰å›¾ç‰‡è·¯å¾„
            processed_content = re.sub(img_pattern, replace_image_path, content)
            
            logger.info(f"Processed {len(re.findall(img_pattern, content))} image paths for {arxiv_id}")
            
            return processed_content
            
        except Exception as e:
            logger.error(f"Failed to process image paths for {arxiv_id}: {e}")
            return content
    
    def get_analysis_status(self, arxiv_id: str) -> Dict[str, Any]:
        """
        è·å–åˆ†æçŠ¶æ€
        
        Args:
            arxiv_id: ArXivè®ºæ–‡ID
            
        Returns:
            Dict: çŠ¶æ€ä¿¡æ¯
        """
        try:
            # ä»æ•°æ®åº“è·å–çŠ¶æ€
            status_info = self.paper_service.get_analysis_status(arxiv_id)
            
            if not status_info:
                return {
                    'success': True,
                    'status': 'not_started',
                    'message': 'å°šæœªå¼€å§‹åˆ†æ'
                }
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„çº¿ç¨‹
            if arxiv_id in self.analysis_threads:
                thread = self.analysis_threads[arxiv_id]
                if thread.is_alive():
                    status_info['is_running'] = True
                else:
                    # æ¸…ç†å·²å®Œæˆçš„çº¿ç¨‹
                    del self.analysis_threads[arxiv_id]
                    status_info['is_running'] = False
            else:
                status_info['is_running'] = False
            
            return {
                'success': True,
                **status_info
            }
            
        except Exception as e:
            logger.error(f"Failed to get analysis status for {arxiv_id}: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def get_analysis_result(self, arxiv_id: str) -> Dict[str, Any]:
        """
        è·å–åˆ†æç»“æœ
        
        Args:
            arxiv_id: ArXivè®ºæ–‡ID
            
        Returns:
            Dict: åˆ†æç»“æœ
        """
        try:
            result = self.paper_service.get_analysis_result(arxiv_id)
            
            if not result:
                return {
                    'success': False,
                    'error': 'åˆ†æç»“æœä¸å­˜åœ¨'
                }
            
            return {
                'success': True,
                **result
            }
            
        except Exception as e:
            logger.error(f"Failed to get analysis result for {arxiv_id}: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def cancel_analysis(self, arxiv_id: str) -> Dict[str, Any]:
        """
        å–æ¶ˆæ­£åœ¨è¿›è¡Œçš„åˆ†æ
        
        Args:
            arxiv_id: ArXivè®ºæ–‡ID
            
        Returns:
            Dict: æ“ä½œç»“æœ
        """
        try:
            if arxiv_id not in self.analysis_threads:
                return {
                    'success': False,
                    'error': 'æ²¡æœ‰æ­£åœ¨è¿›è¡Œçš„åˆ†æ'
                }
            
            thread = self.analysis_threads[arxiv_id]
            if not thread.is_alive():
                del self.analysis_threads[arxiv_id]
                return {
                    'success': False,
                    'error': 'åˆ†æå·²å®Œæˆæˆ–å·²åœæ­¢'
                }
            
            # æ³¨æ„ï¼šPythonçº¿ç¨‹æ— æ³•å¼ºåˆ¶åœæ­¢ï¼Œè¿™é‡Œåªèƒ½æ ‡è®°çŠ¶æ€
            # å®é™…çš„çº¿ç¨‹ä»ä¼šç»§ç»­è¿è¡Œç›´åˆ°è‡ªç„¶ç»“æŸ
            del self.analysis_threads[arxiv_id]
            
            # æ›´æ–°æ•°æ®åº“çŠ¶æ€
            self.paper_service.update_analysis_status(arxiv_id, 'cancelled')
            
            logger.info(f"Analysis cancelled for {arxiv_id}")
            
            return {
                'success': True,
                'message': 'åˆ†æå·²å–æ¶ˆ'
            }
            
        except Exception as e:
            logger.error(f"Failed to cancel analysis for {arxiv_id}: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def cleanup_completed_threads(self):
        """æ¸…ç†å·²å®Œæˆçš„åˆ†æçº¿ç¨‹"""
        completed_threads = []
        
        for arxiv_id, thread in self.analysis_threads.items():
            if not thread.is_alive():
                completed_threads.append(arxiv_id)
        
        for arxiv_id in completed_threads:
            del self.analysis_threads[arxiv_id]
        
        if completed_threads:
            logger.info(f"Cleaned up {len(completed_threads)} completed analysis threads")
    
    def get_active_analyses(self) -> Dict[str, Any]:
        """
        è·å–æ‰€æœ‰æ´»è·ƒçš„åˆ†æä»»åŠ¡
        
        Returns:
            Dict: æ´»è·ƒä»»åŠ¡ä¿¡æ¯
        """
        try:
            self.cleanup_completed_threads()
            
            active_analyses = []
            for arxiv_id, thread in self.analysis_threads.items():
                if thread.is_alive():
                    status_info = self.paper_service.get_analysis_status(arxiv_id)
                    if status_info:
                        active_analyses.append({
                            'arxiv_id': arxiv_id,
                            **status_info
                        })
            
            return {
                'success': True,
                'active_count': len(active_analyses),
                'analyses': active_analyses
            }
            
        except Exception as e:
            logger.error(f"Failed to get active analyses: {e}")
            return {
                'success': False,
                'error': str(e)
            }