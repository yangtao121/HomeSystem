# HomeSystem LLMé›†æˆç³»ç»Ÿ

HomeSystemå›¾å½¢ç³»ç»Ÿçš„LLMæ¨¡å‹ç®¡ç†å’Œé›†æˆè§£å†³æ–¹æ¡ˆã€‚

## âœ¨ ä¸»è¦ç‰¹æ€§

- ğŸ¯ **ç»Ÿä¸€æ¨¡å‹ç®¡ç†**: æ”¯æŒå¤šä¸ªä¸­å›½LLMå‚å•†çš„æ¨¡å‹
- ğŸ”§ **ç®€å•æ˜“ç”¨**: ä¸€è¡Œä»£ç è·å–ä»»æ„å¯ç”¨æ¨¡å‹  
- ğŸ“Š **æ™ºèƒ½æ£€æµ‹**: è‡ªåŠ¨æ£€æµ‹API Keyå¯ç”¨æ€§
- ğŸ”„ **çµæ´»é…ç½®**: YAMLé…ç½®æ–‡ä»¶ï¼Œæ”¯æŒå‚å•†åˆ†ç¦»
- ğŸ·ï¸ **æ¸…æ™°å‘½å**: `provider.model`æ ¼å¼ï¼Œæ˜“äºåŒºåˆ†
- ğŸš€ **LangGraphå…¼å®¹**: æ‰€æœ‰æ¨¡å‹ç›´æ¥æ”¯æŒLangGraph

## ğŸ¢ æ”¯æŒçš„å‚å•†

### LLMæ¨¡å‹å‚å•†
- **DeepSeek**: DeepSeek V3 (671B), DeepSeek R1 (æ¨ç†ä¸“ç”¨)
- **ç¡…åŸºæµåŠ¨**: DeepSeek V3/R1, é€šä¹‰åƒé—®QwQ-32B, Qwen2.5-72B  
- **ç«å±±å¼•æ“**: è±†åŒ…1.6ç³»åˆ— (å…¨èƒ½ç‰ˆ/æ€è€ƒç‰ˆ/æé€Ÿç‰ˆ)
- **æœˆä¹‹æš—é¢**: Kimi K2 (1Tå‚æ•°), Kimi v1 128K
- **Ollama**: æœ¬åœ°éƒ¨ç½²14B+å‚æ•°æ¨¡å‹

### Embeddingæ¨¡å‹å‚å•†
- **Ollama**: BGE-M3, Nomic Embed Text, MxBai Embed Large
- **OpenAI**: Text Embedding 3 Large/Small
- **ç¡…åŸºæµåŠ¨**: BGE Large ä¸­æ–‡ v1.5

## ğŸ“‹ æ¨¡å‹å‘½åæ ¼å¼

ç»Ÿä¸€é‡‡ç”¨ `provider.model` æ ¼å¼:

```
deepseek.DeepSeek_V3          # DeepSeek V3
siliconflow.Qwen2_5_72B       # ç¡…åŸºæµåŠ¨çš„é€šä¹‰åƒé—®2.5-72B
volcano.Doubao_1_6_Thinking   # ç«å±±å¼•æ“è±†åŒ…1.6æ€è€ƒç‰ˆ
moonshot.Kimi_K2              # æœˆä¹‹æš—é¢Kimi K2
ollama.DeepSeek_R1_32B        # Ollamaæœ¬åœ°DeepSeek R1
ollama.BGE_M3                 # Ollamaæœ¬åœ°BGE-M3 Embedding
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒé…ç½®

å¤åˆ¶å¹¶é…ç½®ç¯å¢ƒå˜é‡:
```bash
cp .env.example .env
# ç¼–è¾‘.envæ–‡ä»¶ï¼Œå¡«å…¥æ‚¨çš„API Keys
```

### 2. åŸºç¡€ä½¿ç”¨

```python
from HomeSystem.graph.llm_factory import get_llm, get_embedding

# ä½¿ç”¨é»˜è®¤æ¨¡å‹
llm = get_llm()

# ä½¿ç”¨æŒ‡å®šæ¨¡å‹
deepseek_llm = get_llm("deepseek.DeepSeek_V3")
qwen_llm = get_llm("siliconflow.Qwen2_5_72B")

# ä½¿ç”¨embeddingæ¨¡å‹
embedding = get_embedding("ollama.BGE_M3")
```

### 3. åœ¨Graphä¸­ä½¿ç”¨

```python
from HomeSystem.graph.base_graph import BaseGraph
from HomeSystem.graph.llm_factory import get_llm, get_embedding

class MyGraph(BaseGraph):
    def __init__(self):
        super().__init__()
        
        # æ ¹æ®ä»»åŠ¡éœ€æ±‚é€‰æ‹©ä¸åŒæ¨¡å‹
        self.main_llm = get_llm("deepseek.DeepSeek_V3")       # é€šç”¨å¯¹è¯
        self.code_llm = get_llm("siliconflow.Qwen2_5_72B")   # ä»£ç ç”Ÿæˆ  
        self.reasoning_llm = get_llm("deepseek.DeepSeek_R1") # æ¨ç†ä»»åŠ¡
        self.embedding = get_embedding("ollama.BGE_M3")      # æ–‡æœ¬å‘é‡åŒ–
        
    def process_different_tasks(self, query: str):
        # åŠ¨æ€é€‰æ‹©æœ€é€‚åˆçš„æ¨¡å‹
        if "ä»£ç " in query:
            return self.code_llm.invoke([HumanMessage(content=query)])
        elif "æ¨ç†" in query:
            return self.reasoning_llm.invoke([HumanMessage(content=query)])
        else:
            return self.main_llm.invoke([HumanMessage(content=query)])
```

## ğŸ“– APIæ–‡æ¡£

### æ ¸å¿ƒå‡½æ•°

#### `get_llm(model_name=None, **kwargs)`
åˆ›å»ºLLMå®ä¾‹ï¼Œè¿”å›LangGraphå…¼å®¹çš„æ¨¡å‹ã€‚

**å‚æ•°:**
- `model_name`: æ¨¡å‹åç§°ï¼Œä½¿ç”¨`provider.model`æ ¼å¼ï¼ŒNoneæ—¶ä½¿ç”¨é»˜è®¤æ¨¡å‹
- `**kwargs`: æ¨¡å‹å‚æ•°(temperature, max_tokensç­‰)

**è¿”å›:** `BaseChatModel` - å¯ç›´æ¥ç”¨äºLangGraph

#### `get_embedding(model_name=None, **kwargs)`
åˆ›å»ºEmbeddingå®ä¾‹ã€‚

**å‚æ•°:**
- `model_name`: æ¨¡å‹åç§°ï¼ŒNoneæ—¶ä½¿ç”¨é»˜è®¤æ¨¡å‹  
- `**kwargs`: æ¨¡å‹å‚æ•°

**è¿”å›:** `Embeddings` - Embeddingæ¨¡å‹å®ä¾‹

#### `list_available_llm_models()`
è·å–æ‰€æœ‰å¯ç”¨LLMæ¨¡å‹åˆ—è¡¨ã€‚

**è¿”å›:** `List[str]` - å¯ç”¨æ¨¡å‹åç§°åˆ—è¡¨

#### `list_available_embedding_models()`
è·å–æ‰€æœ‰å¯ç”¨Embeddingæ¨¡å‹åˆ—è¡¨ã€‚

**è¿”å›:** `List[str]` - å¯ç”¨Embeddingæ¨¡å‹åç§°åˆ—è¡¨

### LLMFactoryç±»

```python
from HomeSystem.graph.llm_factory import LLMFactory

factory = LLMFactory()

# æŸ¥çœ‹å¯ç”¨æ¨¡å‹
factory.list_models()

# åˆ›å»ºæ¨¡å‹å®ä¾‹
llm = factory.create_llm("deepseek.DeepSeek_V3")
embedding = factory.create_embedding("ollama.BGE_M3")
```

## âš™ï¸ é…ç½®æ–‡ä»¶

### llm_providers.yamlç»“æ„

```yaml
providers:
  deepseek:
    name: "DeepSeek"
    type: "openai_compatible"
    api_key_env: "DEEPSEEK_API_KEY"
    base_url: "https://api.deepseek.com"
    models:
      - name: "deepseek-chat"
        key: "deepseek.DeepSeek_V3"
        display_name: "DeepSeek V3"
        parameters: "671Bæ€»å‚æ•°/37Bæ¿€æ´»"
        max_tokens: 131072
        supports_functions: true

defaults:
  llm:
    model_key: "deepseek.DeepSeek_V3"
    temperature: 0.7
    max_tokens: 4000
  embedding:
    model_key: "ollama.BGE_M3"
    dimensions: 1024
```

### .envé…ç½®

```bash
# DeepSeek
DEEPSEEK_API_KEY=sk-your-deepseek-key
DEEPSEEK_BASE_URL=https://api.deepseek.com

# ç¡…åŸºæµåŠ¨
SILICONFLOW_API_KEY=sk-your-siliconflow-key  
SILICONFLOW_BASE_URL=https://api.siliconflow.cn/v1

# ç«å±±å¼•æ“
VOLCANO_API_KEY=your-volcano-key
VOLCANO_BASE_URL=https://ark.cn-beijing.volces.com/api/v3

# æœˆä¹‹æš—é¢
MOONSHOT_API_KEY=sk-your-moonshot-key
MOONSHOT_BASE_URL=https://api.moonshot.cn/v1

# Ollamaæœ¬åœ°
OLLAMA_BASE_URL=http://localhost:11434
```

## ğŸ’¡ ä½¿ç”¨å»ºè®®

### æ¨¡å‹é€‰æ‹©æŒ‡å—

- **é€šç”¨å¯¹è¯**: `deepseek.DeepSeek_V3` - é«˜æ€§èƒ½ï¼Œæˆæœ¬åˆç†
- **æ·±åº¦æ¨ç†**: `deepseek.DeepSeek_R1` - ä¸“é—¨ä¼˜åŒ–æ¨ç†èƒ½åŠ›
- **ä»£ç ç”Ÿæˆ**: `siliconflow.Qwen2_5_72B` - ä»£ç èƒ½åŠ›å¼º
- **é•¿æ–‡æ¡£**: `volcano.Doubao_1_6` - 256Kä¸Šä¸‹æ–‡é•¿åº¦
- **æœ¬åœ°éƒ¨ç½²**: `ollama.DeepSeek_R1_32B` - æ— éœ€API Key
- **æ–‡æœ¬å‘é‡**: `ollama.BGE_M3` - ä¸­è‹±æ–‡æ”¯æŒå¥½

### æ€§èƒ½ä¼˜åŒ–

1. **API Keyç®¡ç†**: ç¡®ä¿è®¾ç½®æ­£ç¡®çš„ç¯å¢ƒå˜é‡
2. **æœ¬åœ°æ¨¡å‹**: ä½¿ç”¨Ollamaå‡å°‘APIè°ƒç”¨æˆæœ¬
3. **æ¨¡å‹åˆ‡æ¢**: æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©åˆé€‚æ¨¡å‹
4. **å‚æ•°è°ƒä¼˜**: é€‚å½“è°ƒæ•´temperatureå’Œmax_tokens

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**Q: æ¨¡å‹ä¸å¯ç”¨/API Keyé”™è¯¯**
```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
python -c "import os; print('DEEPSEEK_API_KEY:', os.getenv('DEEPSEEK_API_KEY')[:10] + '...' if os.getenv('DEEPSEEK_API_KEY') else 'None')"

# æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§
python -c "from HomeSystem.graph.llm_factory import list_available_llm_models; print(list_available_llm_models())"
```

**Q: Ollamaæ¨¡å‹ä¸å¯ç”¨**
```bash
# ç¡®ä¿OllamaæœåŠ¡è¿è¡Œ
curl http://localhost:11434/api/tags

# å®‰è£…éœ€è¦çš„æ¨¡å‹
ollama pull deepseek-r1:32b
ollama pull bge-m3:latest
```

**Q: ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜**
```bash
# å®‰è£…æ­£ç¡®çš„ä¾èµ–ç‰ˆæœ¬
pip install langchain-openai langchain-ollama langchain-core
```

## ğŸ“ ç¤ºä¾‹ä»£ç 

å®Œæ•´ç¤ºä¾‹è¯·æŸ¥çœ‹:
- `examples/llm_usage_example.py` - åŸºç¡€ä½¿ç”¨ç¤ºä¾‹
- `examples/workflow_example.py` - å·¥ä½œæµé›†æˆç¤ºä¾‹

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›è¿™ä¸ªç³»ç»Ÿï¼

## ğŸ“„ è®¸å¯è¯

éµå¾ªHomeSystemé¡¹ç›®è®¸å¯è¯ã€‚