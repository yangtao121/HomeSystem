# ArXiv API å·¥å…·æ–‡æ¡£

## æ¦‚è¿°

HomeSystem ArXiv å·¥å…·æ˜¯ä¸€ä¸ªç”¨äºæœç´¢å’Œè·å– ArXiv å­¦æœ¯è®ºæ–‡çš„ Python åº“ã€‚è¯¥å·¥å…·å®Œå…¨åŸºäº ArXiv å®˜æ–¹ APIï¼Œæä¾›é«˜æ€§èƒ½ã€æ— é™åˆ¶çš„è®ºæ–‡æœç´¢åŠŸèƒ½ï¼Œæ”¯æŒè·å–æœ€æ–°è®ºæ–‡æ•°æ®ã€‚

## ä¸»è¦ç‰¹æ€§

- âœ… **ç›´æ¥ API è®¿é—®**: ä½¿ç”¨ ArXiv å®˜æ–¹ APIï¼Œæ— ç¬¬ä¸‰æ–¹ä¾èµ–
- âœ… **æ— æœç´¢é™åˆ¶**: æ”¯æŒå¤§é‡ç»“æœæ£€ç´¢ï¼ˆæœ€å¤š 2000 æ¡ï¼‰
- âœ… **æœ€æ–°æ•°æ®**: è·å–å®æ—¶æ›´æ–°çš„è®ºæ–‡ä¿¡æ¯
- âœ… **å¤šç§æ’åº**: æ”¯æŒç›¸å…³æ€§ã€æäº¤æ—¥æœŸã€æ›´æ–°æ—¥æœŸæ’åº
- âœ… **PDF ä¸‹è½½**: å†…ç½® PDF ä¸‹è½½åŠŸèƒ½ï¼Œæ”¯æŒè¿›åº¦æ¡
- âœ… **å…ƒæ•°æ®æå–**: è‡ªåŠ¨æå–è®ºæ–‡ IDã€å‘å¸ƒæ—¶é—´ç­‰ä¿¡æ¯
- âœ… **é”™è¯¯å¤„ç†**: å®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—è®°å½•

## å®‰è£…ä¾èµ–

```bash
pip install requests xml feedparser loguru tqdm
```

## å¿«é€Ÿå¼€å§‹

```python
from HomeSystem.utility.arxiv.arxiv import ArxivTool

# åˆ›å»ºå·¥å…·å®ä¾‹
arxiv_tool = ArxivTool()

# åŸºç¡€æœç´¢
results = arxiv_tool.arxivSearch("machine learning", num_results=20)

# éå†ç»“æœ
for paper in results:
    print(f"æ ‡é¢˜: {paper.title}")
    print(f"å‘å¸ƒæ—¶é—´: {paper.published_date}")
    print(f"é“¾æ¥: {paper.link}")
    print("-" * 50)
```

## API å‚è€ƒ

### ç±»ç»“æ„

#### ArxivData

å•ä¸ªè®ºæ–‡çš„æ•°æ®å®¹å™¨ç±»ã€‚

**å±æ€§**:
- `title` (str): è®ºæ–‡æ ‡é¢˜
- `link` (str): ArXiv é“¾æ¥
- `snippet` (str): è®ºæ–‡æ‘˜è¦
- `categories` (str): è®ºæ–‡åˆ†ç±»
- `pdf_link` (str): PDF ä¸‹è½½é“¾æ¥
- `arxiv_id` (str): ArXiv ID
- `published_date` (str): å‘å¸ƒæ—¥æœŸ
- `tag` (list[str]): è®ºæ–‡æ ‡ç­¾
- `pdf` (bytes): PDF å†…å®¹ï¼ˆä¸‹è½½åï¼‰
- `pdf_path` (str): PDF ä¿å­˜è·¯å¾„

**æ–¹æ³•**:

##### `setTag(tag: list[str])`
è®¾ç½®è®ºæ–‡æ ‡ç­¾ã€‚

```python
paper = results.results[0]
paper.setTag(["AI", "æ·±åº¦å­¦ä¹ ", "è®¡ç®—æœºè§†è§‰"])
```

##### `get_formatted_info() -> str`
è·å–æ ¼å¼åŒ–çš„è®ºæ–‡ä¿¡æ¯ã€‚

```python
info = paper.get_formatted_info()
print(info)
```

##### `downloadPdf(save_path: str = None) -> bytes`
ä¸‹è½½è®ºæ–‡ PDFã€‚

**å‚æ•°**:
- `save_path` (str, optional): PDF ä¿å­˜ç›®å½•è·¯å¾„

**è¿”å›**: PDF å†…å®¹çš„å­—èŠ‚æ•°æ®

**å¼‚å¸¸**:
- `ValueError`: PDF é“¾æ¥ä¸ºç©º
- `Exception`: ä¸‹è½½æˆ–ä¿å­˜å¤±è´¥

```python
# ä»…ä¸‹è½½åˆ°å†…å­˜
pdf_content = paper.downloadPdf()

# ä¸‹è½½å¹¶ä¿å­˜åˆ°æ–‡ä»¶
pdf_content = paper.downloadPdf(save_path="/path/to/save/directory")
```

##### `clearPdf()`
æ¸…ç©º PDF å†…å®¹ï¼Œé‡Šæ”¾å†…å­˜ã€‚

```python
paper.clearPdf()
```

#### ArxivResult

æœç´¢ç»“æœå®¹å™¨ç±»ï¼Œæä¾›å¤šç§ç»“æ„åŒ–æ˜¾ç¤ºåŠŸèƒ½ã€‚

**å±æ€§**:
- `results` (list[ArxivData]): è®ºæ–‡æ•°æ®åˆ—è¡¨
- `num_results` (int): ç»“æœæ•°é‡

**æ–¹æ³•**:
- æ”¯æŒè¿­ä»£å™¨åè®®ï¼Œå¯ç›´æ¥éå†

```python
for paper in results:
    print(paper.title)
```

##### `display_results(display_range="all", max_display=10, show_details=True, show_summary=True)`
ç»“æ„åŒ–æ˜¾ç¤ºæœç´¢ç»“æœçš„ä¸»è¦æ–¹æ³•ã€‚

**å‚æ•°**:
- `display_range` (str): æ˜¾ç¤ºèŒƒå›´ï¼Œ"all" æ˜¾ç¤ºå…¨éƒ¨ï¼Œ"limited" é™åˆ¶æ•°é‡
- `max_display` (int): å½“ display_range ä¸º "limited" æ—¶çš„æœ€å¤§æ˜¾ç¤ºæ•°é‡
- `show_details` (bool): æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
- `show_summary` (bool): æ˜¯å¦æ˜¾ç¤ºæ‘˜è¦ç»Ÿè®¡

```python
# æ˜¾ç¤ºå…¨éƒ¨ç»“æœ
results.display_results()

# åªæ˜¾ç¤ºå‰5ä¸ªï¼ŒåŒ…å«æ‘˜è¦ç»Ÿè®¡
results.display_results(display_range="limited", max_display=5, show_summary=True)

# åªæ˜¾ç¤ºæ ‡é¢˜ï¼Œä¸æ˜¾ç¤ºæ‘˜è¦
results.display_results(show_details=True, show_summary=False)
```

##### `display_brief(max_display=5)`
ç®€æ´æ˜¾ç¤ºæ¨¡å¼ï¼Œåªæ˜¾ç¤ºæ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯ã€‚

**å‚æ•°**:
- `max_display` (int): æœ€å¤§æ˜¾ç¤ºæ•°é‡

```python
# ç®€æ´æ˜¾ç¤ºå‰5ç¯‡è®ºæ–‡
results.display_brief(max_display=5)
```

##### `display_titles_only(max_display=None)`
ä»…æ˜¾ç¤ºè®ºæ–‡æ ‡é¢˜åˆ—è¡¨ã€‚

**å‚æ•°**:
- `max_display` (int, optional): æœ€å¤§æ˜¾ç¤ºæ•°é‡ï¼ŒNone åˆ™æ˜¾ç¤ºå…¨éƒ¨

```python
# ä»…æ˜¾ç¤ºæ‰€æœ‰æ ‡é¢˜
results.display_titles_only()

# ä»…æ˜¾ç¤ºå‰10ä¸ªæ ‡é¢˜
results.display_titles_only(max_display=10)
```

##### `get_papers_by_date_range(start_year=None, end_year=None) -> ArxivResult`
æ ¹æ®å‘å¸ƒå¹´ä»½ç­›é€‰è®ºæ–‡ã€‚

**å‚æ•°**:
- `start_year` (int, optional): å¼€å§‹å¹´ä»½
- `end_year` (int, optional): ç»“æŸå¹´ä»½

**è¿”å›**: ç­›é€‰åçš„ ArxivResult å¯¹è±¡

```python
# ç­›é€‰2020å¹´åçš„è®ºæ–‡
recent_papers = results.get_papers_by_date_range(start_year=2020)

# ç­›é€‰2018-2022å¹´çš„è®ºæ–‡
period_papers = results.get_papers_by_date_range(start_year=2018, end_year=2022)
```

#### ArxivTool

ä¸»è¦çš„æœç´¢å·¥å…·ç±»ã€‚

##### `__init__(search_host: str = None)`
æ„é€ å‡½æ•°ã€‚

**å‚æ•°**:
- `search_host` (str, optional): ä¿ç•™å‚æ•°ï¼Œå…¼å®¹æ—§ç‰ˆæœ¬

```python
arxiv_tool = ArxivTool()
```

##### `arxivSearch(query, num_results=20, sort_by="relevance", order="desc", max_results=None, kwargs=None, use_direct_api=True) -> ArxivResult`
ä¸»è¦æœç´¢æ–¹æ³•ã€‚

**å‚æ•°**:
- `query` (str): æœç´¢æŸ¥è¯¢
- `num_results` (int, default=20): è¿”å›ç»“æœæ•°é‡
- `sort_by` (str, default="relevance"): æ’åºæ–¹å¼
  - `"relevance"`: ç›¸å…³æ€§
  - `"lastUpdatedDate"`: æœ€åæ›´æ–°æ—¥æœŸ
  - `"submittedDate"`: æäº¤æ—¥æœŸ
- `order` (str, default="desc"): æ’åºé¡ºåº
  - `"desc"`: é™åº
  - `"asc"`: å‡åº
- `max_results` (int, optional): ä¿ç•™å‚æ•°ï¼Œå…¼å®¹æ—§ç‰ˆæœ¬
- `kwargs` (dict, optional): ä¿ç•™å‚æ•°ï¼Œå…¼å®¹æ—§ç‰ˆæœ¬
- `use_direct_api` (bool, default=True): ä¿ç•™å‚æ•°ï¼Œæ€»æ˜¯ä½¿ç”¨ç›´æ¥ API

**è¿”å›**: ArxivResult å¯¹è±¡

```python
# åŸºç¡€æœç´¢
results = arxiv_tool.arxivSearch("deep learning")

# è·å–å¤§é‡ç»“æœ
results = arxiv_tool.arxivSearch("neural networks", num_results=100)

# æŒ‰æäº¤æ—¥æœŸæ’åº
results = arxiv_tool.arxivSearch("computer vision", 
                                sort_by="submittedDate", 
                                order="desc")
```

##### `getLatestPapers(query: str, num_results: int = 20) -> ArxivResult`
è·å–æœ€æ–°è®ºæ–‡ã€‚

```python
latest = arxiv_tool.getLatestPapers("machine learning", num_results=30)
```

##### `getRecentlyUpdated(query: str, num_results: int = 20) -> ArxivResult`
è·å–æœ€è¿‘æ›´æ–°çš„è®ºæ–‡ã€‚

```python
updated = arxiv_tool.getRecentlyUpdated("artificial intelligence", num_results=25)
```

##### `searchWithHighLimit(query, num_results=50, sort_by="relevance", order="desc", max_single_request=20) -> ArxivResult`
é«˜é™åˆ¶æœç´¢æ–¹æ³•ã€‚

```python
large_results = arxiv_tool.searchWithHighLimit("NLP", num_results=200)
```

##### `directArxivSearch(query, num_results=20, sort_by="relevance", order="descending") -> ArxivResult`
ç›´æ¥ ArXiv API æœç´¢ã€‚

```python
direct_results = arxiv_tool.directArxivSearch("reinforcement learning", 
                                            num_results=50,
                                            sort_by="submittedDate",
                                            order="descending")
```

##### `getLatestPapersDirectly(query: str, num_results: int = 20) -> ArxivResult`
ç›´æ¥è·å–æœ€æ–°è®ºæ–‡ã€‚

```python
latest_direct = arxiv_tool.getLatestPapersDirectly("GAN", num_results=40)
```

## ä½¿ç”¨ç¤ºä¾‹

### 1. åŸºç¡€æœç´¢å’Œç»“æœå¤„ç†

```python
from HomeSystem.utility.arxiv.arxiv import ArxivTool

# åˆ›å»ºå·¥å…·å®ä¾‹
arxiv = ArxivTool()

# æœç´¢è®ºæ–‡
results = arxiv.arxivSearch("transformer architecture", num_results=10)

print(f"æ‰¾åˆ° {results.num_results} ç¯‡è®ºæ–‡:")
for i, paper in enumerate(results, 1):
    print(f"\n{i}. {paper.title}")
    print(f"   ArXiv ID: {paper.arxiv_id}")
    print(f"   å‘å¸ƒæ—¶é—´: {paper.published_date}")
    print(f"   åˆ†ç±»: {paper.categories}")
    print(f"   é“¾æ¥: {paper.link}")
    print(f"   æ‘˜è¦: {paper.snippet[:200]}...")
```

### 2. è·å–æœ€æ–°è®ºæ–‡

```python
# è·å–æœ€æ–°çš„æ·±åº¦å­¦ä¹ è®ºæ–‡
latest_papers = arxiv.getLatestPapers("deep learning", num_results=20)

print("æœ€æ–°çš„æ·±åº¦å­¦ä¹ è®ºæ–‡:")
for paper in latest_papers:
    print(f"ğŸ“„ {paper.title}")
    print(f"ğŸ•’ {paper.published_date}")
    print(f"ğŸ”— {paper.link}")
    print("-" * 80)
```

### 3. å¤§é‡æ•°æ®æ£€ç´¢

```python
# è·å–å¤§é‡ç¥ç»ç½‘ç»œç›¸å…³è®ºæ–‡
large_dataset = arxiv.arxivSearch("neural network", num_results=500)

print(f"æ£€ç´¢åˆ° {large_dataset.num_results} ç¯‡è®ºæ–‡")

# æŒ‰å‘å¸ƒæ—¶é—´ç»Ÿè®¡
date_counts = {}
for paper in large_dataset:
    date = paper.published_date
    date_counts[date] = date_counts.get(date, 0) + 1

print("è®ºæ–‡å‘å¸ƒæ—¶é—´åˆ†å¸ƒ:")
for date, count in sorted(date_counts.items(), reverse=True)[:10]:
    print(f"{date}: {count} ç¯‡")
```

### 4. PDF ä¸‹è½½

```python
# æœç´¢å¹¶ä¸‹è½½PDF
results = arxiv.arxivSearch("attention mechanism", num_results=5)

for i, paper in enumerate(results):
    try:
        print(f"ä¸‹è½½è®ºæ–‡ {i+1}: {paper.title[:50]}...")
        
        # ä¸‹è½½PDFåˆ°æŒ‡å®šç›®å½•
        pdf_content = paper.downloadPdf(save_path="./downloads")
        print(f"âœ… ä¸‹è½½æˆåŠŸ: {paper.pdf_path}")
        
        # é‡Šæ”¾å†…å­˜
        paper.clearPdf()
        
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
```

### 5. æŒ‰ä¸åŒæ¡ä»¶æ’åº

```python
# æŒ‰ç›¸å…³æ€§æ’åº
relevance_results = arxiv.arxivSearch("BERT", 
                                    sort_by="relevance", 
                                    order="desc", 
                                    num_results=15)

# æŒ‰æäº¤æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„ï¼‰
newest_results = arxiv.arxivSearch("BERT", 
                                 sort_by="submittedDate", 
                                 order="desc", 
                                 num_results=15)

# æŒ‰æ›´æ–°æ—¥æœŸæ’åº
updated_results = arxiv.getRecentlyUpdated("BERT", num_results=15)

print("æŒ‰ç›¸å…³æ€§æ’åºçš„å‰3ç¯‡:")
for i, paper in enumerate(relevance_results.results[:3], 1):
    print(f"{i}. {paper.title}")

print("\næŒ‰æäº¤æ—¥æœŸæ’åºçš„å‰3ç¯‡:")
for i, paper in enumerate(newest_results.results[:3], 1):
    print(f"{i}. {paper.title} ({paper.published_date})")
```

### 6. è®ºæ–‡æ ‡ç­¾ç®¡ç†

```python
results = arxiv.arxivSearch("computer vision", num_results=10)

# ä¸ºè®ºæ–‡æ·»åŠ æ ‡ç­¾
for paper in results:
    # æ ¹æ®æ ‡é¢˜æˆ–æ‘˜è¦æ·»åŠ ç›¸åº”æ ‡ç­¾
    tags = []
    
    if "CNN" in paper.title or "convolutional" in paper.snippet.lower():
        tags.append("CNN")
    if "object detection" in paper.snippet.lower():
        tags.append("ç›®æ ‡æ£€æµ‹")
    if "image" in paper.snippet.lower():
        tags.append("å›¾åƒå¤„ç†")
    
    if tags:
        paper.setTag(tags)
        print(f"è®ºæ–‡: {paper.title[:50]}...")
        print(f"æ ‡ç­¾: {', '.join(paper.tag)}")
        print("-" * 50)
```

### 7. ç»“æ„åŒ–æ˜¾ç¤ºåŠŸèƒ½æ¼”ç¤º

```python
# åˆ›å»ºå·¥å…·å®ä¾‹
arxiv = ArxivTool()

# æœç´¢æœºå™¨å­¦ä¹ ç›¸å…³è®ºæ–‡
results = arxiv.arxivSearch("machine learning", num_results=20)

print("=== ç»“æ„åŒ–æ˜¾ç¤ºåŠŸèƒ½æ¼”ç¤º ===")

# 1. å®Œæ•´æ˜¾ç¤ºå‰5ä¸ªç»“æœ
print("ğŸ“‹ å®Œæ•´æ˜¾ç¤ºå‰5ä¸ªç»“æœ:")
results.display_results(display_range="limited", max_display=5)

print("\n" + "="*80 + "\n")

# 2. ç®€æ´æ˜¾ç¤ºæ¨¡å¼
print("ğŸ“‹ ç®€æ´æ˜¾ç¤ºæ¨¡å¼:")
results.display_brief(max_display=7)

print("\n" + "="*80 + "\n")

# 3. ä»…æ˜¾ç¤ºæ ‡é¢˜
print("ğŸ“‹ ä»…æ˜¾ç¤ºæ ‡é¢˜:")
results.display_titles_only(max_display=10)

print("\n" + "="*80 + "\n")

# 4. æ˜¾ç¤ºå…¨éƒ¨ç»“æœï¼ˆé€‚åˆå°æ•°æ®é›†ï¼‰
small_results = arxiv.arxivSearch("quantum computing", num_results=5)
print("ğŸ“‹ æ˜¾ç¤ºå…¨éƒ¨ç»“æœ:")
small_results.display_results(display_range="all", show_summary=True)

print("\n" + "="*80 + "\n")

# 5. å¹´ä»½ç­›é€‰å’Œæ˜¾ç¤º
print("ğŸ“‹ å¹´ä»½ç­›é€‰æ¼”ç¤º:")
recent_papers = results.get_papers_by_date_range(start_year=2020)
if recent_papers.num_results > 0:
    print(f"æ‰¾åˆ° {recent_papers.num_results} ç¯‡2020å¹´åçš„è®ºæ–‡")
    recent_papers.display_brief(max_display=3)
else:
    print("æœªæ‰¾åˆ°2020å¹´åçš„è®ºæ–‡")
```

### 8. é”™è¯¯å¤„ç†å’Œé‡è¯•

```python
import time

def robust_search(arxiv_tool, query, num_results=20, max_retries=3):
    """å¸¦é‡è¯•æœºåˆ¶çš„æœç´¢"""
    for attempt in range(max_retries):
        try:
            results = arxiv_tool.arxivSearch(query, num_results=num_results)
            if results.num_results > 0:
                return results
            else:
                print(f"å°è¯• {attempt + 1}: æœªæ‰¾åˆ°ç»“æœ")
        except Exception as e:
            print(f"å°è¯• {attempt + 1} å¤±è´¥: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
    
    return None

# ä½¿ç”¨ç¤ºä¾‹
arxiv = ArxivTool()
results = robust_search(arxiv, "quantum computing", num_results=30)

if results:
    print(f"æˆåŠŸè·å– {results.num_results} ä¸ªç»“æœ")
    # ä½¿ç”¨ç»“æ„åŒ–æ˜¾ç¤º
    results.display_brief()
else:
    print("æœç´¢å¤±è´¥")
```

## æœ€ä½³å®è·µ

### 1. æœç´¢æŸ¥è¯¢ä¼˜åŒ–

```python
# ä½¿ç”¨å…·ä½“çš„æŸ¥è¯¢è¯
good_query = "transformer attention mechanism NLP"
bad_query = "AI"

# ä½¿ç”¨ArXivåˆ†ç±»æ ‡è¯†ç¬¦
category_query = "cat:cs.LG"  # æœºå™¨å­¦ä¹ ç±»åˆ«

# ç»„åˆæŸ¥è¯¢
complex_query = "ti:transformer AND cat:cs.CL"  # æ ‡é¢˜åŒ…å«transformerä¸”å±äºè®¡ç®—è¯­è¨€å­¦
```

### 2. å†…å­˜ç®¡ç†

```python
# å¤„ç†å¤§é‡è®ºæ–‡æ—¶åŠæ—¶æ¸…ç†PDFå†…å®¹
results = arxiv.arxivSearch("deep learning", num_results=100)

for paper in results:
    # å¤„ç†è®ºæ–‡ä¿¡æ¯
    process_paper_metadata(paper)
    
    # å¦‚æœéœ€è¦PDFï¼Œä¸‹è½½ååŠæ—¶æ¸…ç†
    if need_pdf(paper):
        pdf_content = paper.downloadPdf()
        process_pdf(pdf_content)
        paper.clearPdf()  # é‡Šæ”¾å†…å­˜
```

### 3. æ‰¹é‡å¤„ç†

```python
def batch_download_papers(queries, papers_per_query=20, save_dir="./papers"):
    """æ‰¹é‡ä¸‹è½½å¤šä¸ªæŸ¥è¯¢çš„è®ºæ–‡"""
    arxiv = ArxivTool()
    all_papers = []
    
    for query in queries:
        print(f"æœç´¢: {query}")
        results = arxiv.arxivSearch(query, num_results=papers_per_query)
        
        for paper in results:
            try:
                paper.downloadPdf(save_path=save_dir)
                all_papers.append(paper)
                paper.clearPdf()  # é‡Šæ”¾å†…å­˜
            except Exception as e:
                print(f"ä¸‹è½½å¤±è´¥ {paper.title}: {e}")
    
    return all_papers

# ä½¿ç”¨ç¤ºä¾‹
queries = ["neural architecture search", "few-shot learning", "meta learning"]
papers = batch_download_papers(queries, papers_per_query=10)
print(f"æ€»å…±ä¸‹è½½äº† {len(papers)} ç¯‡è®ºæ–‡")
```

## é™åˆ¶è¯´æ˜

1. **API é™åˆ¶**: ArXiv API å•æ¬¡è¯·æ±‚æœ€å¤šè¿”å› 2000 ä¸ªç»“æœ
2. **è¯·æ±‚é¢‘ç‡**: å»ºè®®æ§åˆ¶è¯·æ±‚é¢‘ç‡ï¼Œé¿å…è¿‡äºé¢‘ç¹çš„APIè°ƒç”¨
3. **PDF ä¸‹è½½**: å¤§é‡PDFä¸‹è½½æ—¶æ³¨æ„ç½‘ç»œå¸¦å®½å’Œå­˜å‚¨ç©ºé—´
4. **å†…å­˜ä½¿ç”¨**: å¤„ç†å¤§é‡è®ºæ–‡æ—¶æ³¨æ„å†…å­˜ç®¡ç†

## é”™è¯¯å¤„ç†

å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆ:

1. **ç½‘ç»œè¿æ¥é”™è¯¯**: æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œé‡è¯•è¯·æ±‚
2. **ArXiv API è¶…æ—¶**: å¢åŠ è¶…æ—¶è®¾ç½®ï¼Œä½¿ç”¨é‡è¯•æœºåˆ¶
3. **PDF ä¸‹è½½å¤±è´¥**: æ£€æŸ¥é“¾æ¥æœ‰æ•ˆæ€§ï¼Œé‡è¯•ä¸‹è½½
4. **å†…å­˜ä¸è¶³**: åŠæ—¶æ¸…ç†PDFå†…å®¹ï¼Œåˆ†æ‰¹å¤„ç†

## æ›´æ–°æ—¥å¿—

### v2.0.0 (å½“å‰ç‰ˆæœ¬)
- âœ… å®Œå…¨ç§»é™¤ SearxNG ä¾èµ–
- âœ… ä½¿ç”¨ ArXiv å®˜æ–¹ API
- âœ… æ”¯æŒæ— é™åˆ¶æœç´¢ç»“æœ
- âœ… ä¼˜åŒ–æ€§èƒ½å’Œç¨³å®šæ€§
- âœ… ä¿æŒå‘åå…¼å®¹æ€§

### v1.x.x (å·²åºŸå¼ƒ)
- âŒ åŸºäº SearxNG æœç´¢
- âŒ æœç´¢ç»“æœé™åˆ¶ä¸º 10 æ¡
- âŒ æ•°æ®æ›´æ–°ä¸åŠæ—¶

## è´¡çŒ®å’Œæ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤ Issue æˆ– Pull Requestã€‚

## è®¸å¯è¯

è¯·éµå¾ªé¡¹ç›®çš„è®¸å¯è¯è¦æ±‚ã€‚