#!/usr/bin/env python3
"""
æ·±åº¦è®ºæ–‡åˆ†æAgentæµ‹è¯•è„šæœ¬

æµ‹è¯•å®Œæ•´çš„è®ºæ–‡åˆ†ææµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
1. æ–‡ä»¶å¤¹è§£æ
2. å›¾ç‰‡åˆ†æ
3. æ·±åº¦æ–‡æœ¬åˆ†æ  
4. ç¿»è¯‘
5. æŠ¥å‘Šç”Ÿæˆ
"""

import sys
import os
import asyncio
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/mnt/nfs_share/code/homesystem')

from HomeSystem.graph.deep_paper_analysis_agent import create_deep_paper_analysis_agent
from HomeSystem.graph.parser.paper_folder_parser import create_paper_folder_parser
from loguru import logger


def test_folder_parser():
    """æµ‹è¯•æ–‡ä»¶å¤¹è§£æå™¨"""
    logger.info("=== æµ‹è¯•æ–‡ä»¶å¤¹è§£æå™¨ ===")
    
    test_folder = "/mnt/nfs_share/code/homesystem/data/paper_analyze/2502.13508"
    
    try:
        parser = create_paper_folder_parser(test_folder)
        
        # éªŒè¯æ–‡ä»¶å¤¹
        validation = parser.validate_folder_integrity()
        logger.info(f"æ–‡ä»¶å¤¹éªŒè¯: {'é€šè¿‡' if validation['is_valid'] else 'å¤±è´¥'}")
        
        if validation["issues"]:
            logger.warning(f"å‘ç°é—®é¢˜: {validation['issues']}")
        
        # è§£ææ–‡ä»¶å¤¹
        result = parser.parse_folder()
        logger.info(f"è§£æç»“æœ:")
        logger.info(f"  æ–‡æœ¬é•¿åº¦: {len(result['paper_text'])} å­—ç¬¦")
        logger.info(f"  å›¾ç‰‡æ•°é‡: {len(result['available_images'])}")
        logger.info(f"  å…¬å¼æ•°é‡: {result['latex_formulas']['total_count']}")
        logger.info(f"  ç« èŠ‚æ•°é‡: {len(result['content_sections'])}")
        
        # å›¾ç‰‡åˆ†ç±»
        categorized = parser.categorize_images_by_type()
        for category, images in categorized.items():
            if images:
                logger.info(f"  {category}: {len(images)} å¼ ")
        
        return True
        
    except Exception as e:
        logger.error(f"æ–‡ä»¶å¤¹è§£ææµ‹è¯•å¤±è´¥: {e}")
        return False


def test_image_analysis_tool():
    """æµ‹è¯•å›¾ç‰‡åˆ†æå·¥å…·"""
    logger.info("=== æµ‹è¯•å›¾ç‰‡åˆ†æå·¥å…· ===")
    
    test_folder = "/mnt/nfs_share/code/homesystem/data/paper_analyze/2502.13508"
    
    try:
        from HomeSystem.graph.tool.image_analysis_tool import create_image_analysis_tool
        
        # åˆ›å»ºå·¥å…·
        tool = create_image_analysis_tool(test_folder, "ollama.Qwen2_5_VL_7B")
        
        # æµ‹è¯•å›¾ç‰‡éªŒè¯
        test_image = "imgs/img_in_image_box_253_178_967_593.jpg"
        validation = tool.validate_image(test_image)
        
        logger.info(f"å›¾ç‰‡éªŒè¯: {'æœ‰æ•ˆ' if validation['is_valid'] else 'æ— æ•ˆ'}")
        
        if validation["is_valid"]:
            # æµ‹è¯•å›¾ç‰‡åˆ†æ
            logger.info("å¼€å§‹å›¾ç‰‡åˆ†ææµ‹è¯•...")
            result = tool._run(
                analysis_query="Analyze this architecture diagram and describe the main components",
                image_path=test_image
            )
            
            logger.info(f"åˆ†æç»“æœé•¿åº¦: {len(result)} å­—ç¬¦")
            logger.info(f"å‰200å­—ç¬¦: {result[:200]}...")
            
            return True
        else:
            logger.error(f"å›¾ç‰‡éªŒè¯å¤±è´¥: {validation['error_message']}")
            return False
            
    except Exception as e:
        logger.error(f"å›¾ç‰‡åˆ†æå·¥å…·æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_translation_tool():
    """æµ‹è¯•ç¿»è¯‘å·¥å…·"""
    logger.info("=== æµ‹è¯•ç¿»è¯‘å·¥å…· ===")
    
    try:
        from HomeSystem.graph.tool.paper_translation_tool import create_translation_tool
        
        # åˆ›å»ºç¿»è¯‘å·¥å…·
        tool = create_translation_tool("ollama.Qwen3_30B", "zh")
        
        # æµ‹è¯•ç»“æ„åŒ–å†…å®¹ç¿»è¯‘
        test_contributions = {
            "contributions": [
                {
                    "id": 1,
                    "title": "End-to-end speech integration",
                    "description": "VLAS integrates speech recognition directly into the robot policy model without external ASR systems."
                }
            ],
            "contribution_count": 1,
            "innovation_level": "high"
        }
        
        logger.info("å¼€å§‹ç¿»è¯‘æµ‹è¯•...")
        translated = tool.translate_contributions(test_contributions)
        
        logger.info("ç¿»è¯‘ç»“æœ:")
        logger.info(f"  ç»“æ„é”®: {list(translated.keys())}")
        
        if "contributions" in translated:
            first_contrib = translated["contributions"][0]
            logger.info(f"  ç¬¬ä¸€ä¸ªè´¡çŒ®æ ‡é¢˜: {first_contrib.get('title', 'N/A')}")
        
        return True
        
    except Exception as e:
        logger.error(f"ç¿»è¯‘å·¥å…·æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_deep_analysis_agent():
    """æµ‹è¯•æ·±åº¦åˆ†æAgent"""
    logger.info("=== æµ‹è¯•æ·±åº¦åˆ†æAgent ===")
    
    test_folder = "/mnt/nfs_share/code/homesystem/data/paper_analyze/2502.13508"
    
    try:
        # åˆ›å»ºagentï¼ˆä½¿ç”¨è¾ƒå¿«çš„é…ç½®è¿›è¡Œæµ‹è¯•ï¼‰
        agent = create_deep_paper_analysis_agent(
            analysis_model="deepseek.DeepSeek_V3",  # ä½¿ç”¨æœ¬åœ°æ¨¡å‹æµ‹è¯•æ›´å¿«
            vision_model="ollama.Qwen2_5_VL_7B",
            translation_model="deepseek.DeepSeek_V3",
            max_analysis_iterations=3,  # é™åˆ¶è¿­ä»£æ¬¡æ•°
            enable_translation=True
        )
        
        logger.info(f"Agenté…ç½®: {agent.get_config().__dict__}")
        
        # æ‰§è¡Œåˆ†æï¼ˆé™åˆ¶æ—¶é—´ï¼‰
        logger.info("å¼€å§‹æ‰§è¡Œåˆ†æï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
        
        analysis_result = agent.analyze_paper_folder(test_folder, thread_id="test_1")
        
        # æ£€æŸ¥ç»“æœ
        logger.info("åˆ†æå®Œæˆï¼Œæ£€æŸ¥ç»“æœ:")
        logger.info(f"  åˆ†æè½®æ¬¡: {analysis_result.get('analysis_iteration', 0)}")
        logger.info(f"  åˆ†æå®Œæˆ: {analysis_result.get('is_analysis_complete', False)}")
        logger.info(f"  ç¿»è¯‘å®Œæˆ: {analysis_result.get('is_translation_complete', False)}")
        logger.info(f"  å·²å®Œæˆä»»åŠ¡: {len(analysis_result.get('completed_tasks', []))}")
        
        if analysis_result.get("analysis_errors"):
            logger.warning(f"åˆ†æé”™è¯¯: {analysis_result['analysis_errors']}")
        
        # æ£€æŸ¥å…·ä½“åˆ†æç»“æœ
        if analysis_result.get("main_contributions"):
            logger.info("âœ… ä¸»è¦è´¡çŒ®åˆ†æå®Œæˆ")
        
        if analysis_result.get("methodology_analysis"):
            logger.info("âœ… æ–¹æ³•è®ºåˆ†æå®Œæˆ")
        
        if analysis_result.get("experimental_results"):
            logger.info("âœ… å®éªŒç»“æœåˆ†æå®Œæˆ")
        
        if analysis_result.get("translated_contributions"):
            logger.info("âœ… ç¿»è¯‘å®Œæˆ")
        
        return analysis_result
        
    except Exception as e:
        logger.error(f"æ·±åº¦åˆ†æAgentæµ‹è¯•å¤±è´¥: {e}")
        return None


def test_markdown_generation(analysis_result):
    """æµ‹è¯•markdownæŠ¥å‘Šç”Ÿæˆ"""
    logger.info("=== æµ‹è¯•MarkdownæŠ¥å‘Šç”Ÿæˆ ===")
    
    if not analysis_result:
        logger.error("æ²¡æœ‰åˆ†æç»“æœï¼Œè·³è¿‡markdownæµ‹è¯•")
        return False
    
    try:
        # åˆ›å»ºagent
        agent = create_deep_paper_analysis_agent()
        
        # ç”ŸæˆæŠ¥å‘Š
        output_path = "/tmp/test_paper_analysis_report.md"
        report_content = agent.generate_markdown_report(analysis_result, output_path)
        
        logger.info(f"æŠ¥å‘Šç”Ÿæˆå®Œæˆ:")
        logger.info(f"  æŠ¥å‘Šé•¿åº¦: {len(report_content)} å­—ç¬¦")
        logger.info(f"  ä¿å­˜è·¯å¾„: {output_path}")
        
        # æ˜¾ç¤ºæŠ¥å‘Šå¼€å¤´
        logger.info("æŠ¥å‘Šå¼€å¤´:")
        lines = report_content.split('\n')
        for i, line in enumerate(lines[:20]):  # æ˜¾ç¤ºå‰20è¡Œ
            print(f"{i+1:2d}: {line}")
        
        return True
        
    except Exception as e:
        logger.error(f"MarkdownæŠ¥å‘Šç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("å¼€å§‹æ·±åº¦è®ºæ–‡åˆ†æAgentå®Œæ•´æµ‹è¯•")
    
    # æ£€æŸ¥æµ‹è¯•æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
    test_folder = "/mnt/nfs_share/code/homesystem/data/paper_analyze/2502.13508"
    if not os.path.exists(test_folder):
        logger.error(f"æµ‹è¯•æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {test_folder}")
        return
    
    test_results = []
    
    # 1. æµ‹è¯•æ–‡ä»¶å¤¹è§£æå™¨
    result1 = test_folder_parser()
    test_results.append(("æ–‡ä»¶å¤¹è§£æå™¨", result1))
    
    # 2. æµ‹è¯•å›¾ç‰‡åˆ†æå·¥å…·
    result2 = test_image_analysis_tool()
    test_results.append(("å›¾ç‰‡åˆ†æå·¥å…·", result2))
    
    # 3. æµ‹è¯•ç¿»è¯‘å·¥å…·
    result3 = test_translation_tool()
    test_results.append(("ç¿»è¯‘å·¥å…·", result3))
    
    # 4. æµ‹è¯•æ·±åº¦åˆ†æAgentï¼ˆä¸»è¦æµ‹è¯•ï¼‰
    analysis_result = test_deep_analysis_agent()
    test_results.append(("æ·±åº¦åˆ†æAgent", analysis_result is not None))
    
    # 5. æµ‹è¯•markdownæŠ¥å‘Šç”Ÿæˆ
    result5 = test_markdown_generation(analysis_result)
    test_results.append(("MarkdownæŠ¥å‘Šç”Ÿæˆ", result5))
    
    # æ±‡æ€»æµ‹è¯•ç»“æœ
    logger.info("\n" + "="*50)
    logger.info("æµ‹è¯•ç»“æœæ±‡æ€»:")
    
    passed = 0
    total = len(test_results)
    
    for test_name, success in test_results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        logger.info(f"  {test_name}: {status}")
        if success:
            passed += 1
    
    logger.info(f"\næ€»ä½“ç»“æœ: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ·±åº¦è®ºæ–‡åˆ†æAgentå¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚")
    else:
        logger.warning(f"âš ï¸  æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³ç»„ä»¶ã€‚")


if __name__ == "__main__":
    main()